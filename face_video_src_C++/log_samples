nohup: ignoring input
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0816 10:11:00.949506 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det1.prototxt
I0816 10:11:00.949668 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:00.949677 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:00.949949 20528 net.cpp:58] Initializing net from parameters: 
name: "PNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4-1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4-2"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv4-1"
  top: "prob1"
}
I0816 10:11:00.950101 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:00.950124 20528 net.cpp:100] Creating Layer input
I0816 10:11:00.950135 20528 net.cpp:408] input -> data
I0816 10:11:00.962855 20528 net.cpp:150] Setting up input
I0816 10:11:00.962913 20528 net.cpp:157] Top shape: 1 3 12 12 (432)
I0816 10:11:00.962919 20528 net.cpp:165] Memory required for data: 1728
I0816 10:11:00.962930 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:00.962957 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:00.962965 20528 net.cpp:434] conv1 <- data
I0816 10:11:00.962977 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:01.297075 20528 net.cpp:150] Setting up conv1
I0816 10:11:01.297134 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:01.297142 20528 net.cpp:165] Memory required for data: 5728
I0816 10:11:01.297183 20528 layer_factory.hpp:77] Creating layer PReLU1
I0816 10:11:01.297201 20528 net.cpp:100] Creating Layer PReLU1
I0816 10:11:01.297207 20528 net.cpp:434] PReLU1 <- conv1
I0816 10:11:01.297215 20528 net.cpp:395] PReLU1 -> conv1 (in-place)
I0816 10:11:01.297358 20528 net.cpp:150] Setting up PReLU1
I0816 10:11:01.297368 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:01.297372 20528 net.cpp:165] Memory required for data: 9728
I0816 10:11:01.297382 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:01.297394 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:01.297400 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:01.297407 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:01.297463 20528 net.cpp:150] Setting up pool1
I0816 10:11:01.297473 20528 net.cpp:157] Top shape: 1 10 5 5 (250)
I0816 10:11:01.297478 20528 net.cpp:165] Memory required for data: 10728
I0816 10:11:01.297483 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:01.297498 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:01.297503 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:01.297511 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:01.299871 20528 net.cpp:150] Setting up conv2
I0816 10:11:01.299892 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:01.299897 20528 net.cpp:165] Memory required for data: 11304
I0816 10:11:01.299911 20528 layer_factory.hpp:77] Creating layer PReLU2
I0816 10:11:01.299921 20528 net.cpp:100] Creating Layer PReLU2
I0816 10:11:01.299926 20528 net.cpp:434] PReLU2 <- conv2
I0816 10:11:01.299933 20528 net.cpp:395] PReLU2 -> conv2 (in-place)
I0816 10:11:01.300032 20528 net.cpp:150] Setting up PReLU2
I0816 10:11:01.300042 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:01.300047 20528 net.cpp:165] Memory required for data: 11880
I0816 10:11:01.300055 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:01.300066 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:01.300072 20528 net.cpp:434] conv3 <- conv2
I0816 10:11:01.300079 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:01.302392 20528 net.cpp:150] Setting up conv3
I0816 10:11:01.302410 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:01.302417 20528 net.cpp:165] Memory required for data: 12008
I0816 10:11:01.302428 20528 layer_factory.hpp:77] Creating layer PReLU3
I0816 10:11:01.302435 20528 net.cpp:100] Creating Layer PReLU3
I0816 10:11:01.302441 20528 net.cpp:434] PReLU3 <- conv3
I0816 10:11:01.302449 20528 net.cpp:395] PReLU3 -> conv3 (in-place)
I0816 10:11:01.302546 20528 net.cpp:150] Setting up PReLU3
I0816 10:11:01.302554 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:01.302559 20528 net.cpp:165] Memory required for data: 12136
I0816 10:11:01.302570 20528 layer_factory.hpp:77] Creating layer conv3_PReLU3_0_split
I0816 10:11:01.302583 20528 net.cpp:100] Creating Layer conv3_PReLU3_0_split
I0816 10:11:01.302588 20528 net.cpp:434] conv3_PReLU3_0_split <- conv3
I0816 10:11:01.302595 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_0
I0816 10:11:01.302603 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_1
I0816 10:11:01.302645 20528 net.cpp:150] Setting up conv3_PReLU3_0_split
I0816 10:11:01.302654 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:01.302659 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:01.302664 20528 net.cpp:165] Memory required for data: 12392
I0816 10:11:01.302670 20528 layer_factory.hpp:77] Creating layer conv4-1
I0816 10:11:01.302681 20528 net.cpp:100] Creating Layer conv4-1
I0816 10:11:01.302686 20528 net.cpp:434] conv4-1 <- conv3_PReLU3_0_split_0
I0816 10:11:01.302706 20528 net.cpp:408] conv4-1 -> conv4-1
I0816 10:11:01.304285 20528 net.cpp:150] Setting up conv4-1
I0816 10:11:01.304302 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:01.304308 20528 net.cpp:165] Memory required for data: 12400
I0816 10:11:01.304318 20528 layer_factory.hpp:77] Creating layer conv4-2
I0816 10:11:01.304330 20528 net.cpp:100] Creating Layer conv4-2
I0816 10:11:01.304337 20528 net.cpp:434] conv4-2 <- conv3_PReLU3_0_split_1
I0816 10:11:01.304345 20528 net.cpp:408] conv4-2 -> conv4-2
I0816 10:11:01.305552 20528 net.cpp:150] Setting up conv4-2
I0816 10:11:01.305570 20528 net.cpp:157] Top shape: 1 4 1 1 (4)
I0816 10:11:01.305577 20528 net.cpp:165] Memory required for data: 12416
I0816 10:11:01.305585 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:01.305601 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:01.305608 20528 net.cpp:434] prob1 <- conv4-1
I0816 10:11:01.305615 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:01.306249 20528 net.cpp:150] Setting up prob1
I0816 10:11:01.306265 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:01.306270 20528 net.cpp:165] Memory required for data: 12424
I0816 10:11:01.306277 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:01.306282 20528 net.cpp:228] conv4-2 does not need backward computation.
I0816 10:11:01.306288 20528 net.cpp:228] conv4-1 does not need backward computation.
I0816 10:11:01.306293 20528 net.cpp:228] conv3_PReLU3_0_split does not need backward computation.
I0816 10:11:01.306298 20528 net.cpp:228] PReLU3 does not need backward computation.
I0816 10:11:01.306303 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:01.306308 20528 net.cpp:228] PReLU2 does not need backward computation.
I0816 10:11:01.306313 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:01.306318 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:01.306324 20528 net.cpp:228] PReLU1 does not need backward computation.
I0816 10:11:01.306329 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:01.306334 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:01.306339 20528 net.cpp:270] This network produces output conv4-2
I0816 10:11:01.306344 20528 net.cpp:270] This network produces output prob1
I0816 10:11:01.306358 20528 net.cpp:283] Network initialization done.
I0816 10:11:01.306623 20528 net.cpp:761] Ignoring source layer data12
I0816 10:11:01.306632 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:01.306637 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:01.306641 20528 net.cpp:761] Ignoring source layer silence
I0816 10:11:01.306658 20528 net.cpp:761] Ignoring source layer conv4-1_conv4-1_0_split
I0816 10:11:01.306664 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:01.306668 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:01.306674 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:01.307085 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det2.prototxt
I0816 10:11:01.307099 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:01.307104 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:01.307276 20528 net.cpp:58] Initializing net from parameters: 
name: "RNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
  propagate_down: true
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
  propagate_down: true
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
  propagate_down: true
}
layer {
  name: "conv4"
  type: "InnerProduct"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5-1"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5-2"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv5-1"
  top: "prob1"
}
I0816 10:11:01.307355 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:01.307368 20528 net.cpp:100] Creating Layer input
I0816 10:11:01.307374 20528 net.cpp:408] input -> data
I0816 10:11:01.307413 20528 net.cpp:150] Setting up input
I0816 10:11:01.307423 20528 net.cpp:157] Top shape: 1 3 24 24 (1728)
I0816 10:11:01.307428 20528 net.cpp:165] Memory required for data: 6912
I0816 10:11:01.307435 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:01.307446 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:01.307451 20528 net.cpp:434] conv1 <- data
I0816 10:11:01.307459 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:01.309355 20528 net.cpp:150] Setting up conv1
I0816 10:11:01.309376 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:01.309381 20528 net.cpp:165] Memory required for data: 61120
I0816 10:11:01.309396 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:01.309406 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:01.309412 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:01.309418 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:01.309525 20528 net.cpp:150] Setting up prelu1
I0816 10:11:01.309533 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:01.309538 20528 net.cpp:165] Memory required for data: 115328
I0816 10:11:01.309547 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:01.309556 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:01.309561 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:01.309568 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:01.309610 20528 net.cpp:150] Setting up pool1
I0816 10:11:01.309619 20528 net.cpp:157] Top shape: 1 28 11 11 (3388)
I0816 10:11:01.309624 20528 net.cpp:165] Memory required for data: 128880
I0816 10:11:01.309629 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:01.309641 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:01.309646 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:01.309654 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:01.311794 20528 net.cpp:150] Setting up conv2
I0816 10:11:01.311812 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:01.311818 20528 net.cpp:165] Memory required for data: 144432
I0816 10:11:01.311831 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:01.311841 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:01.311846 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:01.311853 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:01.311969 20528 net.cpp:150] Setting up prelu2
I0816 10:11:01.311978 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:01.311985 20528 net.cpp:165] Memory required for data: 159984
I0816 10:11:01.311991 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:01.312000 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:01.312006 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:01.312013 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:01.312057 20528 net.cpp:150] Setting up pool2
I0816 10:11:01.312067 20528 net.cpp:157] Top shape: 1 48 4 4 (768)
I0816 10:11:01.312072 20528 net.cpp:165] Memory required for data: 163056
I0816 10:11:01.312077 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:01.312088 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:01.312094 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:01.312101 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:01.314966 20528 net.cpp:150] Setting up conv3
I0816 10:11:01.314985 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:01.314990 20528 net.cpp:165] Memory required for data: 165360
I0816 10:11:01.315001 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:01.315011 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:01.315016 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:01.315023 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:01.315129 20528 net.cpp:150] Setting up prelu3
I0816 10:11:01.315137 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:01.315142 20528 net.cpp:165] Memory required for data: 167664
I0816 10:11:01.315152 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:01.315161 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:01.315167 20528 net.cpp:434] conv4 <- conv3
I0816 10:11:01.315174 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:01.316540 20528 net.cpp:150] Setting up conv4
I0816 10:11:01.316557 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:01.316562 20528 net.cpp:165] Memory required for data: 168176
I0816 10:11:01.316572 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:01.316581 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:01.316586 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:01.316593 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:01.316684 20528 net.cpp:150] Setting up prelu4
I0816 10:11:01.316691 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:01.316697 20528 net.cpp:165] Memory required for data: 168688
I0816 10:11:01.316704 20528 layer_factory.hpp:77] Creating layer conv4_prelu4_0_split
I0816 10:11:01.316711 20528 net.cpp:100] Creating Layer conv4_prelu4_0_split
I0816 10:11:01.316716 20528 net.cpp:434] conv4_prelu4_0_split <- conv4
I0816 10:11:01.316723 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_0
I0816 10:11:01.316738 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_1
I0816 10:11:01.316782 20528 net.cpp:150] Setting up conv4_prelu4_0_split
I0816 10:11:01.316790 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:01.316797 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:01.316802 20528 net.cpp:165] Memory required for data: 169712
I0816 10:11:01.316807 20528 layer_factory.hpp:77] Creating layer conv5-1
I0816 10:11:01.316815 20528 net.cpp:100] Creating Layer conv5-1
I0816 10:11:01.316820 20528 net.cpp:434] conv5-1 <- conv4_prelu4_0_split_0
I0816 10:11:01.316828 20528 net.cpp:408] conv5-1 -> conv5-1
I0816 10:11:01.316934 20528 net.cpp:150] Setting up conv5-1
I0816 10:11:01.316943 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:01.316948 20528 net.cpp:165] Memory required for data: 169720
I0816 10:11:01.316956 20528 layer_factory.hpp:77] Creating layer conv5-2
I0816 10:11:01.316964 20528 net.cpp:100] Creating Layer conv5-2
I0816 10:11:01.316969 20528 net.cpp:434] conv5-2 <- conv4_prelu4_0_split_1
I0816 10:11:01.316977 20528 net.cpp:408] conv5-2 -> conv5-2
I0816 10:11:01.317091 20528 net.cpp:150] Setting up conv5-2
I0816 10:11:01.317101 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:01.317106 20528 net.cpp:165] Memory required for data: 169736
I0816 10:11:01.317119 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:01.317127 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:01.317133 20528 net.cpp:434] prob1 <- conv5-1
I0816 10:11:01.317139 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:01.317894 20528 net.cpp:150] Setting up prob1
I0816 10:11:01.317912 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:01.317917 20528 net.cpp:165] Memory required for data: 169744
I0816 10:11:01.317924 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:01.317929 20528 net.cpp:228] conv5-2 does not need backward computation.
I0816 10:11:01.317934 20528 net.cpp:228] conv5-1 does not need backward computation.
I0816 10:11:01.317940 20528 net.cpp:228] conv4_prelu4_0_split does not need backward computation.
I0816 10:11:01.317945 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:01.317950 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:01.317955 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:01.317960 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:01.317966 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:01.317971 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:01.317976 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:01.317981 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:01.317986 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:01.317991 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:01.317997 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:01.318001 20528 net.cpp:270] This network produces output conv5-2
I0816 10:11:01.318008 20528 net.cpp:270] This network produces output prob1
I0816 10:11:01.318022 20528 net.cpp:283] Network initialization done.
I0816 10:11:01.319176 20528 net.cpp:761] Ignoring source layer data24
I0816 10:11:01.319187 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:01.319192 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:01.319243 20528 net.cpp:761] Ignoring source layer conv5-1_conv5-1_0_split
I0816 10:11:01.319252 20528 net.cpp:761] Ignoring source layer conv5-3
I0816 10:11:01.319257 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:01.319260 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:01.319265 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:01.319270 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:01.319747 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det3.prototxt
I0816 10:11:01.319762 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:01.319767 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:01.319958 20528 net.cpp:58] Initializing net from parameters: 
name: "ONet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 48
      dim: 48
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6-1"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-2"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-3"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv6-1"
  top: "prob1"
}
I0816 10:11:01.320046 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:01.320057 20528 net.cpp:100] Creating Layer input
I0816 10:11:01.320065 20528 net.cpp:408] input -> data
I0816 10:11:01.320107 20528 net.cpp:150] Setting up input
I0816 10:11:01.320118 20528 net.cpp:157] Top shape: 1 3 48 48 (6912)
I0816 10:11:01.320123 20528 net.cpp:165] Memory required for data: 27648
I0816 10:11:01.320129 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:01.320140 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:01.320147 20528 net.cpp:434] conv1 <- data
I0816 10:11:01.320153 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:01.322034 20528 net.cpp:150] Setting up conv1
I0816 10:11:01.322054 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:01.322059 20528 net.cpp:165] Memory required for data: 298496
I0816 10:11:01.322074 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:01.322084 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:01.322089 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:01.322096 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:01.322229 20528 net.cpp:150] Setting up prelu1
I0816 10:11:01.322247 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:01.322252 20528 net.cpp:165] Memory required for data: 569344
I0816 10:11:01.322262 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:01.322270 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:01.322275 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:01.322283 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:01.322325 20528 net.cpp:150] Setting up pool1
I0816 10:11:01.322335 20528 net.cpp:157] Top shape: 1 32 23 23 (16928)
I0816 10:11:01.322340 20528 net.cpp:165] Memory required for data: 637056
I0816 10:11:01.322345 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:01.322355 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:01.322361 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:01.322368 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:01.325803 20528 net.cpp:150] Setting up conv2
I0816 10:11:01.325824 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:01.325829 20528 net.cpp:165] Memory required for data: 749952
I0816 10:11:01.325841 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:01.325850 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:01.325856 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:01.325865 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:01.325978 20528 net.cpp:150] Setting up prelu2
I0816 10:11:01.325989 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:01.325994 20528 net.cpp:165] Memory required for data: 862848
I0816 10:11:01.326001 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:01.326009 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:01.326014 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:01.326021 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:01.326064 20528 net.cpp:150] Setting up pool2
I0816 10:11:01.326073 20528 net.cpp:157] Top shape: 1 64 10 10 (6400)
I0816 10:11:01.326078 20528 net.cpp:165] Memory required for data: 888448
I0816 10:11:01.326083 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:01.326093 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:01.326099 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:01.326107 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:01.327669 20528 net.cpp:150] Setting up conv3
I0816 10:11:01.327687 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:01.327692 20528 net.cpp:165] Memory required for data: 904832
I0816 10:11:01.327702 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:01.327713 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:01.327718 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:01.327725 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:01.327847 20528 net.cpp:150] Setting up prelu3
I0816 10:11:01.327857 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:01.327862 20528 net.cpp:165] Memory required for data: 921216
I0816 10:11:01.327872 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:01.327881 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:01.327886 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:01.327893 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:01.327936 20528 net.cpp:150] Setting up pool3
I0816 10:11:01.327945 20528 net.cpp:157] Top shape: 1 64 4 4 (1024)
I0816 10:11:01.327950 20528 net.cpp:165] Memory required for data: 925312
I0816 10:11:01.327955 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:01.327965 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:01.327970 20528 net.cpp:434] conv4 <- pool3
I0816 10:11:01.327977 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:01.330009 20528 net.cpp:150] Setting up conv4
I0816 10:11:01.330027 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:01.330032 20528 net.cpp:165] Memory required for data: 929920
I0816 10:11:01.330042 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:01.330051 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:01.330057 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:01.330065 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:01.330164 20528 net.cpp:150] Setting up prelu4
I0816 10:11:01.330173 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:01.330184 20528 net.cpp:165] Memory required for data: 934528
I0816 10:11:01.330193 20528 layer_factory.hpp:77] Creating layer conv5
I0816 10:11:01.330201 20528 net.cpp:100] Creating Layer conv5
I0816 10:11:01.330206 20528 net.cpp:434] conv5 <- conv4
I0816 10:11:01.330214 20528 net.cpp:408] conv5 -> conv5
I0816 10:11:01.332918 20528 net.cpp:150] Setting up conv5
I0816 10:11:01.332937 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:01.332942 20528 net.cpp:165] Memory required for data: 935552
I0816 10:11:01.332952 20528 layer_factory.hpp:77] Creating layer drop5
I0816 10:11:01.332964 20528 net.cpp:100] Creating Layer drop5
I0816 10:11:01.332970 20528 net.cpp:434] drop5 <- conv5
I0816 10:11:01.332978 20528 net.cpp:395] drop5 -> conv5 (in-place)
I0816 10:11:01.333014 20528 net.cpp:150] Setting up drop5
I0816 10:11:01.333022 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:01.333027 20528 net.cpp:165] Memory required for data: 936576
I0816 10:11:01.333032 20528 layer_factory.hpp:77] Creating layer prelu5
I0816 10:11:01.333039 20528 net.cpp:100] Creating Layer prelu5
I0816 10:11:01.333045 20528 net.cpp:434] prelu5 <- conv5
I0816 10:11:01.333051 20528 net.cpp:395] prelu5 -> conv5 (in-place)
I0816 10:11:01.333139 20528 net.cpp:150] Setting up prelu5
I0816 10:11:01.333148 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:01.333153 20528 net.cpp:165] Memory required for data: 937600
I0816 10:11:01.333160 20528 layer_factory.hpp:77] Creating layer conv5_prelu5_0_split
I0816 10:11:01.333168 20528 net.cpp:100] Creating Layer conv5_prelu5_0_split
I0816 10:11:01.333173 20528 net.cpp:434] conv5_prelu5_0_split <- conv5
I0816 10:11:01.333179 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_0
I0816 10:11:01.333187 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_1
I0816 10:11:01.333195 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_2
I0816 10:11:01.333248 20528 net.cpp:150] Setting up conv5_prelu5_0_split
I0816 10:11:01.333256 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:01.333262 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:01.333267 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:01.333272 20528 net.cpp:165] Memory required for data: 940672
I0816 10:11:01.333277 20528 layer_factory.hpp:77] Creating layer conv6-1
I0816 10:11:01.333287 20528 net.cpp:100] Creating Layer conv6-1
I0816 10:11:01.333293 20528 net.cpp:434] conv6-1 <- conv5_prelu5_0_split_0
I0816 10:11:01.333302 20528 net.cpp:408] conv6-1 -> conv6-1
I0816 10:11:01.333418 20528 net.cpp:150] Setting up conv6-1
I0816 10:11:01.333427 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:01.333432 20528 net.cpp:165] Memory required for data: 940680
I0816 10:11:01.333444 20528 layer_factory.hpp:77] Creating layer conv6-2
I0816 10:11:01.333452 20528 net.cpp:100] Creating Layer conv6-2
I0816 10:11:01.333458 20528 net.cpp:434] conv6-2 <- conv5_prelu5_0_split_1
I0816 10:11:01.333465 20528 net.cpp:408] conv6-2 -> conv6-2
I0816 10:11:01.333578 20528 net.cpp:150] Setting up conv6-2
I0816 10:11:01.333586 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:01.333591 20528 net.cpp:165] Memory required for data: 940696
I0816 10:11:01.333600 20528 layer_factory.hpp:77] Creating layer conv6-3
I0816 10:11:01.333607 20528 net.cpp:100] Creating Layer conv6-3
I0816 10:11:01.333612 20528 net.cpp:434] conv6-3 <- conv5_prelu5_0_split_2
I0816 10:11:01.333619 20528 net.cpp:408] conv6-3 -> conv6-3
I0816 10:11:01.333745 20528 net.cpp:150] Setting up conv6-3
I0816 10:11:01.333755 20528 net.cpp:157] Top shape: 1 10 (10)
I0816 10:11:01.333760 20528 net.cpp:165] Memory required for data: 940736
I0816 10:11:01.333767 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:01.333775 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:01.333781 20528 net.cpp:434] prob1 <- conv6-1
I0816 10:11:01.333787 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:01.336769 20528 net.cpp:150] Setting up prob1
I0816 10:11:01.336786 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:01.336791 20528 net.cpp:165] Memory required for data: 940744
I0816 10:11:01.336804 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:01.336809 20528 net.cpp:228] conv6-3 does not need backward computation.
I0816 10:11:01.336815 20528 net.cpp:228] conv6-2 does not need backward computation.
I0816 10:11:01.336820 20528 net.cpp:228] conv6-1 does not need backward computation.
I0816 10:11:01.336825 20528 net.cpp:228] conv5_prelu5_0_split does not need backward computation.
I0816 10:11:01.336830 20528 net.cpp:228] prelu5 does not need backward computation.
I0816 10:11:01.336835 20528 net.cpp:228] drop5 does not need backward computation.
I0816 10:11:01.336840 20528 net.cpp:228] conv5 does not need backward computation.
I0816 10:11:01.336845 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:01.336850 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:01.336855 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:01.336860 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:01.336865 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:01.336870 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:01.336876 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:01.336881 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:01.336886 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:01.336891 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:01.336896 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:01.336901 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:01.336906 20528 net.cpp:270] This network produces output conv6-2
I0816 10:11:01.336912 20528 net.cpp:270] This network produces output conv6-3
I0816 10:11:01.336917 20528 net.cpp:270] This network produces output prob1
I0816 10:11:01.336933 20528 net.cpp:283] Network initialization done.
I0816 10:11:01.341226 20528 net.cpp:761] Ignoring source layer data48
I0816 10:11:01.341238 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:01.341243 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:01.341440 20528 net.cpp:761] Ignoring source layer conv6-1_conv6-1_0_split
I0816 10:11:01.341451 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:01.341455 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:01.341460 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:01.341465 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:01.343081 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/face_deploy.prototxt
I0816 10:11:01.343102 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:01.343108 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:01.343688 20528 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 96
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "PReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1b"
  type: "PReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1b"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1b"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1b"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "res2_2"
  type: "Eltwise"
  bottom: "pool1b"
  bottom: "conv2_2"
  top: "res2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "res2_2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "res3_2"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "conv3_2"
  top: "res3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "res3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "res3_4"
  type: "Eltwise"
  bottom: "res3_2"
  bottom: "conv3_4"
  top: "res3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "res3_4"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "res4_2"
  type: "Eltwise"
  bottom: "pool3"
  bottom: "conv4_2"
  top: "res4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "res4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_4"
  type: "PReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "res4_4"
  type: "Eltwise"
  bottom: "res4_2"
  bottom: "conv4_4"
  top: "res4_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_5"
  type: "Convolution"
  bottom: "res4_4"
  top: "conv4_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_5"
  type: "PReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_6"
  type: "PReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
layer {
  name: "res4_6"
  type: "Eltwise"
  bottom: "res4_4"
  bottom: "conv4_6"
  top: "res4_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_7"
  type: "Convolution"
  bottom: "res4_6"
  top: "conv4_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_7"
  type: "PReLU"
  bottom: "conv4_7"
  top: "conv4_7"
}
layer {
  name: "conv4_8"
  type: "Convolution"
  bottom: "conv4_7"
  top: "conv4_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_8"
  type: "PReLU"
  bottom: "conv4_8"
  top: "conv4_8"
}
layer {
  name: "res4_8"
  type: "Eltwise"
  bottom: "res4_6"
  bottom: "conv4_8"
  top: "res4_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_9"
  type: "Convolution"
  bottom: "res4_8"
  top: "conv4_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_9"
  type: "PReLU"
  bottom: "conv4_9"
  top: "conv4_9"
}
layer {
  name: "conv4_10"
  type: "Convolution"
  bottom: "conv4_9"
  top: "conv4_10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_10"
  type: "PReLU"
  bottom: "conv4_10"
  top: "conv4_10"
}
layer {
  name: "res4_10"
  type: "Eltwise"
  bottom: "res4_8"
  bottom: "conv4_10"
  top: "res4_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "res4_10"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "PReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "PReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "res5_2"
  type: "Eltwise"
  bottom: "pool4"
  bottom: "conv5_2"
  top: "res5_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "res5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "PReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_4"
  type: "PReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "res5_4"
  type: "Eltwise"
  bottom: "res5_2"
  bottom: "conv5_4"
  top: "res5_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_5"
  type: "Convolution"
  bottom: "res5_4"
  top: "conv5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_5"
  type: "PReLU"
  bottom: "conv5_5"
  top: "conv5_5"
}
layer {
  name: "conv5_6"
  type: "Convolution"
  bottom: "conv5_5"
  top: "conv5_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_6"
  type: "PReLU"
  bottom: "conv5_6"
  top: "conv5_6"
}
layer {
  name: "res5_6"
  type: "Eltwise"
  bottom: "res5_4"
  bottom: "conv5_6"
  top: "res5_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res5_6"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
I0816 10:11:01.344055 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:01.344069 20528 net.cpp:100] Creating Layer input
I0816 10:11:01.344076 20528 net.cpp:408] input -> data
I0816 10:11:01.344125 20528 net.cpp:150] Setting up input
I0816 10:11:01.344136 20528 net.cpp:157] Top shape: 1 3 112 96 (32256)
I0816 10:11:01.344141 20528 net.cpp:165] Memory required for data: 129024
I0816 10:11:01.344147 20528 layer_factory.hpp:77] Creating layer conv1a
I0816 10:11:01.344158 20528 net.cpp:100] Creating Layer conv1a
I0816 10:11:01.344164 20528 net.cpp:434] conv1a <- data
I0816 10:11:01.344172 20528 net.cpp:408] conv1a -> conv1a
I0816 10:11:01.345870 20528 net.cpp:150] Setting up conv1a
I0816 10:11:01.345890 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:01.345894 20528 net.cpp:165] Memory required for data: 1452544
I0816 10:11:01.345911 20528 layer_factory.hpp:77] Creating layer relu1a
I0816 10:11:01.345921 20528 net.cpp:100] Creating Layer relu1a
I0816 10:11:01.345927 20528 net.cpp:434] relu1a <- conv1a
I0816 10:11:01.345934 20528 net.cpp:395] relu1a -> conv1a (in-place)
I0816 10:11:01.346866 20528 net.cpp:150] Setting up relu1a
I0816 10:11:01.346884 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:01.346889 20528 net.cpp:165] Memory required for data: 2776064
I0816 10:11:01.346899 20528 layer_factory.hpp:77] Creating layer conv1b
I0816 10:11:01.346911 20528 net.cpp:100] Creating Layer conv1b
I0816 10:11:01.346917 20528 net.cpp:434] conv1b <- conv1a
I0816 10:11:01.346925 20528 net.cpp:408] conv1b -> conv1b
I0816 10:11:01.348693 20528 net.cpp:150] Setting up conv1b
I0816 10:11:01.348714 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:01.348721 20528 net.cpp:165] Memory required for data: 5319680
I0816 10:11:01.348740 20528 layer_factory.hpp:77] Creating layer relu1b
I0816 10:11:01.348752 20528 net.cpp:100] Creating Layer relu1b
I0816 10:11:01.348757 20528 net.cpp:434] relu1b <- conv1b
I0816 10:11:01.348774 20528 net.cpp:395] relu1b -> conv1b (in-place)
I0816 10:11:01.350404 20528 net.cpp:150] Setting up relu1b
I0816 10:11:01.350420 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:01.350425 20528 net.cpp:165] Memory required for data: 7863296
I0816 10:11:01.350433 20528 layer_factory.hpp:77] Creating layer pool1b
I0816 10:11:01.350442 20528 net.cpp:100] Creating Layer pool1b
I0816 10:11:01.350448 20528 net.cpp:434] pool1b <- conv1b
I0816 10:11:01.350457 20528 net.cpp:408] pool1b -> pool1b
I0816 10:11:01.350507 20528 net.cpp:150] Setting up pool1b
I0816 10:11:01.350517 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.350522 20528 net.cpp:165] Memory required for data: 8499200
I0816 10:11:01.350527 20528 layer_factory.hpp:77] Creating layer pool1b_pool1b_0_split
I0816 10:11:01.350536 20528 net.cpp:100] Creating Layer pool1b_pool1b_0_split
I0816 10:11:01.350541 20528 net.cpp:434] pool1b_pool1b_0_split <- pool1b
I0816 10:11:01.350548 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_0
I0816 10:11:01.350558 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_1
I0816 10:11:01.350601 20528 net.cpp:150] Setting up pool1b_pool1b_0_split
I0816 10:11:01.350610 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.350616 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.350621 20528 net.cpp:165] Memory required for data: 9771008
I0816 10:11:01.350626 20528 layer_factory.hpp:77] Creating layer conv2_1
I0816 10:11:01.350636 20528 net.cpp:100] Creating Layer conv2_1
I0816 10:11:01.350642 20528 net.cpp:434] conv2_1 <- pool1b_pool1b_0_split_0
I0816 10:11:01.350652 20528 net.cpp:408] conv2_1 -> conv2_1
I0816 10:11:01.354094 20528 net.cpp:150] Setting up conv2_1
I0816 10:11:01.354111 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.354117 20528 net.cpp:165] Memory required for data: 10406912
I0816 10:11:01.354127 20528 layer_factory.hpp:77] Creating layer relu2_1
I0816 10:11:01.354137 20528 net.cpp:100] Creating Layer relu2_1
I0816 10:11:01.354145 20528 net.cpp:434] relu2_1 <- conv2_1
I0816 10:11:01.354151 20528 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0816 10:11:01.355051 20528 net.cpp:150] Setting up relu2_1
I0816 10:11:01.355067 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.355072 20528 net.cpp:165] Memory required for data: 11042816
I0816 10:11:01.355084 20528 layer_factory.hpp:77] Creating layer conv2_2
I0816 10:11:01.355096 20528 net.cpp:100] Creating Layer conv2_2
I0816 10:11:01.355101 20528 net.cpp:434] conv2_2 <- conv2_1
I0816 10:11:01.355110 20528 net.cpp:408] conv2_2 -> conv2_2
I0816 10:11:01.358505 20528 net.cpp:150] Setting up conv2_2
I0816 10:11:01.358523 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.358530 20528 net.cpp:165] Memory required for data: 11678720
I0816 10:11:01.358539 20528 layer_factory.hpp:77] Creating layer relu2_2
I0816 10:11:01.358548 20528 net.cpp:100] Creating Layer relu2_2
I0816 10:11:01.358554 20528 net.cpp:434] relu2_2 <- conv2_2
I0816 10:11:01.358561 20528 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0816 10:11:01.359480 20528 net.cpp:150] Setting up relu2_2
I0816 10:11:01.359498 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.359503 20528 net.cpp:165] Memory required for data: 12314624
I0816 10:11:01.359510 20528 layer_factory.hpp:77] Creating layer res2_2
I0816 10:11:01.359522 20528 net.cpp:100] Creating Layer res2_2
I0816 10:11:01.359529 20528 net.cpp:434] res2_2 <- pool1b_pool1b_0_split_1
I0816 10:11:01.359535 20528 net.cpp:434] res2_2 <- conv2_2
I0816 10:11:01.359544 20528 net.cpp:408] res2_2 -> res2_2
I0816 10:11:01.359594 20528 net.cpp:150] Setting up res2_2
I0816 10:11:01.359604 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:01.359609 20528 net.cpp:165] Memory required for data: 12950528
I0816 10:11:01.359614 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:01.359625 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:01.359632 20528 net.cpp:434] conv2 <- res2_2
I0816 10:11:01.359639 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:01.361759 20528 net.cpp:150] Setting up conv2
I0816 10:11:01.361778 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:01.361783 20528 net.cpp:165] Memory required for data: 14121984
I0816 10:11:01.361793 20528 layer_factory.hpp:77] Creating layer relu2
I0816 10:11:01.361802 20528 net.cpp:100] Creating Layer relu2
I0816 10:11:01.361807 20528 net.cpp:434] relu2 <- conv2
I0816 10:11:01.361814 20528 net.cpp:395] relu2 -> conv2 (in-place)
I0816 10:11:01.362838 20528 net.cpp:150] Setting up relu2
I0816 10:11:01.362854 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:01.362859 20528 net.cpp:165] Memory required for data: 15293440
I0816 10:11:01.362867 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:01.362877 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:01.362882 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:01.362890 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:01.362939 20528 net.cpp:150] Setting up pool2
I0816 10:11:01.362948 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.362953 20528 net.cpp:165] Memory required for data: 15586304
I0816 10:11:01.362958 20528 layer_factory.hpp:77] Creating layer pool2_pool2_0_split
I0816 10:11:01.362965 20528 net.cpp:100] Creating Layer pool2_pool2_0_split
I0816 10:11:01.362972 20528 net.cpp:434] pool2_pool2_0_split <- pool2
I0816 10:11:01.362977 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_0
I0816 10:11:01.362985 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_1
I0816 10:11:01.363025 20528 net.cpp:150] Setting up pool2_pool2_0_split
I0816 10:11:01.363034 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.363039 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.363044 20528 net.cpp:165] Memory required for data: 16172032
I0816 10:11:01.363049 20528 layer_factory.hpp:77] Creating layer conv3_1
I0816 10:11:01.363061 20528 net.cpp:100] Creating Layer conv3_1
I0816 10:11:01.363067 20528 net.cpp:434] conv3_1 <- pool2_pool2_0_split_0
I0816 10:11:01.363075 20528 net.cpp:408] conv3_1 -> conv3_1
I0816 10:11:01.370679 20528 net.cpp:150] Setting up conv3_1
I0816 10:11:01.370699 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.370705 20528 net.cpp:165] Memory required for data: 16464896
I0816 10:11:01.370720 20528 layer_factory.hpp:77] Creating layer relu3_1
I0816 10:11:01.370735 20528 net.cpp:100] Creating Layer relu3_1
I0816 10:11:01.370743 20528 net.cpp:434] relu3_1 <- conv3_1
I0816 10:11:01.370750 20528 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0816 10:11:01.370896 20528 net.cpp:150] Setting up relu3_1
I0816 10:11:01.370906 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.370911 20528 net.cpp:165] Memory required for data: 16757760
I0816 10:11:01.370919 20528 layer_factory.hpp:77] Creating layer conv3_2
I0816 10:11:01.370930 20528 net.cpp:100] Creating Layer conv3_2
I0816 10:11:01.370936 20528 net.cpp:434] conv3_2 <- conv3_1
I0816 10:11:01.370945 20528 net.cpp:408] conv3_2 -> conv3_2
I0816 10:11:01.378908 20528 net.cpp:150] Setting up conv3_2
I0816 10:11:01.378929 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.378935 20528 net.cpp:165] Memory required for data: 17050624
I0816 10:11:01.378947 20528 layer_factory.hpp:77] Creating layer relu3_2
I0816 10:11:01.378957 20528 net.cpp:100] Creating Layer relu3_2
I0816 10:11:01.378962 20528 net.cpp:434] relu3_2 <- conv3_2
I0816 10:11:01.378970 20528 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0816 10:11:01.379118 20528 net.cpp:150] Setting up relu3_2
I0816 10:11:01.379129 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.379134 20528 net.cpp:165] Memory required for data: 17343488
I0816 10:11:01.379142 20528 layer_factory.hpp:77] Creating layer res3_2
I0816 10:11:01.379150 20528 net.cpp:100] Creating Layer res3_2
I0816 10:11:01.379156 20528 net.cpp:434] res3_2 <- pool2_pool2_0_split_1
I0816 10:11:01.379163 20528 net.cpp:434] res3_2 <- conv3_2
I0816 10:11:01.379170 20528 net.cpp:408] res3_2 -> res3_2
I0816 10:11:01.379204 20528 net.cpp:150] Setting up res3_2
I0816 10:11:01.379220 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.379225 20528 net.cpp:165] Memory required for data: 17636352
I0816 10:11:01.379230 20528 layer_factory.hpp:77] Creating layer res3_2_res3_2_0_split
I0816 10:11:01.379238 20528 net.cpp:100] Creating Layer res3_2_res3_2_0_split
I0816 10:11:01.379243 20528 net.cpp:434] res3_2_res3_2_0_split <- res3_2
I0816 10:11:01.379251 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_0
I0816 10:11:01.379262 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_1
I0816 10:11:01.379305 20528 net.cpp:150] Setting up res3_2_res3_2_0_split
I0816 10:11:01.379315 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.379321 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.379326 20528 net.cpp:165] Memory required for data: 18222080
I0816 10:11:01.379331 20528 layer_factory.hpp:77] Creating layer conv3_3
I0816 10:11:01.379343 20528 net.cpp:100] Creating Layer conv3_3
I0816 10:11:01.379349 20528 net.cpp:434] conv3_3 <- res3_2_res3_2_0_split_0
I0816 10:11:01.379359 20528 net.cpp:408] conv3_3 -> conv3_3
I0816 10:11:01.387646 20528 net.cpp:150] Setting up conv3_3
I0816 10:11:01.387666 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.387672 20528 net.cpp:165] Memory required for data: 18514944
I0816 10:11:01.387682 20528 layer_factory.hpp:77] Creating layer relu3_3
I0816 10:11:01.387692 20528 net.cpp:100] Creating Layer relu3_3
I0816 10:11:01.387698 20528 net.cpp:434] relu3_3 <- conv3_3
I0816 10:11:01.387707 20528 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0816 10:11:01.387866 20528 net.cpp:150] Setting up relu3_3
I0816 10:11:01.387878 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.387883 20528 net.cpp:165] Memory required for data: 18807808
I0816 10:11:01.387890 20528 layer_factory.hpp:77] Creating layer conv3_4
I0816 10:11:01.387903 20528 net.cpp:100] Creating Layer conv3_4
I0816 10:11:01.387909 20528 net.cpp:434] conv3_4 <- conv3_3
I0816 10:11:01.387918 20528 net.cpp:408] conv3_4 -> conv3_4
I0816 10:11:01.396217 20528 net.cpp:150] Setting up conv3_4
I0816 10:11:01.396237 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.396244 20528 net.cpp:165] Memory required for data: 19100672
I0816 10:11:01.396253 20528 layer_factory.hpp:77] Creating layer relu3_4
I0816 10:11:01.396263 20528 net.cpp:100] Creating Layer relu3_4
I0816 10:11:01.396270 20528 net.cpp:434] relu3_4 <- conv3_4
I0816 10:11:01.396278 20528 net.cpp:395] relu3_4 -> conv3_4 (in-place)
I0816 10:11:01.396431 20528 net.cpp:150] Setting up relu3_4
I0816 10:11:01.396441 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.396447 20528 net.cpp:165] Memory required for data: 19393536
I0816 10:11:01.396455 20528 layer_factory.hpp:77] Creating layer res3_4
I0816 10:11:01.396464 20528 net.cpp:100] Creating Layer res3_4
I0816 10:11:01.396471 20528 net.cpp:434] res3_4 <- res3_2_res3_2_0_split_1
I0816 10:11:01.396477 20528 net.cpp:434] res3_4 <- conv3_4
I0816 10:11:01.396486 20528 net.cpp:408] res3_4 -> res3_4
I0816 10:11:01.396518 20528 net.cpp:150] Setting up res3_4
I0816 10:11:01.396528 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:01.396533 20528 net.cpp:165] Memory required for data: 19686400
I0816 10:11:01.396538 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:01.396550 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:01.396556 20528 net.cpp:434] conv3 <- res3_4
I0816 10:11:01.396565 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:01.407690 20528 net.cpp:150] Setting up conv3
I0816 10:11:01.407709 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:01.407716 20528 net.cpp:165] Memory required for data: 20177920
I0816 10:11:01.407726 20528 layer_factory.hpp:77] Creating layer relu3
I0816 10:11:01.407742 20528 net.cpp:100] Creating Layer relu3
I0816 10:11:01.407749 20528 net.cpp:434] relu3 <- conv3
I0816 10:11:01.407757 20528 net.cpp:395] relu3 -> conv3 (in-place)
I0816 10:11:01.408509 20528 net.cpp:150] Setting up relu3
I0816 10:11:01.408524 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:01.408535 20528 net.cpp:165] Memory required for data: 20669440
I0816 10:11:01.408543 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:01.408555 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:01.408560 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:01.408568 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:01.408622 20528 net.cpp:150] Setting up pool3
I0816 10:11:01.408630 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.408635 20528 net.cpp:165] Memory required for data: 20792320
I0816 10:11:01.408640 20528 layer_factory.hpp:77] Creating layer pool3_pool3_0_split
I0816 10:11:01.408649 20528 net.cpp:100] Creating Layer pool3_pool3_0_split
I0816 10:11:01.408654 20528 net.cpp:434] pool3_pool3_0_split <- pool3
I0816 10:11:01.408663 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_0
I0816 10:11:01.408670 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_1
I0816 10:11:01.408715 20528 net.cpp:150] Setting up pool3_pool3_0_split
I0816 10:11:01.408723 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.408737 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.408743 20528 net.cpp:165] Memory required for data: 21038080
I0816 10:11:01.408749 20528 layer_factory.hpp:77] Creating layer conv4_1
I0816 10:11:01.408761 20528 net.cpp:100] Creating Layer conv4_1
I0816 10:11:01.408766 20528 net.cpp:434] conv4_1 <- pool3_pool3_0_split_0
I0816 10:11:01.408776 20528 net.cpp:408] conv4_1 -> conv4_1
I0816 10:11:01.432696 20528 net.cpp:150] Setting up conv4_1
I0816 10:11:01.432716 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.432721 20528 net.cpp:165] Memory required for data: 21160960
I0816 10:11:01.432739 20528 layer_factory.hpp:77] Creating layer relu4_1
I0816 10:11:01.432754 20528 net.cpp:100] Creating Layer relu4_1
I0816 10:11:01.432760 20528 net.cpp:434] relu4_1 <- conv4_1
I0816 10:11:01.432770 20528 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0816 10:11:01.432915 20528 net.cpp:150] Setting up relu4_1
I0816 10:11:01.432925 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.432930 20528 net.cpp:165] Memory required for data: 21283840
I0816 10:11:01.432945 20528 layer_factory.hpp:77] Creating layer conv4_2
I0816 10:11:01.432958 20528 net.cpp:100] Creating Layer conv4_2
I0816 10:11:01.432965 20528 net.cpp:434] conv4_2 <- conv4_1
I0816 10:11:01.432973 20528 net.cpp:408] conv4_2 -> conv4_2
I0816 10:11:01.457151 20528 net.cpp:150] Setting up conv4_2
I0816 10:11:01.457171 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.457176 20528 net.cpp:165] Memory required for data: 21406720
I0816 10:11:01.457187 20528 layer_factory.hpp:77] Creating layer relu4_2
I0816 10:11:01.457197 20528 net.cpp:100] Creating Layer relu4_2
I0816 10:11:01.457203 20528 net.cpp:434] relu4_2 <- conv4_2
I0816 10:11:01.457212 20528 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0816 10:11:01.457938 20528 net.cpp:150] Setting up relu4_2
I0816 10:11:01.457954 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.457960 20528 net.cpp:165] Memory required for data: 21529600
I0816 10:11:01.457968 20528 layer_factory.hpp:77] Creating layer res4_2
I0816 10:11:01.457978 20528 net.cpp:100] Creating Layer res4_2
I0816 10:11:01.457984 20528 net.cpp:434] res4_2 <- pool3_pool3_0_split_1
I0816 10:11:01.457991 20528 net.cpp:434] res4_2 <- conv4_2
I0816 10:11:01.457999 20528 net.cpp:408] res4_2 -> res4_2
I0816 10:11:01.458036 20528 net.cpp:150] Setting up res4_2
I0816 10:11:01.458045 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.458050 20528 net.cpp:165] Memory required for data: 21652480
I0816 10:11:01.458055 20528 layer_factory.hpp:77] Creating layer res4_2_res4_2_0_split
I0816 10:11:01.458062 20528 net.cpp:100] Creating Layer res4_2_res4_2_0_split
I0816 10:11:01.458068 20528 net.cpp:434] res4_2_res4_2_0_split <- res4_2
I0816 10:11:01.458076 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_0
I0816 10:11:01.458084 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_1
I0816 10:11:01.458135 20528 net.cpp:150] Setting up res4_2_res4_2_0_split
I0816 10:11:01.458144 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.458151 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.458156 20528 net.cpp:165] Memory required for data: 21898240
I0816 10:11:01.458161 20528 layer_factory.hpp:77] Creating layer conv4_3
I0816 10:11:01.458174 20528 net.cpp:100] Creating Layer conv4_3
I0816 10:11:01.458179 20528 net.cpp:434] conv4_3 <- res4_2_res4_2_0_split_0
I0816 10:11:01.458189 20528 net.cpp:408] conv4_3 -> conv4_3
I0816 10:11:01.482480 20528 net.cpp:150] Setting up conv4_3
I0816 10:11:01.482499 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.482506 20528 net.cpp:165] Memory required for data: 22021120
I0816 10:11:01.482516 20528 layer_factory.hpp:77] Creating layer relu4_3
I0816 10:11:01.482525 20528 net.cpp:100] Creating Layer relu4_3
I0816 10:11:01.482532 20528 net.cpp:434] relu4_3 <- conv4_3
I0816 10:11:01.482539 20528 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0816 10:11:01.482673 20528 net.cpp:150] Setting up relu4_3
I0816 10:11:01.482683 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.482688 20528 net.cpp:165] Memory required for data: 22144000
I0816 10:11:01.482697 20528 layer_factory.hpp:77] Creating layer conv4_4
I0816 10:11:01.482708 20528 net.cpp:100] Creating Layer conv4_4
I0816 10:11:01.482714 20528 net.cpp:434] conv4_4 <- conv4_3
I0816 10:11:01.482723 20528 net.cpp:408] conv4_4 -> conv4_4
I0816 10:11:01.507175 20528 net.cpp:150] Setting up conv4_4
I0816 10:11:01.507195 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.507201 20528 net.cpp:165] Memory required for data: 22266880
I0816 10:11:01.507211 20528 layer_factory.hpp:77] Creating layer relu4_4
I0816 10:11:01.507221 20528 net.cpp:100] Creating Layer relu4_4
I0816 10:11:01.507228 20528 net.cpp:434] relu4_4 <- conv4_4
I0816 10:11:01.507237 20528 net.cpp:395] relu4_4 -> conv4_4 (in-place)
I0816 10:11:01.507372 20528 net.cpp:150] Setting up relu4_4
I0816 10:11:01.507382 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.507387 20528 net.cpp:165] Memory required for data: 22389760
I0816 10:11:01.507395 20528 layer_factory.hpp:77] Creating layer res4_4
I0816 10:11:01.507403 20528 net.cpp:100] Creating Layer res4_4
I0816 10:11:01.507410 20528 net.cpp:434] res4_4 <- res4_2_res4_2_0_split_1
I0816 10:11:01.507416 20528 net.cpp:434] res4_4 <- conv4_4
I0816 10:11:01.507424 20528 net.cpp:408] res4_4 -> res4_4
I0816 10:11:01.507463 20528 net.cpp:150] Setting up res4_4
I0816 10:11:01.507473 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.507478 20528 net.cpp:165] Memory required for data: 22512640
I0816 10:11:01.507483 20528 layer_factory.hpp:77] Creating layer res4_4_res4_4_0_split
I0816 10:11:01.507491 20528 net.cpp:100] Creating Layer res4_4_res4_4_0_split
I0816 10:11:01.507498 20528 net.cpp:434] res4_4_res4_4_0_split <- res4_4
I0816 10:11:01.507504 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_0
I0816 10:11:01.507513 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_1
I0816 10:11:01.507557 20528 net.cpp:150] Setting up res4_4_res4_4_0_split
I0816 10:11:01.507566 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.507572 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.507577 20528 net.cpp:165] Memory required for data: 22758400
I0816 10:11:01.507582 20528 layer_factory.hpp:77] Creating layer conv4_5
I0816 10:11:01.507594 20528 net.cpp:100] Creating Layer conv4_5
I0816 10:11:01.507601 20528 net.cpp:434] conv4_5 <- res4_4_res4_4_0_split_0
I0816 10:11:01.507609 20528 net.cpp:408] conv4_5 -> conv4_5
I0816 10:11:01.532071 20528 net.cpp:150] Setting up conv4_5
I0816 10:11:01.532091 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.532097 20528 net.cpp:165] Memory required for data: 22881280
I0816 10:11:01.532107 20528 layer_factory.hpp:77] Creating layer relu4_5
I0816 10:11:01.532117 20528 net.cpp:100] Creating Layer relu4_5
I0816 10:11:01.532130 20528 net.cpp:434] relu4_5 <- conv4_5
I0816 10:11:01.532140 20528 net.cpp:395] relu4_5 -> conv4_5 (in-place)
I0816 10:11:01.532276 20528 net.cpp:150] Setting up relu4_5
I0816 10:11:01.532287 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.532292 20528 net.cpp:165] Memory required for data: 23004160
I0816 10:11:01.532299 20528 layer_factory.hpp:77] Creating layer conv4_6
I0816 10:11:01.532310 20528 net.cpp:100] Creating Layer conv4_6
I0816 10:11:01.532316 20528 net.cpp:434] conv4_6 <- conv4_5
I0816 10:11:01.532325 20528 net.cpp:408] conv4_6 -> conv4_6
I0816 10:11:01.556427 20528 net.cpp:150] Setting up conv4_6
I0816 10:11:01.556447 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.556452 20528 net.cpp:165] Memory required for data: 23127040
I0816 10:11:01.556463 20528 layer_factory.hpp:77] Creating layer relu4_6
I0816 10:11:01.556473 20528 net.cpp:100] Creating Layer relu4_6
I0816 10:11:01.556479 20528 net.cpp:434] relu4_6 <- conv4_6
I0816 10:11:01.556488 20528 net.cpp:395] relu4_6 -> conv4_6 (in-place)
I0816 10:11:01.556624 20528 net.cpp:150] Setting up relu4_6
I0816 10:11:01.556634 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.556639 20528 net.cpp:165] Memory required for data: 23249920
I0816 10:11:01.556646 20528 layer_factory.hpp:77] Creating layer res4_6
I0816 10:11:01.556656 20528 net.cpp:100] Creating Layer res4_6
I0816 10:11:01.556663 20528 net.cpp:434] res4_6 <- res4_4_res4_4_0_split_1
I0816 10:11:01.556669 20528 net.cpp:434] res4_6 <- conv4_6
I0816 10:11:01.556676 20528 net.cpp:408] res4_6 -> res4_6
I0816 10:11:01.556711 20528 net.cpp:150] Setting up res4_6
I0816 10:11:01.556720 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.556725 20528 net.cpp:165] Memory required for data: 23372800
I0816 10:11:01.556736 20528 layer_factory.hpp:77] Creating layer res4_6_res4_6_0_split
I0816 10:11:01.556746 20528 net.cpp:100] Creating Layer res4_6_res4_6_0_split
I0816 10:11:01.556751 20528 net.cpp:434] res4_6_res4_6_0_split <- res4_6
I0816 10:11:01.556759 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_0
I0816 10:11:01.556768 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_1
I0816 10:11:01.556815 20528 net.cpp:150] Setting up res4_6_res4_6_0_split
I0816 10:11:01.556824 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.556831 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.556836 20528 net.cpp:165] Memory required for data: 23618560
I0816 10:11:01.556841 20528 layer_factory.hpp:77] Creating layer conv4_7
I0816 10:11:01.556854 20528 net.cpp:100] Creating Layer conv4_7
I0816 10:11:01.556859 20528 net.cpp:434] conv4_7 <- res4_6_res4_6_0_split_0
I0816 10:11:01.556869 20528 net.cpp:408] conv4_7 -> conv4_7
I0816 10:11:01.581344 20528 net.cpp:150] Setting up conv4_7
I0816 10:11:01.581363 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.581369 20528 net.cpp:165] Memory required for data: 23741440
I0816 10:11:01.581379 20528 layer_factory.hpp:77] Creating layer relu4_7
I0816 10:11:01.581389 20528 net.cpp:100] Creating Layer relu4_7
I0816 10:11:01.581396 20528 net.cpp:434] relu4_7 <- conv4_7
I0816 10:11:01.581405 20528 net.cpp:395] relu4_7 -> conv4_7 (in-place)
I0816 10:11:01.581543 20528 net.cpp:150] Setting up relu4_7
I0816 10:11:01.581553 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.581558 20528 net.cpp:165] Memory required for data: 23864320
I0816 10:11:01.581565 20528 layer_factory.hpp:77] Creating layer conv4_8
I0816 10:11:01.581578 20528 net.cpp:100] Creating Layer conv4_8
I0816 10:11:01.581583 20528 net.cpp:434] conv4_8 <- conv4_7
I0816 10:11:01.581593 20528 net.cpp:408] conv4_8 -> conv4_8
I0816 10:11:01.606498 20528 net.cpp:150] Setting up conv4_8
I0816 10:11:01.606518 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.606524 20528 net.cpp:165] Memory required for data: 23987200
I0816 10:11:01.606534 20528 layer_factory.hpp:77] Creating layer relu4_8
I0816 10:11:01.606544 20528 net.cpp:100] Creating Layer relu4_8
I0816 10:11:01.606550 20528 net.cpp:434] relu4_8 <- conv4_8
I0816 10:11:01.606565 20528 net.cpp:395] relu4_8 -> conv4_8 (in-place)
I0816 10:11:01.606709 20528 net.cpp:150] Setting up relu4_8
I0816 10:11:01.606719 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.606724 20528 net.cpp:165] Memory required for data: 24110080
I0816 10:11:01.606739 20528 layer_factory.hpp:77] Creating layer res4_8
I0816 10:11:01.606750 20528 net.cpp:100] Creating Layer res4_8
I0816 10:11:01.606755 20528 net.cpp:434] res4_8 <- res4_6_res4_6_0_split_1
I0816 10:11:01.606762 20528 net.cpp:434] res4_8 <- conv4_8
I0816 10:11:01.606770 20528 net.cpp:408] res4_8 -> res4_8
I0816 10:11:01.606808 20528 net.cpp:150] Setting up res4_8
I0816 10:11:01.606817 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.606822 20528 net.cpp:165] Memory required for data: 24232960
I0816 10:11:01.606827 20528 layer_factory.hpp:77] Creating layer res4_8_res4_8_0_split
I0816 10:11:01.606835 20528 net.cpp:100] Creating Layer res4_8_res4_8_0_split
I0816 10:11:01.606840 20528 net.cpp:434] res4_8_res4_8_0_split <- res4_8
I0816 10:11:01.606848 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_0
I0816 10:11:01.606856 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_1
I0816 10:11:01.606904 20528 net.cpp:150] Setting up res4_8_res4_8_0_split
I0816 10:11:01.606912 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.606919 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.606923 20528 net.cpp:165] Memory required for data: 24478720
I0816 10:11:01.606928 20528 layer_factory.hpp:77] Creating layer conv4_9
I0816 10:11:01.606940 20528 net.cpp:100] Creating Layer conv4_9
I0816 10:11:01.606946 20528 net.cpp:434] conv4_9 <- res4_8_res4_8_0_split_0
I0816 10:11:01.606956 20528 net.cpp:408] conv4_9 -> conv4_9
I0816 10:11:01.631476 20528 net.cpp:150] Setting up conv4_9
I0816 10:11:01.631497 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.631502 20528 net.cpp:165] Memory required for data: 24601600
I0816 10:11:01.631513 20528 layer_factory.hpp:77] Creating layer relu4_9
I0816 10:11:01.631522 20528 net.cpp:100] Creating Layer relu4_9
I0816 10:11:01.631530 20528 net.cpp:434] relu4_9 <- conv4_9
I0816 10:11:01.631537 20528 net.cpp:395] relu4_9 -> conv4_9 (in-place)
I0816 10:11:01.631685 20528 net.cpp:150] Setting up relu4_9
I0816 10:11:01.631695 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.631700 20528 net.cpp:165] Memory required for data: 24724480
I0816 10:11:01.631706 20528 layer_factory.hpp:77] Creating layer conv4_10
I0816 10:11:01.631718 20528 net.cpp:100] Creating Layer conv4_10
I0816 10:11:01.631724 20528 net.cpp:434] conv4_10 <- conv4_9
I0816 10:11:01.631741 20528 net.cpp:408] conv4_10 -> conv4_10
I0816 10:11:01.656285 20528 net.cpp:150] Setting up conv4_10
I0816 10:11:01.656303 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.656309 20528 net.cpp:165] Memory required for data: 24847360
I0816 10:11:01.656321 20528 layer_factory.hpp:77] Creating layer relu4_10
I0816 10:11:01.656329 20528 net.cpp:100] Creating Layer relu4_10
I0816 10:11:01.656335 20528 net.cpp:434] relu4_10 <- conv4_10
I0816 10:11:01.656344 20528 net.cpp:395] relu4_10 -> conv4_10 (in-place)
I0816 10:11:01.657200 20528 net.cpp:150] Setting up relu4_10
I0816 10:11:01.657217 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.657222 20528 net.cpp:165] Memory required for data: 24970240
I0816 10:11:01.657230 20528 layer_factory.hpp:77] Creating layer res4_10
I0816 10:11:01.657239 20528 net.cpp:100] Creating Layer res4_10
I0816 10:11:01.657246 20528 net.cpp:434] res4_10 <- res4_8_res4_8_0_split_1
I0816 10:11:01.657253 20528 net.cpp:434] res4_10 <- conv4_10
I0816 10:11:01.657261 20528 net.cpp:408] res4_10 -> res4_10
I0816 10:11:01.657300 20528 net.cpp:150] Setting up res4_10
I0816 10:11:01.657310 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:01.657315 20528 net.cpp:165] Memory required for data: 25093120
I0816 10:11:01.657320 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:01.657337 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:01.657343 20528 net.cpp:434] conv4 <- res4_10
I0816 10:11:01.657352 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:01.668210 20528 net.cpp:150] Setting up conv4
I0816 10:11:01.668229 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:01.668236 20528 net.cpp:165] Memory required for data: 25256960
I0816 10:11:01.668246 20528 layer_factory.hpp:77] Creating layer relu4
I0816 10:11:01.668256 20528 net.cpp:100] Creating Layer relu4
I0816 10:11:01.668262 20528 net.cpp:434] relu4 <- conv4
I0816 10:11:01.668270 20528 net.cpp:395] relu4 -> conv4 (in-place)
I0816 10:11:01.668428 20528 net.cpp:150] Setting up relu4
I0816 10:11:01.668438 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:01.668443 20528 net.cpp:165] Memory required for data: 25420800
I0816 10:11:01.668450 20528 layer_factory.hpp:77] Creating layer pool4
I0816 10:11:01.668462 20528 net.cpp:100] Creating Layer pool4
I0816 10:11:01.668467 20528 net.cpp:434] pool4 <- conv4
I0816 10:11:01.668475 20528 net.cpp:408] pool4 -> pool4
I0816 10:11:01.668534 20528 net.cpp:150] Setting up pool4
I0816 10:11:01.668543 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.668548 20528 net.cpp:165] Memory required for data: 25461760
I0816 10:11:01.668553 20528 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I0816 10:11:01.668561 20528 net.cpp:100] Creating Layer pool4_pool4_0_split
I0816 10:11:01.668567 20528 net.cpp:434] pool4_pool4_0_split <- pool4
I0816 10:11:01.668576 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_0
I0816 10:11:01.668584 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_1
I0816 10:11:01.668645 20528 net.cpp:150] Setting up pool4_pool4_0_split
I0816 10:11:01.668653 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.668660 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.668665 20528 net.cpp:165] Memory required for data: 25543680
I0816 10:11:01.668670 20528 layer_factory.hpp:77] Creating layer conv5_1
I0816 10:11:01.668695 20528 net.cpp:100] Creating Layer conv5_1
I0816 10:11:01.668701 20528 net.cpp:434] conv5_1 <- pool4_pool4_0_split_0
I0816 10:11:01.668710 20528 net.cpp:408] conv5_1 -> conv5_1
I0816 10:11:01.763094 20528 net.cpp:150] Setting up conv5_1
I0816 10:11:01.763119 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.763128 20528 net.cpp:165] Memory required for data: 25584640
I0816 10:11:01.763155 20528 layer_factory.hpp:77] Creating layer relu5_1
I0816 10:11:01.763170 20528 net.cpp:100] Creating Layer relu5_1
I0816 10:11:01.763176 20528 net.cpp:434] relu5_1 <- conv5_1
I0816 10:11:01.763185 20528 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0816 10:11:01.763366 20528 net.cpp:150] Setting up relu5_1
I0816 10:11:01.763376 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.763381 20528 net.cpp:165] Memory required for data: 25625600
I0816 10:11:01.763389 20528 layer_factory.hpp:77] Creating layer conv5_2
I0816 10:11:01.763404 20528 net.cpp:100] Creating Layer conv5_2
I0816 10:11:01.763411 20528 net.cpp:434] conv5_2 <- conv5_1
I0816 10:11:01.763420 20528 net.cpp:408] conv5_2 -> conv5_2
I0816 10:11:01.855199 20528 net.cpp:150] Setting up conv5_2
I0816 10:11:01.855221 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.855226 20528 net.cpp:165] Memory required for data: 25666560
I0816 10:11:01.855239 20528 layer_factory.hpp:77] Creating layer relu5_2
I0816 10:11:01.855248 20528 net.cpp:100] Creating Layer relu5_2
I0816 10:11:01.855255 20528 net.cpp:434] relu5_2 <- conv5_2
I0816 10:11:01.855263 20528 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0816 10:11:01.855414 20528 net.cpp:150] Setting up relu5_2
I0816 10:11:01.855424 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.855429 20528 net.cpp:165] Memory required for data: 25707520
I0816 10:11:01.855437 20528 layer_factory.hpp:77] Creating layer res5_2
I0816 10:11:01.855448 20528 net.cpp:100] Creating Layer res5_2
I0816 10:11:01.855456 20528 net.cpp:434] res5_2 <- pool4_pool4_0_split_1
I0816 10:11:01.855463 20528 net.cpp:434] res5_2 <- conv5_2
I0816 10:11:01.855480 20528 net.cpp:408] res5_2 -> res5_2
I0816 10:11:01.855520 20528 net.cpp:150] Setting up res5_2
I0816 10:11:01.855528 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.855533 20528 net.cpp:165] Memory required for data: 25748480
I0816 10:11:01.855540 20528 layer_factory.hpp:77] Creating layer res5_2_res5_2_0_split
I0816 10:11:01.855551 20528 net.cpp:100] Creating Layer res5_2_res5_2_0_split
I0816 10:11:01.855556 20528 net.cpp:434] res5_2_res5_2_0_split <- res5_2
I0816 10:11:01.855562 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_0
I0816 10:11:01.855571 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_1
I0816 10:11:01.855625 20528 net.cpp:150] Setting up res5_2_res5_2_0_split
I0816 10:11:01.855633 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.855640 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.855645 20528 net.cpp:165] Memory required for data: 25830400
I0816 10:11:01.855650 20528 layer_factory.hpp:77] Creating layer conv5_3
I0816 10:11:01.855664 20528 net.cpp:100] Creating Layer conv5_3
I0816 10:11:01.855670 20528 net.cpp:434] conv5_3 <- res5_2_res5_2_0_split_0
I0816 10:11:01.855680 20528 net.cpp:408] conv5_3 -> conv5_3
I0816 10:11:01.975719 20528 net.cpp:150] Setting up conv5_3
I0816 10:11:01.975790 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.975801 20528 net.cpp:165] Memory required for data: 25871360
I0816 10:11:01.975821 20528 layer_factory.hpp:77] Creating layer relu5_3
I0816 10:11:01.975843 20528 net.cpp:100] Creating Layer relu5_3
I0816 10:11:01.975857 20528 net.cpp:434] relu5_3 <- conv5_3
I0816 10:11:01.975872 20528 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0816 10:11:01.976116 20528 net.cpp:150] Setting up relu5_3
I0816 10:11:01.976133 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:01.976142 20528 net.cpp:165] Memory required for data: 25912320
I0816 10:11:01.976155 20528 layer_factory.hpp:77] Creating layer conv5_4
I0816 10:11:01.976181 20528 net.cpp:100] Creating Layer conv5_4
I0816 10:11:01.976191 20528 net.cpp:434] conv5_4 <- conv5_3
I0816 10:11:01.976205 20528 net.cpp:408] conv5_4 -> conv5_4
I0816 10:11:02.111183 20528 net.cpp:150] Setting up conv5_4
I0816 10:11:02.111251 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.111263 20528 net.cpp:165] Memory required for data: 25953280
I0816 10:11:02.111291 20528 layer_factory.hpp:77] Creating layer relu5_4
I0816 10:11:02.111312 20528 net.cpp:100] Creating Layer relu5_4
I0816 10:11:02.111330 20528 net.cpp:434] relu5_4 <- conv5_4
I0816 10:11:02.111348 20528 net.cpp:395] relu5_4 -> conv5_4 (in-place)
I0816 10:11:02.111611 20528 net.cpp:150] Setting up relu5_4
I0816 10:11:02.111629 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.111637 20528 net.cpp:165] Memory required for data: 25994240
I0816 10:11:02.111650 20528 layer_factory.hpp:77] Creating layer res5_4
I0816 10:11:02.111668 20528 net.cpp:100] Creating Layer res5_4
I0816 10:11:02.111682 20528 net.cpp:434] res5_4 <- res5_2_res5_2_0_split_1
I0816 10:11:02.111693 20528 net.cpp:434] res5_4 <- conv5_4
I0816 10:11:02.111706 20528 net.cpp:408] res5_4 -> res5_4
I0816 10:11:02.111778 20528 net.cpp:150] Setting up res5_4
I0816 10:11:02.111795 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.111804 20528 net.cpp:165] Memory required for data: 26035200
I0816 10:11:02.111812 20528 layer_factory.hpp:77] Creating layer res5_4_res5_4_0_split
I0816 10:11:02.111825 20528 net.cpp:100] Creating Layer res5_4_res5_4_0_split
I0816 10:11:02.111835 20528 net.cpp:434] res5_4_res5_4_0_split <- res5_4
I0816 10:11:02.111848 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_0
I0816 10:11:02.111862 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_1
I0816 10:11:02.111951 20528 net.cpp:150] Setting up res5_4_res5_4_0_split
I0816 10:11:02.111969 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.111981 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.111989 20528 net.cpp:165] Memory required for data: 26117120
I0816 10:11:02.112009 20528 layer_factory.hpp:77] Creating layer conv5_5
I0816 10:11:02.112033 20528 net.cpp:100] Creating Layer conv5_5
I0816 10:11:02.112043 20528 net.cpp:434] conv5_5 <- res5_4_res5_4_0_split_0
I0816 10:11:02.112056 20528 net.cpp:408] conv5_5 -> conv5_5
I0816 10:11:02.242589 20528 net.cpp:150] Setting up conv5_5
I0816 10:11:02.242651 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.242662 20528 net.cpp:165] Memory required for data: 26158080
I0816 10:11:02.242683 20528 layer_factory.hpp:77] Creating layer relu5_5
I0816 10:11:02.242712 20528 net.cpp:100] Creating Layer relu5_5
I0816 10:11:02.242725 20528 net.cpp:434] relu5_5 <- conv5_5
I0816 10:11:02.242751 20528 net.cpp:395] relu5_5 -> conv5_5 (in-place)
I0816 10:11:02.243006 20528 net.cpp:150] Setting up relu5_5
I0816 10:11:02.243029 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.243038 20528 net.cpp:165] Memory required for data: 26199040
I0816 10:11:02.243053 20528 layer_factory.hpp:77] Creating layer conv5_6
I0816 10:11:02.243089 20528 net.cpp:100] Creating Layer conv5_6
I0816 10:11:02.243101 20528 net.cpp:434] conv5_6 <- conv5_5
I0816 10:11:02.243118 20528 net.cpp:408] conv5_6 -> conv5_6
I0816 10:11:02.367660 20528 net.cpp:150] Setting up conv5_6
I0816 10:11:02.367707 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.367714 20528 net.cpp:165] Memory required for data: 26240000
I0816 10:11:02.367727 20528 layer_factory.hpp:77] Creating layer relu5_6
I0816 10:11:02.367746 20528 net.cpp:100] Creating Layer relu5_6
I0816 10:11:02.367754 20528 net.cpp:434] relu5_6 <- conv5_6
I0816 10:11:02.367764 20528 net.cpp:395] relu5_6 -> conv5_6 (in-place)
I0816 10:11:02.367929 20528 net.cpp:150] Setting up relu5_6
I0816 10:11:02.367940 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.367945 20528 net.cpp:165] Memory required for data: 26280960
I0816 10:11:02.367954 20528 layer_factory.hpp:77] Creating layer res5_6
I0816 10:11:02.367964 20528 net.cpp:100] Creating Layer res5_6
I0816 10:11:02.367972 20528 net.cpp:434] res5_6 <- res5_4_res5_4_0_split_1
I0816 10:11:02.367980 20528 net.cpp:434] res5_6 <- conv5_6
I0816 10:11:02.367987 20528 net.cpp:408] res5_6 -> res5_6
I0816 10:11:02.368072 20528 net.cpp:150] Setting up res5_6
I0816 10:11:02.368088 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:02.368093 20528 net.cpp:165] Memory required for data: 26321920
I0816 10:11:02.368098 20528 layer_factory.hpp:77] Creating layer fc5
I0816 10:11:02.368109 20528 net.cpp:100] Creating Layer fc5
I0816 10:11:02.368115 20528 net.cpp:434] fc5 <- res5_6
I0816 10:11:02.368124 20528 net.cpp:408] fc5 -> fc5
I0816 10:11:02.410684 20528 net.cpp:150] Setting up fc5
I0816 10:11:02.410722 20528 net.cpp:157] Top shape: 1 512 (512)
I0816 10:11:02.410728 20528 net.cpp:165] Memory required for data: 26323968
I0816 10:11:02.410748 20528 net.cpp:228] fc5 does not need backward computation.
I0816 10:11:02.410753 20528 net.cpp:228] res5_6 does not need backward computation.
I0816 10:11:02.410760 20528 net.cpp:228] relu5_6 does not need backward computation.
I0816 10:11:02.410765 20528 net.cpp:228] conv5_6 does not need backward computation.
I0816 10:11:02.410771 20528 net.cpp:228] relu5_5 does not need backward computation.
I0816 10:11:02.410776 20528 net.cpp:228] conv5_5 does not need backward computation.
I0816 10:11:02.410782 20528 net.cpp:228] res5_4_res5_4_0_split does not need backward computation.
I0816 10:11:02.410789 20528 net.cpp:228] res5_4 does not need backward computation.
I0816 10:11:02.410795 20528 net.cpp:228] relu5_4 does not need backward computation.
I0816 10:11:02.410800 20528 net.cpp:228] conv5_4 does not need backward computation.
I0816 10:11:02.410806 20528 net.cpp:228] relu5_3 does not need backward computation.
I0816 10:11:02.410811 20528 net.cpp:228] conv5_3 does not need backward computation.
I0816 10:11:02.410818 20528 net.cpp:228] res5_2_res5_2_0_split does not need backward computation.
I0816 10:11:02.410825 20528 net.cpp:228] res5_2 does not need backward computation.
I0816 10:11:02.410840 20528 net.cpp:228] relu5_2 does not need backward computation.
I0816 10:11:02.410846 20528 net.cpp:228] conv5_2 does not need backward computation.
I0816 10:11:02.410852 20528 net.cpp:228] relu5_1 does not need backward computation.
I0816 10:11:02.410858 20528 net.cpp:228] conv5_1 does not need backward computation.
I0816 10:11:02.410864 20528 net.cpp:228] pool4_pool4_0_split does not need backward computation.
I0816 10:11:02.410871 20528 net.cpp:228] pool4 does not need backward computation.
I0816 10:11:02.410877 20528 net.cpp:228] relu4 does not need backward computation.
I0816 10:11:02.410882 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:02.410889 20528 net.cpp:228] res4_10 does not need backward computation.
I0816 10:11:02.410897 20528 net.cpp:228] relu4_10 does not need backward computation.
I0816 10:11:02.410902 20528 net.cpp:228] conv4_10 does not need backward computation.
I0816 10:11:02.410908 20528 net.cpp:228] relu4_9 does not need backward computation.
I0816 10:11:02.410914 20528 net.cpp:228] conv4_9 does not need backward computation.
I0816 10:11:02.410922 20528 net.cpp:228] res4_8_res4_8_0_split does not need backward computation.
I0816 10:11:02.410928 20528 net.cpp:228] res4_8 does not need backward computation.
I0816 10:11:02.410934 20528 net.cpp:228] relu4_8 does not need backward computation.
I0816 10:11:02.410940 20528 net.cpp:228] conv4_8 does not need backward computation.
I0816 10:11:02.410948 20528 net.cpp:228] relu4_7 does not need backward computation.
I0816 10:11:02.410953 20528 net.cpp:228] conv4_7 does not need backward computation.
I0816 10:11:02.410960 20528 net.cpp:228] res4_6_res4_6_0_split does not need backward computation.
I0816 10:11:02.410965 20528 net.cpp:228] res4_6 does not need backward computation.
I0816 10:11:02.410972 20528 net.cpp:228] relu4_6 does not need backward computation.
I0816 10:11:02.410979 20528 net.cpp:228] conv4_6 does not need backward computation.
I0816 10:11:02.410985 20528 net.cpp:228] relu4_5 does not need backward computation.
I0816 10:11:02.410996 20528 net.cpp:228] conv4_5 does not need backward computation.
I0816 10:11:02.411003 20528 net.cpp:228] res4_4_res4_4_0_split does not need backward computation.
I0816 10:11:02.411008 20528 net.cpp:228] res4_4 does not need backward computation.
I0816 10:11:02.411015 20528 net.cpp:228] relu4_4 does not need backward computation.
I0816 10:11:02.411021 20528 net.cpp:228] conv4_4 does not need backward computation.
I0816 10:11:02.411026 20528 net.cpp:228] relu4_3 does not need backward computation.
I0816 10:11:02.411032 20528 net.cpp:228] conv4_3 does not need backward computation.
I0816 10:11:02.411038 20528 net.cpp:228] res4_2_res4_2_0_split does not need backward computation.
I0816 10:11:02.411044 20528 net.cpp:228] res4_2 does not need backward computation.
I0816 10:11:02.411051 20528 net.cpp:228] relu4_2 does not need backward computation.
I0816 10:11:02.411056 20528 net.cpp:228] conv4_2 does not need backward computation.
I0816 10:11:02.411062 20528 net.cpp:228] relu4_1 does not need backward computation.
I0816 10:11:02.411068 20528 net.cpp:228] conv4_1 does not need backward computation.
I0816 10:11:02.411077 20528 net.cpp:228] pool3_pool3_0_split does not need backward computation.
I0816 10:11:02.411082 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:02.411088 20528 net.cpp:228] relu3 does not need backward computation.
I0816 10:11:02.411095 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:02.411101 20528 net.cpp:228] res3_4 does not need backward computation.
I0816 10:11:02.411109 20528 net.cpp:228] relu3_4 does not need backward computation.
I0816 10:11:02.411115 20528 net.cpp:228] conv3_4 does not need backward computation.
I0816 10:11:02.411123 20528 net.cpp:228] relu3_3 does not need backward computation.
I0816 10:11:02.411129 20528 net.cpp:228] conv3_3 does not need backward computation.
I0816 10:11:02.411137 20528 net.cpp:228] res3_2_res3_2_0_split does not need backward computation.
I0816 10:11:02.411144 20528 net.cpp:228] res3_2 does not need backward computation.
I0816 10:11:02.411154 20528 net.cpp:228] relu3_2 does not need backward computation.
I0816 10:11:02.411161 20528 net.cpp:228] conv3_2 does not need backward computation.
I0816 10:11:02.411167 20528 net.cpp:228] relu3_1 does not need backward computation.
I0816 10:11:02.411173 20528 net.cpp:228] conv3_1 does not need backward computation.
I0816 10:11:02.411180 20528 net.cpp:228] pool2_pool2_0_split does not need backward computation.
I0816 10:11:02.411185 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:02.411192 20528 net.cpp:228] relu2 does not need backward computation.
I0816 10:11:02.411198 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:02.411206 20528 net.cpp:228] res2_2 does not need backward computation.
I0816 10:11:02.411213 20528 net.cpp:228] relu2_2 does not need backward computation.
I0816 10:11:02.411219 20528 net.cpp:228] conv2_2 does not need backward computation.
I0816 10:11:02.411226 20528 net.cpp:228] relu2_1 does not need backward computation.
I0816 10:11:02.411232 20528 net.cpp:228] conv2_1 does not need backward computation.
I0816 10:11:02.411238 20528 net.cpp:228] pool1b_pool1b_0_split does not need backward computation.
I0816 10:11:02.411244 20528 net.cpp:228] pool1b does not need backward computation.
I0816 10:11:02.411250 20528 net.cpp:228] relu1b does not need backward computation.
I0816 10:11:02.411255 20528 net.cpp:228] conv1b does not need backward computation.
I0816 10:11:02.411262 20528 net.cpp:228] relu1a does not need backward computation.
I0816 10:11:02.411268 20528 net.cpp:228] conv1a does not need backward computation.
I0816 10:11:02.411274 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:02.411279 20528 net.cpp:270] This network produces output fc5
I0816 10:11:02.411337 20528 net.cpp:283] Network initialization done.
I0816 10:11:02.850782 20528 net.cpp:761] Ignoring source layer data
I0816 10:11:02.850821 20528 net.cpp:761] Ignoring source layer label_data_1_split
I0816 10:11:02.874228 20528 net.cpp:761] Ignoring source layer fc5_fc5_0_split
I0816 10:11:02.874259 20528 net.cpp:761] Ignoring source layer fc6
I0816 10:11:02.874265 20528 net.cpp:761] Ignoring source layer softmax_loss
I0816 10:11:02.874270 20528 net.cpp:761] Ignoring source layer center_loss
i: 0   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_0
I0816 10:11:02.878476 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det1.prototxt
I0816 10:11:02.878496 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:02.878502 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:02.878674 20528 net.cpp:58] Initializing net from parameters: 
name: "PNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4-1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4-2"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv4-1"
  top: "prob1"
}
I0816 10:11:02.878767 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:02.878785 20528 net.cpp:100] Creating Layer input
I0816 10:11:02.878793 20528 net.cpp:408] input -> data
I0816 10:11:02.878926 20528 net.cpp:150] Setting up input
I0816 10:11:02.878939 20528 net.cpp:157] Top shape: 1 3 12 12 (432)
I0816 10:11:02.878944 20528 net.cpp:165] Memory required for data: 1728
I0816 10:11:02.878950 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:02.878964 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:02.878969 20528 net.cpp:434] conv1 <- data
I0816 10:11:02.878978 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:02.882535 20528 net.cpp:150] Setting up conv1
I0816 10:11:02.882556 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:02.882562 20528 net.cpp:165] Memory required for data: 5728
I0816 10:11:02.882580 20528 layer_factory.hpp:77] Creating layer PReLU1
I0816 10:11:02.882591 20528 net.cpp:100] Creating Layer PReLU1
I0816 10:11:02.882597 20528 net.cpp:434] PReLU1 <- conv1
I0816 10:11:02.882606 20528 net.cpp:395] PReLU1 -> conv1 (in-place)
I0816 10:11:02.882779 20528 net.cpp:150] Setting up PReLU1
I0816 10:11:02.882791 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:02.882797 20528 net.cpp:165] Memory required for data: 9728
I0816 10:11:02.882807 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:02.882817 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:02.882822 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:02.882829 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:02.882887 20528 net.cpp:150] Setting up pool1
I0816 10:11:02.882897 20528 net.cpp:157] Top shape: 1 10 5 5 (250)
I0816 10:11:02.882902 20528 net.cpp:165] Memory required for data: 10728
I0816 10:11:02.882908 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:02.882920 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:02.882926 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:02.882935 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:02.887661 20528 net.cpp:150] Setting up conv2
I0816 10:11:02.887681 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:02.887686 20528 net.cpp:165] Memory required for data: 11304
I0816 10:11:02.887699 20528 layer_factory.hpp:77] Creating layer PReLU2
I0816 10:11:02.887708 20528 net.cpp:100] Creating Layer PReLU2
I0816 10:11:02.887714 20528 net.cpp:434] PReLU2 <- conv2
I0816 10:11:02.887722 20528 net.cpp:395] PReLU2 -> conv2 (in-place)
I0816 10:11:02.887871 20528 net.cpp:150] Setting up PReLU2
I0816 10:11:02.887882 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:02.887887 20528 net.cpp:165] Memory required for data: 11880
I0816 10:11:02.887894 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:02.887907 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:02.887912 20528 net.cpp:434] conv3 <- conv2
I0816 10:11:02.887928 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:02.892803 20528 net.cpp:150] Setting up conv3
I0816 10:11:02.892823 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:02.892829 20528 net.cpp:165] Memory required for data: 12008
I0816 10:11:02.892838 20528 layer_factory.hpp:77] Creating layer PReLU3
I0816 10:11:02.892848 20528 net.cpp:100] Creating Layer PReLU3
I0816 10:11:02.892854 20528 net.cpp:434] PReLU3 <- conv3
I0816 10:11:02.892863 20528 net.cpp:395] PReLU3 -> conv3 (in-place)
I0816 10:11:02.893002 20528 net.cpp:150] Setting up PReLU3
I0816 10:11:02.893012 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:02.893016 20528 net.cpp:165] Memory required for data: 12136
I0816 10:11:02.893028 20528 layer_factory.hpp:77] Creating layer conv3_PReLU3_0_split
I0816 10:11:02.893040 20528 net.cpp:100] Creating Layer conv3_PReLU3_0_split
I0816 10:11:02.893045 20528 net.cpp:434] conv3_PReLU3_0_split <- conv3
I0816 10:11:02.893054 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_0
I0816 10:11:02.893062 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_1
I0816 10:11:02.893117 20528 net.cpp:150] Setting up conv3_PReLU3_0_split
I0816 10:11:02.893126 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:02.893133 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:02.893137 20528 net.cpp:165] Memory required for data: 12392
I0816 10:11:02.893143 20528 layer_factory.hpp:77] Creating layer conv4-1
I0816 10:11:02.893154 20528 net.cpp:100] Creating Layer conv4-1
I0816 10:11:02.893160 20528 net.cpp:434] conv4-1 <- conv3_PReLU3_0_split_0
I0816 10:11:02.893169 20528 net.cpp:408] conv4-1 -> conv4-1
I0816 10:11:02.897953 20528 net.cpp:150] Setting up conv4-1
I0816 10:11:02.897971 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:02.897977 20528 net.cpp:165] Memory required for data: 12400
I0816 10:11:02.897987 20528 layer_factory.hpp:77] Creating layer conv4-2
I0816 10:11:02.898003 20528 net.cpp:100] Creating Layer conv4-2
I0816 10:11:02.898010 20528 net.cpp:434] conv4-2 <- conv3_PReLU3_0_split_1
I0816 10:11:02.898021 20528 net.cpp:408] conv4-2 -> conv4-2
I0816 10:11:02.902524 20528 net.cpp:150] Setting up conv4-2
I0816 10:11:02.902544 20528 net.cpp:157] Top shape: 1 4 1 1 (4)
I0816 10:11:02.902549 20528 net.cpp:165] Memory required for data: 12416
I0816 10:11:02.902559 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:02.902571 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:02.902578 20528 net.cpp:434] prob1 <- conv4-1
I0816 10:11:02.902586 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:02.903328 20528 net.cpp:150] Setting up prob1
I0816 10:11:02.903347 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:02.903353 20528 net.cpp:165] Memory required for data: 12424
I0816 10:11:02.903359 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:02.903365 20528 net.cpp:228] conv4-2 does not need backward computation.
I0816 10:11:02.903370 20528 net.cpp:228] conv4-1 does not need backward computation.
I0816 10:11:02.903376 20528 net.cpp:228] conv3_PReLU3_0_split does not need backward computation.
I0816 10:11:02.903381 20528 net.cpp:228] PReLU3 does not need backward computation.
I0816 10:11:02.903388 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:02.903393 20528 net.cpp:228] PReLU2 does not need backward computation.
I0816 10:11:02.903398 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:02.903403 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:02.903408 20528 net.cpp:228] PReLU1 does not need backward computation.
I0816 10:11:02.903414 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:02.903419 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:02.903424 20528 net.cpp:270] This network produces output conv4-2
I0816 10:11:02.903429 20528 net.cpp:270] This network produces output prob1
I0816 10:11:02.903442 20528 net.cpp:283] Network initialization done.
I0816 10:11:02.903661 20528 net.cpp:761] Ignoring source layer data12
I0816 10:11:02.903676 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:02.903681 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:02.903686 20528 net.cpp:761] Ignoring source layer silence
I0816 10:11:02.903702 20528 net.cpp:761] Ignoring source layer conv4-1_conv4-1_0_split
I0816 10:11:02.903707 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:02.903712 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:02.903717 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:02.904109 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det2.prototxt
I0816 10:11:02.904124 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:02.904129 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:02.904295 20528 net.cpp:58] Initializing net from parameters: 
name: "RNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
  propagate_down: true
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
  propagate_down: true
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
  propagate_down: true
}
layer {
  name: "conv4"
  type: "InnerProduct"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5-1"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5-2"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv5-1"
  top: "prob1"
}
I0816 10:11:02.904366 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:02.904383 20528 net.cpp:100] Creating Layer input
I0816 10:11:02.904392 20528 net.cpp:408] input -> data
I0816 10:11:02.904444 20528 net.cpp:150] Setting up input
I0816 10:11:02.904455 20528 net.cpp:157] Top shape: 1 3 24 24 (1728)
I0816 10:11:02.904460 20528 net.cpp:165] Memory required for data: 6912
I0816 10:11:02.904466 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:02.904477 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:02.904482 20528 net.cpp:434] conv1 <- data
I0816 10:11:02.904491 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:02.908421 20528 net.cpp:150] Setting up conv1
I0816 10:11:02.908442 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:02.908447 20528 net.cpp:165] Memory required for data: 61120
I0816 10:11:02.908462 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:02.908471 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:02.908478 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:02.908488 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:02.908651 20528 net.cpp:150] Setting up prelu1
I0816 10:11:02.908669 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:02.908674 20528 net.cpp:165] Memory required for data: 115328
I0816 10:11:02.908684 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:02.908692 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:02.908697 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:02.908707 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:02.908777 20528 net.cpp:150] Setting up pool1
I0816 10:11:02.908788 20528 net.cpp:157] Top shape: 1 28 11 11 (3388)
I0816 10:11:02.908793 20528 net.cpp:165] Memory required for data: 128880
I0816 10:11:02.908799 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:02.908814 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:02.908820 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:02.908828 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:02.913573 20528 net.cpp:150] Setting up conv2
I0816 10:11:02.913591 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:02.913597 20528 net.cpp:165] Memory required for data: 144432
I0816 10:11:02.913610 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:02.913621 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:02.913627 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:02.913635 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:02.913808 20528 net.cpp:150] Setting up prelu2
I0816 10:11:02.913820 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:02.913825 20528 net.cpp:165] Memory required for data: 159984
I0816 10:11:02.913832 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:02.913844 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:02.913851 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:02.913857 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:02.913921 20528 net.cpp:150] Setting up pool2
I0816 10:11:02.913931 20528 net.cpp:157] Top shape: 1 48 4 4 (768)
I0816 10:11:02.913936 20528 net.cpp:165] Memory required for data: 163056
I0816 10:11:02.913941 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:02.913954 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:02.913960 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:02.913970 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:02.918759 20528 net.cpp:150] Setting up conv3
I0816 10:11:02.918778 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:02.918784 20528 net.cpp:165] Memory required for data: 165360
I0816 10:11:02.918794 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:02.918807 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:02.918813 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:02.918820 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:02.918979 20528 net.cpp:150] Setting up prelu3
I0816 10:11:02.918989 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:02.918994 20528 net.cpp:165] Memory required for data: 167664
I0816 10:11:02.919005 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:02.919018 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:02.919029 20528 net.cpp:434] conv4 <- conv3
I0816 10:11:02.919040 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:02.919662 20528 net.cpp:150] Setting up conv4
I0816 10:11:02.919672 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:02.919677 20528 net.cpp:165] Memory required for data: 168176
I0816 10:11:02.919687 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:02.919693 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:02.919699 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:02.919708 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:02.919841 20528 net.cpp:150] Setting up prelu4
I0816 10:11:02.919850 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:02.919855 20528 net.cpp:165] Memory required for data: 168688
I0816 10:11:02.919862 20528 layer_factory.hpp:77] Creating layer conv4_prelu4_0_split
I0816 10:11:02.919872 20528 net.cpp:100] Creating Layer conv4_prelu4_0_split
I0816 10:11:02.919878 20528 net.cpp:434] conv4_prelu4_0_split <- conv4
I0816 10:11:02.919885 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_0
I0816 10:11:02.919893 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_1
I0816 10:11:02.919950 20528 net.cpp:150] Setting up conv4_prelu4_0_split
I0816 10:11:02.919960 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:02.919966 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:02.919971 20528 net.cpp:165] Memory required for data: 169712
I0816 10:11:02.919976 20528 layer_factory.hpp:77] Creating layer conv5-1
I0816 10:11:02.919986 20528 net.cpp:100] Creating Layer conv5-1
I0816 10:11:02.919992 20528 net.cpp:434] conv5-1 <- conv4_prelu4_0_split_0
I0816 10:11:02.919999 20528 net.cpp:408] conv5-1 -> conv5-1
I0816 10:11:02.920151 20528 net.cpp:150] Setting up conv5-1
I0816 10:11:02.920161 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:02.920166 20528 net.cpp:165] Memory required for data: 169720
I0816 10:11:02.920174 20528 layer_factory.hpp:77] Creating layer conv5-2
I0816 10:11:02.920182 20528 net.cpp:100] Creating Layer conv5-2
I0816 10:11:02.920187 20528 net.cpp:434] conv5-2 <- conv4_prelu4_0_split_1
I0816 10:11:02.920195 20528 net.cpp:408] conv5-2 -> conv5-2
I0816 10:11:02.920361 20528 net.cpp:150] Setting up conv5-2
I0816 10:11:02.920372 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:02.920377 20528 net.cpp:165] Memory required for data: 169736
I0816 10:11:02.920384 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:02.920392 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:02.920397 20528 net.cpp:434] prob1 <- conv5-1
I0816 10:11:02.920406 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:02.921169 20528 net.cpp:150] Setting up prob1
I0816 10:11:02.921187 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:02.921193 20528 net.cpp:165] Memory required for data: 169744
I0816 10:11:02.921200 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:02.921205 20528 net.cpp:228] conv5-2 does not need backward computation.
I0816 10:11:02.921211 20528 net.cpp:228] conv5-1 does not need backward computation.
I0816 10:11:02.921216 20528 net.cpp:228] conv4_prelu4_0_split does not need backward computation.
I0816 10:11:02.921221 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:02.921226 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:02.921231 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:02.921236 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:02.921241 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:02.921247 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:02.921252 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:02.921257 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:02.921262 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:02.921267 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:02.921272 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:02.921285 20528 net.cpp:270] This network produces output conv5-2
I0816 10:11:02.921291 20528 net.cpp:270] This network produces output prob1
I0816 10:11:02.921305 20528 net.cpp:283] Network initialization done.
I0816 10:11:02.922657 20528 net.cpp:761] Ignoring source layer data24
I0816 10:11:02.922668 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:02.922673 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:02.922725 20528 net.cpp:761] Ignoring source layer conv5-1_conv5-1_0_split
I0816 10:11:02.922739 20528 net.cpp:761] Ignoring source layer conv5-3
I0816 10:11:02.922744 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:02.922749 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:02.922754 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:02.922758 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:02.923244 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det3.prototxt
I0816 10:11:02.923257 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:02.923262 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:02.923460 20528 net.cpp:58] Initializing net from parameters: 
name: "ONet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 48
      dim: 48
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6-1"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-2"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-3"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv6-1"
  top: "prob1"
}
I0816 10:11:02.923549 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:02.923562 20528 net.cpp:100] Creating Layer input
I0816 10:11:02.923568 20528 net.cpp:408] input -> data
I0816 10:11:02.923624 20528 net.cpp:150] Setting up input
I0816 10:11:02.923635 20528 net.cpp:157] Top shape: 1 3 48 48 (6912)
I0816 10:11:02.923640 20528 net.cpp:165] Memory required for data: 27648
I0816 10:11:02.923646 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:02.923657 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:02.923663 20528 net.cpp:434] conv1 <- data
I0816 10:11:02.923671 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:02.927219 20528 net.cpp:150] Setting up conv1
I0816 10:11:02.927239 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:02.927245 20528 net.cpp:165] Memory required for data: 298496
I0816 10:11:02.927259 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:02.927269 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:02.927275 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:02.927283 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:02.927494 20528 net.cpp:150] Setting up prelu1
I0816 10:11:02.927503 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:02.927508 20528 net.cpp:165] Memory required for data: 569344
I0816 10:11:02.927517 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:02.927526 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:02.927531 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:02.927538 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:02.927597 20528 net.cpp:150] Setting up pool1
I0816 10:11:02.927606 20528 net.cpp:157] Top shape: 1 32 23 23 (16928)
I0816 10:11:02.927611 20528 net.cpp:165] Memory required for data: 637056
I0816 10:11:02.927616 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:02.927628 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:02.927634 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:02.927640 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:02.932366 20528 net.cpp:150] Setting up conv2
I0816 10:11:02.932385 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:02.932390 20528 net.cpp:165] Memory required for data: 749952
I0816 10:11:02.932404 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:02.932412 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:02.932418 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:02.932425 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:02.932581 20528 net.cpp:150] Setting up prelu2
I0816 10:11:02.932591 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:02.932596 20528 net.cpp:165] Memory required for data: 862848
I0816 10:11:02.932603 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:02.932611 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:02.932616 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:02.932631 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:02.932687 20528 net.cpp:150] Setting up pool2
I0816 10:11:02.932698 20528 net.cpp:157] Top shape: 1 64 10 10 (6400)
I0816 10:11:02.932703 20528 net.cpp:165] Memory required for data: 888448
I0816 10:11:02.932708 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:02.932718 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:02.932723 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:02.932737 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:02.937525 20528 net.cpp:150] Setting up conv3
I0816 10:11:02.937544 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:02.937551 20528 net.cpp:165] Memory required for data: 904832
I0816 10:11:02.937559 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:02.937571 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:02.937575 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:02.937583 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:02.937818 20528 net.cpp:150] Setting up prelu3
I0816 10:11:02.937830 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:02.937835 20528 net.cpp:165] Memory required for data: 921216
I0816 10:11:02.937846 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:02.937855 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:02.937860 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:02.937867 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:02.937924 20528 net.cpp:150] Setting up pool3
I0816 10:11:02.937933 20528 net.cpp:157] Top shape: 1 64 4 4 (1024)
I0816 10:11:02.937938 20528 net.cpp:165] Memory required for data: 925312
I0816 10:11:02.937943 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:02.937954 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:02.937959 20528 net.cpp:434] conv4 <- pool3
I0816 10:11:02.937968 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:02.942682 20528 net.cpp:150] Setting up conv4
I0816 10:11:02.942699 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:02.942705 20528 net.cpp:165] Memory required for data: 929920
I0816 10:11:02.942715 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:02.942723 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:02.942735 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:02.942744 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:02.942879 20528 net.cpp:150] Setting up prelu4
I0816 10:11:02.942889 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:02.942894 20528 net.cpp:165] Memory required for data: 934528
I0816 10:11:02.942901 20528 layer_factory.hpp:77] Creating layer conv5
I0816 10:11:02.942910 20528 net.cpp:100] Creating Layer conv5
I0816 10:11:02.942915 20528 net.cpp:434] conv5 <- conv4
I0816 10:11:02.942924 20528 net.cpp:408] conv5 -> conv5
I0816 10:11:02.945574 20528 net.cpp:150] Setting up conv5
I0816 10:11:02.945591 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:02.945597 20528 net.cpp:165] Memory required for data: 935552
I0816 10:11:02.945606 20528 layer_factory.hpp:77] Creating layer drop5
I0816 10:11:02.945616 20528 net.cpp:100] Creating Layer drop5
I0816 10:11:02.945621 20528 net.cpp:434] drop5 <- conv5
I0816 10:11:02.945628 20528 net.cpp:395] drop5 -> conv5 (in-place)
I0816 10:11:02.945668 20528 net.cpp:150] Setting up drop5
I0816 10:11:02.945677 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:02.945683 20528 net.cpp:165] Memory required for data: 936576
I0816 10:11:02.945688 20528 layer_factory.hpp:77] Creating layer prelu5
I0816 10:11:02.945694 20528 net.cpp:100] Creating Layer prelu5
I0816 10:11:02.945700 20528 net.cpp:434] prelu5 <- conv5
I0816 10:11:02.945706 20528 net.cpp:395] prelu5 -> conv5 (in-place)
I0816 10:11:02.945838 20528 net.cpp:150] Setting up prelu5
I0816 10:11:02.945848 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:02.945853 20528 net.cpp:165] Memory required for data: 937600
I0816 10:11:02.945860 20528 layer_factory.hpp:77] Creating layer conv5_prelu5_0_split
I0816 10:11:02.945868 20528 net.cpp:100] Creating Layer conv5_prelu5_0_split
I0816 10:11:02.945873 20528 net.cpp:434] conv5_prelu5_0_split <- conv5
I0816 10:11:02.945888 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_0
I0816 10:11:02.945896 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_1
I0816 10:11:02.945904 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_2
I0816 10:11:02.945979 20528 net.cpp:150] Setting up conv5_prelu5_0_split
I0816 10:11:02.945987 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:02.945993 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:02.945999 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:02.946004 20528 net.cpp:165] Memory required for data: 940672
I0816 10:11:02.946009 20528 layer_factory.hpp:77] Creating layer conv6-1
I0816 10:11:02.946020 20528 net.cpp:100] Creating Layer conv6-1
I0816 10:11:02.946027 20528 net.cpp:434] conv6-1 <- conv5_prelu5_0_split_0
I0816 10:11:02.946034 20528 net.cpp:408] conv6-1 -> conv6-1
I0816 10:11:02.946197 20528 net.cpp:150] Setting up conv6-1
I0816 10:11:02.946205 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:02.946210 20528 net.cpp:165] Memory required for data: 940680
I0816 10:11:02.946223 20528 layer_factory.hpp:77] Creating layer conv6-2
I0816 10:11:02.946231 20528 net.cpp:100] Creating Layer conv6-2
I0816 10:11:02.946236 20528 net.cpp:434] conv6-2 <- conv5_prelu5_0_split_1
I0816 10:11:02.946244 20528 net.cpp:408] conv6-2 -> conv6-2
I0816 10:11:02.946399 20528 net.cpp:150] Setting up conv6-2
I0816 10:11:02.946408 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:02.946413 20528 net.cpp:165] Memory required for data: 940696
I0816 10:11:02.946421 20528 layer_factory.hpp:77] Creating layer conv6-3
I0816 10:11:02.946429 20528 net.cpp:100] Creating Layer conv6-3
I0816 10:11:02.946435 20528 net.cpp:434] conv6-3 <- conv5_prelu5_0_split_2
I0816 10:11:02.946442 20528 net.cpp:408] conv6-3 -> conv6-3
I0816 10:11:02.946611 20528 net.cpp:150] Setting up conv6-3
I0816 10:11:02.946620 20528 net.cpp:157] Top shape: 1 10 (10)
I0816 10:11:02.946625 20528 net.cpp:165] Memory required for data: 940736
I0816 10:11:02.946633 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:02.946641 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:02.946647 20528 net.cpp:434] prob1 <- conv6-1
I0816 10:11:02.946655 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:02.946977 20528 net.cpp:150] Setting up prob1
I0816 10:11:02.946991 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:02.946996 20528 net.cpp:165] Memory required for data: 940744
I0816 10:11:02.947002 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:02.947007 20528 net.cpp:228] conv6-3 does not need backward computation.
I0816 10:11:02.947013 20528 net.cpp:228] conv6-2 does not need backward computation.
I0816 10:11:02.947018 20528 net.cpp:228] conv6-1 does not need backward computation.
I0816 10:11:02.947023 20528 net.cpp:228] conv5_prelu5_0_split does not need backward computation.
I0816 10:11:02.947029 20528 net.cpp:228] prelu5 does not need backward computation.
I0816 10:11:02.947034 20528 net.cpp:228] drop5 does not need backward computation.
I0816 10:11:02.947039 20528 net.cpp:228] conv5 does not need backward computation.
I0816 10:11:02.947044 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:02.947049 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:02.947054 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:02.947059 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:02.947064 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:02.947069 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:02.947074 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:02.947079 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:02.947084 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:02.947089 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:02.947094 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:02.947100 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:02.947110 20528 net.cpp:270] This network produces output conv6-2
I0816 10:11:02.947116 20528 net.cpp:270] This network produces output conv6-3
I0816 10:11:02.947123 20528 net.cpp:270] This network produces output prob1
I0816 10:11:02.947139 20528 net.cpp:283] Network initialization done.
I0816 10:11:02.952002 20528 net.cpp:761] Ignoring source layer data48
I0816 10:11:02.952013 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:02.952018 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:02.952242 20528 net.cpp:761] Ignoring source layer conv6-1_conv6-1_0_split
I0816 10:11:02.952252 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:02.952257 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:02.952262 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:02.952267 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:02.953917 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/face_deploy.prototxt
I0816 10:11:02.953939 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:02.953945 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:02.954550 20528 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 96
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "PReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1b"
  type: "PReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1b"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1b"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1b"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "res2_2"
  type: "Eltwise"
  bottom: "pool1b"
  bottom: "conv2_2"
  top: "res2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "res2_2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "res3_2"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "conv3_2"
  top: "res3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "res3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "res3_4"
  type: "Eltwise"
  bottom: "res3_2"
  bottom: "conv3_4"
  top: "res3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "res3_4"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "res4_2"
  type: "Eltwise"
  bottom: "pool3"
  bottom: "conv4_2"
  top: "res4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "res4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_4"
  type: "PReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "res4_4"
  type: "Eltwise"
  bottom: "res4_2"
  bottom: "conv4_4"
  top: "res4_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_5"
  type: "Convolution"
  bottom: "res4_4"
  top: "conv4_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_5"
  type: "PReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_6"
  type: "PReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
layer {
  name: "res4_6"
  type: "Eltwise"
  bottom: "res4_4"
  bottom: "conv4_6"
  top: "res4_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_7"
  type: "Convolution"
  bottom: "res4_6"
  top: "conv4_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_7"
  type: "PReLU"
  bottom: "conv4_7"
  top: "conv4_7"
}
layer {
  name: "conv4_8"
  type: "Convolution"
  bottom: "conv4_7"
  top: "conv4_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_8"
  type: "PReLU"
  bottom: "conv4_8"
  top: "conv4_8"
}
layer {
  name: "res4_8"
  type: "Eltwise"
  bottom: "res4_6"
  bottom: "conv4_8"
  top: "res4_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_9"
  type: "Convolution"
  bottom: "res4_8"
  top: "conv4_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_9"
  type: "PReLU"
  bottom: "conv4_9"
  top: "conv4_9"
}
layer {
  name: "conv4_10"
  type: "Convolution"
  bottom: "conv4_9"
  top: "conv4_10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_10"
  type: "PReLU"
  bottom: "conv4_10"
  top: "conv4_10"
}
layer {
  name: "res4_10"
  type: "Eltwise"
  bottom: "res4_8"
  bottom: "conv4_10"
  top: "res4_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "res4_10"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "PReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "PReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "res5_2"
  type: "Eltwise"
  bottom: "pool4"
  bottom: "conv5_2"
  top: "res5_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "res5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "PReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_4"
  type: "PReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "res5_4"
  type: "Eltwise"
  bottom: "res5_2"
  bottom: "conv5_4"
  top: "res5_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_5"
  type: "Convolution"
  bottom: "res5_4"
  top: "conv5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_5"
  type: "PReLU"
  bottom: "conv5_5"
  top: "conv5_5"
}
layer {
  name: "conv5_6"
  type: "Convolution"
  bottom: "conv5_5"
  top: "conv5_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_6"
  type: "PReLU"
  bottom: "conv5_6"
  top: "conv5_6"
}
layer {
  name: "res5_6"
  type: "Eltwise"
  bottom: "res5_4"
  bottom: "conv5_6"
  top: "res5_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res5_6"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
I0816 10:11:02.954926 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:02.954941 20528 net.cpp:100] Creating Layer input
I0816 10:11:02.954948 20528 net.cpp:408] input -> data
I0816 10:11:02.955013 20528 net.cpp:150] Setting up input
I0816 10:11:02.955025 20528 net.cpp:157] Top shape: 1 3 112 96 (32256)
I0816 10:11:02.955030 20528 net.cpp:165] Memory required for data: 129024
I0816 10:11:02.955036 20528 layer_factory.hpp:77] Creating layer conv1a
I0816 10:11:02.955049 20528 net.cpp:100] Creating Layer conv1a
I0816 10:11:02.955054 20528 net.cpp:434] conv1a <- data
I0816 10:11:02.955065 20528 net.cpp:408] conv1a -> conv1a
I0816 10:11:02.957440 20528 net.cpp:150] Setting up conv1a
I0816 10:11:02.957460 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:02.957466 20528 net.cpp:165] Memory required for data: 1452544
I0816 10:11:02.957481 20528 layer_factory.hpp:77] Creating layer relu1a
I0816 10:11:02.957490 20528 net.cpp:100] Creating Layer relu1a
I0816 10:11:02.957496 20528 net.cpp:434] relu1a <- conv1a
I0816 10:11:02.957504 20528 net.cpp:395] relu1a -> conv1a (in-place)
I0816 10:11:02.958698 20528 net.cpp:150] Setting up relu1a
I0816 10:11:02.958716 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:02.958721 20528 net.cpp:165] Memory required for data: 2776064
I0816 10:11:02.958739 20528 layer_factory.hpp:77] Creating layer conv1b
I0816 10:11:02.958753 20528 net.cpp:100] Creating Layer conv1b
I0816 10:11:02.958760 20528 net.cpp:434] conv1b <- conv1a
I0816 10:11:02.958767 20528 net.cpp:408] conv1b -> conv1b
I0816 10:11:02.961292 20528 net.cpp:150] Setting up conv1b
I0816 10:11:02.961318 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:02.961323 20528 net.cpp:165] Memory required for data: 5319680
I0816 10:11:02.961336 20528 layer_factory.hpp:77] Creating layer relu1b
I0816 10:11:02.961346 20528 net.cpp:100] Creating Layer relu1b
I0816 10:11:02.961351 20528 net.cpp:434] relu1b <- conv1b
I0816 10:11:02.961361 20528 net.cpp:395] relu1b -> conv1b (in-place)
I0816 10:11:02.963317 20528 net.cpp:150] Setting up relu1b
I0816 10:11:02.963338 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:02.963343 20528 net.cpp:165] Memory required for data: 7863296
I0816 10:11:02.963351 20528 layer_factory.hpp:77] Creating layer pool1b
I0816 10:11:02.963361 20528 net.cpp:100] Creating Layer pool1b
I0816 10:11:02.963367 20528 net.cpp:434] pool1b <- conv1b
I0816 10:11:02.963374 20528 net.cpp:408] pool1b -> pool1b
I0816 10:11:02.963444 20528 net.cpp:150] Setting up pool1b
I0816 10:11:02.963454 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.963459 20528 net.cpp:165] Memory required for data: 8499200
I0816 10:11:02.963464 20528 layer_factory.hpp:77] Creating layer pool1b_pool1b_0_split
I0816 10:11:02.963472 20528 net.cpp:100] Creating Layer pool1b_pool1b_0_split
I0816 10:11:02.963477 20528 net.cpp:434] pool1b_pool1b_0_split <- pool1b
I0816 10:11:02.963486 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_0
I0816 10:11:02.963495 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_1
I0816 10:11:02.963557 20528 net.cpp:150] Setting up pool1b_pool1b_0_split
I0816 10:11:02.963565 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.963572 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.963577 20528 net.cpp:165] Memory required for data: 9771008
I0816 10:11:02.963582 20528 layer_factory.hpp:77] Creating layer conv2_1
I0816 10:11:02.963593 20528 net.cpp:100] Creating Layer conv2_1
I0816 10:11:02.963598 20528 net.cpp:434] conv2_1 <- pool1b_pool1b_0_split_0
I0816 10:11:02.963609 20528 net.cpp:408] conv2_1 -> conv2_1
I0816 10:11:02.968484 20528 net.cpp:150] Setting up conv2_1
I0816 10:11:02.968503 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.968509 20528 net.cpp:165] Memory required for data: 10406912
I0816 10:11:02.968520 20528 layer_factory.hpp:77] Creating layer relu2_1
I0816 10:11:02.968530 20528 net.cpp:100] Creating Layer relu2_1
I0816 10:11:02.968538 20528 net.cpp:434] relu2_1 <- conv2_1
I0816 10:11:02.968545 20528 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0816 10:11:02.969512 20528 net.cpp:150] Setting up relu2_1
I0816 10:11:02.969529 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.969535 20528 net.cpp:165] Memory required for data: 11042816
I0816 10:11:02.969547 20528 layer_factory.hpp:77] Creating layer conv2_2
I0816 10:11:02.969559 20528 net.cpp:100] Creating Layer conv2_2
I0816 10:11:02.969565 20528 net.cpp:434] conv2_2 <- conv2_1
I0816 10:11:02.969574 20528 net.cpp:408] conv2_2 -> conv2_2
I0816 10:11:02.974330 20528 net.cpp:150] Setting up conv2_2
I0816 10:11:02.974349 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.974355 20528 net.cpp:165] Memory required for data: 11678720
I0816 10:11:02.974365 20528 layer_factory.hpp:77] Creating layer relu2_2
I0816 10:11:02.974375 20528 net.cpp:100] Creating Layer relu2_2
I0816 10:11:02.974381 20528 net.cpp:434] relu2_2 <- conv2_2
I0816 10:11:02.974390 20528 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0816 10:11:02.975345 20528 net.cpp:150] Setting up relu2_2
I0816 10:11:02.975363 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.975368 20528 net.cpp:165] Memory required for data: 12314624
I0816 10:11:02.975376 20528 layer_factory.hpp:77] Creating layer res2_2
I0816 10:11:02.975388 20528 net.cpp:100] Creating Layer res2_2
I0816 10:11:02.975394 20528 net.cpp:434] res2_2 <- pool1b_pool1b_0_split_1
I0816 10:11:02.975400 20528 net.cpp:434] res2_2 <- conv2_2
I0816 10:11:02.975409 20528 net.cpp:408] res2_2 -> res2_2
I0816 10:11:02.975456 20528 net.cpp:150] Setting up res2_2
I0816 10:11:02.975466 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:02.975471 20528 net.cpp:165] Memory required for data: 12950528
I0816 10:11:02.975476 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:02.975488 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:02.975494 20528 net.cpp:434] conv2 <- res2_2
I0816 10:11:02.975502 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:02.978718 20528 net.cpp:150] Setting up conv2
I0816 10:11:02.978742 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:02.978749 20528 net.cpp:165] Memory required for data: 14121984
I0816 10:11:02.978760 20528 layer_factory.hpp:77] Creating layer relu2
I0816 10:11:02.978768 20528 net.cpp:100] Creating Layer relu2
I0816 10:11:02.978775 20528 net.cpp:434] relu2 <- conv2
I0816 10:11:02.978782 20528 net.cpp:395] relu2 -> conv2 (in-place)
I0816 10:11:02.981386 20528 net.cpp:150] Setting up relu2
I0816 10:11:02.981407 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:02.981413 20528 net.cpp:165] Memory required for data: 15293440
I0816 10:11:02.981427 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:02.981441 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:02.981448 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:02.981461 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:02.981557 20528 net.cpp:150] Setting up pool2
I0816 10:11:02.981567 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:02.981572 20528 net.cpp:165] Memory required for data: 15586304
I0816 10:11:02.981577 20528 layer_factory.hpp:77] Creating layer pool2_pool2_0_split
I0816 10:11:02.981587 20528 net.cpp:100] Creating Layer pool2_pool2_0_split
I0816 10:11:02.981593 20528 net.cpp:434] pool2_pool2_0_split <- pool2
I0816 10:11:02.981611 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_0
I0816 10:11:02.981621 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_1
I0816 10:11:02.981685 20528 net.cpp:150] Setting up pool2_pool2_0_split
I0816 10:11:02.981696 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:02.981710 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:02.981715 20528 net.cpp:165] Memory required for data: 16172032
I0816 10:11:02.981720 20528 layer_factory.hpp:77] Creating layer conv3_1
I0816 10:11:02.981750 20528 net.cpp:100] Creating Layer conv3_1
I0816 10:11:02.981757 20528 net.cpp:434] conv3_1 <- pool2_pool2_0_split_0
I0816 10:11:02.981768 20528 net.cpp:408] conv3_1 -> conv3_1
I0816 10:11:02.991755 20528 net.cpp:150] Setting up conv3_1
I0816 10:11:02.991775 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:02.991780 20528 net.cpp:165] Memory required for data: 16464896
I0816 10:11:02.991799 20528 layer_factory.hpp:77] Creating layer relu3_1
I0816 10:11:02.991811 20528 net.cpp:100] Creating Layer relu3_1
I0816 10:11:02.991817 20528 net.cpp:434] relu3_1 <- conv3_1
I0816 10:11:02.991827 20528 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0816 10:11:02.992022 20528 net.cpp:150] Setting up relu3_1
I0816 10:11:02.992033 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:02.992038 20528 net.cpp:165] Memory required for data: 16757760
I0816 10:11:02.992045 20528 layer_factory.hpp:77] Creating layer conv3_2
I0816 10:11:02.992059 20528 net.cpp:100] Creating Layer conv3_2
I0816 10:11:02.992065 20528 net.cpp:434] conv3_2 <- conv3_1
I0816 10:11:02.992075 20528 net.cpp:408] conv3_2 -> conv3_2
I0816 10:11:03.001634 20528 net.cpp:150] Setting up conv3_2
I0816 10:11:03.001657 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.001662 20528 net.cpp:165] Memory required for data: 17050624
I0816 10:11:03.001673 20528 layer_factory.hpp:77] Creating layer relu3_2
I0816 10:11:03.001684 20528 net.cpp:100] Creating Layer relu3_2
I0816 10:11:03.001691 20528 net.cpp:434] relu3_2 <- conv3_2
I0816 10:11:03.001700 20528 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0816 10:11:03.001909 20528 net.cpp:150] Setting up relu3_2
I0816 10:11:03.001921 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.001926 20528 net.cpp:165] Memory required for data: 17343488
I0816 10:11:03.001935 20528 layer_factory.hpp:77] Creating layer res3_2
I0816 10:11:03.001945 20528 net.cpp:100] Creating Layer res3_2
I0816 10:11:03.001951 20528 net.cpp:434] res3_2 <- pool2_pool2_0_split_1
I0816 10:11:03.001958 20528 net.cpp:434] res3_2 <- conv3_2
I0816 10:11:03.001968 20528 net.cpp:408] res3_2 -> res3_2
I0816 10:11:03.002012 20528 net.cpp:150] Setting up res3_2
I0816 10:11:03.002020 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.002025 20528 net.cpp:165] Memory required for data: 17636352
I0816 10:11:03.002032 20528 layer_factory.hpp:77] Creating layer res3_2_res3_2_0_split
I0816 10:11:03.002040 20528 net.cpp:100] Creating Layer res3_2_res3_2_0_split
I0816 10:11:03.002046 20528 net.cpp:434] res3_2_res3_2_0_split <- res3_2
I0816 10:11:03.002054 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_0
I0816 10:11:03.002068 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_1
I0816 10:11:03.002130 20528 net.cpp:150] Setting up res3_2_res3_2_0_split
I0816 10:11:03.002140 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.002146 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.002151 20528 net.cpp:165] Memory required for data: 18222080
I0816 10:11:03.002157 20528 layer_factory.hpp:77] Creating layer conv3_3
I0816 10:11:03.002171 20528 net.cpp:100] Creating Layer conv3_3
I0816 10:11:03.002177 20528 net.cpp:434] conv3_3 <- res3_2_res3_2_0_split_0
I0816 10:11:03.002185 20528 net.cpp:408] conv3_3 -> conv3_3
I0816 10:11:03.012709 20528 net.cpp:150] Setting up conv3_3
I0816 10:11:03.012734 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.012742 20528 net.cpp:165] Memory required for data: 18514944
I0816 10:11:03.012753 20528 layer_factory.hpp:77] Creating layer relu3_3
I0816 10:11:03.012763 20528 net.cpp:100] Creating Layer relu3_3
I0816 10:11:03.012770 20528 net.cpp:434] relu3_3 <- conv3_3
I0816 10:11:03.012779 20528 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0816 10:11:03.012974 20528 net.cpp:150] Setting up relu3_3
I0816 10:11:03.012995 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.013000 20528 net.cpp:165] Memory required for data: 18807808
I0816 10:11:03.013008 20528 layer_factory.hpp:77] Creating layer conv3_4
I0816 10:11:03.013023 20528 net.cpp:100] Creating Layer conv3_4
I0816 10:11:03.013029 20528 net.cpp:434] conv3_4 <- conv3_3
I0816 10:11:03.013041 20528 net.cpp:408] conv3_4 -> conv3_4
I0816 10:11:03.023823 20528 net.cpp:150] Setting up conv3_4
I0816 10:11:03.023844 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.023849 20528 net.cpp:165] Memory required for data: 19100672
I0816 10:11:03.023861 20528 layer_factory.hpp:77] Creating layer relu3_4
I0816 10:11:03.023871 20528 net.cpp:100] Creating Layer relu3_4
I0816 10:11:03.023878 20528 net.cpp:434] relu3_4 <- conv3_4
I0816 10:11:03.023886 20528 net.cpp:395] relu3_4 -> conv3_4 (in-place)
I0816 10:11:03.024086 20528 net.cpp:150] Setting up relu3_4
I0816 10:11:03.024097 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.024102 20528 net.cpp:165] Memory required for data: 19393536
I0816 10:11:03.024109 20528 layer_factory.hpp:77] Creating layer res3_4
I0816 10:11:03.024121 20528 net.cpp:100] Creating Layer res3_4
I0816 10:11:03.024127 20528 net.cpp:434] res3_4 <- res3_2_res3_2_0_split_1
I0816 10:11:03.024133 20528 net.cpp:434] res3_4 <- conv3_4
I0816 10:11:03.024143 20528 net.cpp:408] res3_4 -> res3_4
I0816 10:11:03.024189 20528 net.cpp:150] Setting up res3_4
I0816 10:11:03.024199 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:03.024204 20528 net.cpp:165] Memory required for data: 19686400
I0816 10:11:03.024209 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:03.024235 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:03.024241 20528 net.cpp:434] conv3 <- res3_4
I0816 10:11:03.024250 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:03.029131 20528 net.cpp:150] Setting up conv3
I0816 10:11:03.029152 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:03.029158 20528 net.cpp:165] Memory required for data: 20177920
I0816 10:11:03.029168 20528 layer_factory.hpp:77] Creating layer relu3
I0816 10:11:03.029177 20528 net.cpp:100] Creating Layer relu3
I0816 10:11:03.029183 20528 net.cpp:434] relu3 <- conv3
I0816 10:11:03.029192 20528 net.cpp:395] relu3 -> conv3 (in-place)
I0816 10:11:03.030135 20528 net.cpp:150] Setting up relu3
I0816 10:11:03.030153 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:03.030158 20528 net.cpp:165] Memory required for data: 20669440
I0816 10:11:03.030166 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:03.030176 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:03.030182 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:03.030191 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:03.030266 20528 net.cpp:150] Setting up pool3
I0816 10:11:03.030275 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.030280 20528 net.cpp:165] Memory required for data: 20792320
I0816 10:11:03.030285 20528 layer_factory.hpp:77] Creating layer pool3_pool3_0_split
I0816 10:11:03.030294 20528 net.cpp:100] Creating Layer pool3_pool3_0_split
I0816 10:11:03.030300 20528 net.cpp:434] pool3_pool3_0_split <- pool3
I0816 10:11:03.030308 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_0
I0816 10:11:03.030318 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_1
I0816 10:11:03.030378 20528 net.cpp:150] Setting up pool3_pool3_0_split
I0816 10:11:03.030387 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.030395 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.030400 20528 net.cpp:165] Memory required for data: 21038080
I0816 10:11:03.030405 20528 layer_factory.hpp:77] Creating layer conv4_1
I0816 10:11:03.030418 20528 net.cpp:100] Creating Layer conv4_1
I0816 10:11:03.030424 20528 net.cpp:434] conv4_1 <- pool3_pool3_0_split_0
I0816 10:11:03.030434 20528 net.cpp:408] conv4_1 -> conv4_1
I0816 10:11:03.056932 20528 net.cpp:150] Setting up conv4_1
I0816 10:11:03.056953 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.056959 20528 net.cpp:165] Memory required for data: 21160960
I0816 10:11:03.056977 20528 layer_factory.hpp:77] Creating layer relu4_1
I0816 10:11:03.056991 20528 net.cpp:100] Creating Layer relu4_1
I0816 10:11:03.056998 20528 net.cpp:434] relu4_1 <- conv4_1
I0816 10:11:03.057008 20528 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0816 10:11:03.057272 20528 net.cpp:150] Setting up relu4_1
I0816 10:11:03.057287 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.057292 20528 net.cpp:165] Memory required for data: 21283840
I0816 10:11:03.057312 20528 layer_factory.hpp:77] Creating layer conv4_2
I0816 10:11:03.057327 20528 net.cpp:100] Creating Layer conv4_2
I0816 10:11:03.057332 20528 net.cpp:434] conv4_2 <- conv4_1
I0816 10:11:03.057343 20528 net.cpp:408] conv4_2 -> conv4_2
I0816 10:11:03.084058 20528 net.cpp:150] Setting up conv4_2
I0816 10:11:03.084079 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.084085 20528 net.cpp:165] Memory required for data: 21406720
I0816 10:11:03.084096 20528 layer_factory.hpp:77] Creating layer relu4_2
I0816 10:11:03.084106 20528 net.cpp:100] Creating Layer relu4_2
I0816 10:11:03.084113 20528 net.cpp:434] relu4_2 <- conv4_2
I0816 10:11:03.084121 20528 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0816 10:11:03.084312 20528 net.cpp:150] Setting up relu4_2
I0816 10:11:03.084323 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.084328 20528 net.cpp:165] Memory required for data: 21529600
I0816 10:11:03.084336 20528 layer_factory.hpp:77] Creating layer res4_2
I0816 10:11:03.084347 20528 net.cpp:100] Creating Layer res4_2
I0816 10:11:03.084352 20528 net.cpp:434] res4_2 <- pool3_pool3_0_split_1
I0816 10:11:03.084359 20528 net.cpp:434] res4_2 <- conv4_2
I0816 10:11:03.084368 20528 net.cpp:408] res4_2 -> res4_2
I0816 10:11:03.084414 20528 net.cpp:150] Setting up res4_2
I0816 10:11:03.084422 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.084427 20528 net.cpp:165] Memory required for data: 21652480
I0816 10:11:03.084432 20528 layer_factory.hpp:77] Creating layer res4_2_res4_2_0_split
I0816 10:11:03.084442 20528 net.cpp:100] Creating Layer res4_2_res4_2_0_split
I0816 10:11:03.084447 20528 net.cpp:434] res4_2_res4_2_0_split <- res4_2
I0816 10:11:03.084455 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_0
I0816 10:11:03.084463 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_1
I0816 10:11:03.084527 20528 net.cpp:150] Setting up res4_2_res4_2_0_split
I0816 10:11:03.084537 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.084542 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.084547 20528 net.cpp:165] Memory required for data: 21898240
I0816 10:11:03.084553 20528 layer_factory.hpp:77] Creating layer conv4_3
I0816 10:11:03.084565 20528 net.cpp:100] Creating Layer conv4_3
I0816 10:11:03.084571 20528 net.cpp:434] conv4_3 <- res4_2_res4_2_0_split_0
I0816 10:11:03.084583 20528 net.cpp:408] conv4_3 -> conv4_3
I0816 10:11:03.111301 20528 net.cpp:150] Setting up conv4_3
I0816 10:11:03.111326 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.111332 20528 net.cpp:165] Memory required for data: 22021120
I0816 10:11:03.111346 20528 layer_factory.hpp:77] Creating layer relu4_3
I0816 10:11:03.111359 20528 net.cpp:100] Creating Layer relu4_3
I0816 10:11:03.111368 20528 net.cpp:434] relu4_3 <- conv4_3
I0816 10:11:03.111379 20528 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0816 10:11:03.111593 20528 net.cpp:150] Setting up relu4_3
I0816 10:11:03.111604 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.111610 20528 net.cpp:165] Memory required for data: 22144000
I0816 10:11:03.111618 20528 layer_factory.hpp:77] Creating layer conv4_4
I0816 10:11:03.111634 20528 net.cpp:100] Creating Layer conv4_4
I0816 10:11:03.111641 20528 net.cpp:434] conv4_4 <- conv4_3
I0816 10:11:03.111650 20528 net.cpp:408] conv4_4 -> conv4_4
I0816 10:11:03.140810 20528 net.cpp:150] Setting up conv4_4
I0816 10:11:03.140858 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.140866 20528 net.cpp:165] Memory required for data: 22266880
I0816 10:11:03.140894 20528 layer_factory.hpp:77] Creating layer relu4_4
I0816 10:11:03.140914 20528 net.cpp:100] Creating Layer relu4_4
I0816 10:11:03.140928 20528 net.cpp:434] relu4_4 <- conv4_4
I0816 10:11:03.140947 20528 net.cpp:395] relu4_4 -> conv4_4 (in-place)
I0816 10:11:03.141212 20528 net.cpp:150] Setting up relu4_4
I0816 10:11:03.141228 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.141233 20528 net.cpp:165] Memory required for data: 22389760
I0816 10:11:03.141242 20528 layer_factory.hpp:77] Creating layer res4_4
I0816 10:11:03.141255 20528 net.cpp:100] Creating Layer res4_4
I0816 10:11:03.141263 20528 net.cpp:434] res4_4 <- res4_2_res4_2_0_split_1
I0816 10:11:03.141269 20528 net.cpp:434] res4_4 <- conv4_4
I0816 10:11:03.141280 20528 net.cpp:408] res4_4 -> res4_4
I0816 10:11:03.141366 20528 net.cpp:150] Setting up res4_4
I0816 10:11:03.141381 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.141387 20528 net.cpp:165] Memory required for data: 22512640
I0816 10:11:03.141396 20528 layer_factory.hpp:77] Creating layer res4_4_res4_4_0_split
I0816 10:11:03.141407 20528 net.cpp:100] Creating Layer res4_4_res4_4_0_split
I0816 10:11:03.141412 20528 net.cpp:434] res4_4_res4_4_0_split <- res4_4
I0816 10:11:03.141423 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_0
I0816 10:11:03.141433 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_1
I0816 10:11:03.141536 20528 net.cpp:150] Setting up res4_4_res4_4_0_split
I0816 10:11:03.141552 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.141559 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.141564 20528 net.cpp:165] Memory required for data: 22758400
I0816 10:11:03.141571 20528 layer_factory.hpp:77] Creating layer conv4_5
I0816 10:11:03.141588 20528 net.cpp:100] Creating Layer conv4_5
I0816 10:11:03.141595 20528 net.cpp:434] conv4_5 <- res4_4_res4_4_0_split_0
I0816 10:11:03.141607 20528 net.cpp:408] conv4_5 -> conv4_5
I0816 10:11:03.171571 20528 net.cpp:150] Setting up conv4_5
I0816 10:11:03.171622 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.171628 20528 net.cpp:165] Memory required for data: 22881280
I0816 10:11:03.171650 20528 layer_factory.hpp:77] Creating layer relu4_5
I0816 10:11:03.171676 20528 net.cpp:100] Creating Layer relu4_5
I0816 10:11:03.171691 20528 net.cpp:434] relu4_5 <- conv4_5
I0816 10:11:03.171705 20528 net.cpp:395] relu4_5 -> conv4_5 (in-place)
I0816 10:11:03.171988 20528 net.cpp:150] Setting up relu4_5
I0816 10:11:03.172003 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.172009 20528 net.cpp:165] Memory required for data: 23004160
I0816 10:11:03.172024 20528 layer_factory.hpp:77] Creating layer conv4_6
I0816 10:11:03.172053 20528 net.cpp:100] Creating Layer conv4_6
I0816 10:11:03.172068 20528 net.cpp:434] conv4_6 <- conv4_5
I0816 10:11:03.172082 20528 net.cpp:408] conv4_6 -> conv4_6
I0816 10:11:03.210862 20528 net.cpp:150] Setting up conv4_6
I0816 10:11:03.210928 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.210938 20528 net.cpp:165] Memory required for data: 23127040
I0816 10:11:03.210958 20528 layer_factory.hpp:77] Creating layer relu4_6
I0816 10:11:03.210978 20528 net.cpp:100] Creating Layer relu4_6
I0816 10:11:03.210990 20528 net.cpp:434] relu4_6 <- conv4_6
I0816 10:11:03.211006 20528 net.cpp:395] relu4_6 -> conv4_6 (in-place)
I0816 10:11:03.211323 20528 net.cpp:150] Setting up relu4_6
I0816 10:11:03.211340 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.211349 20528 net.cpp:165] Memory required for data: 23249920
I0816 10:11:03.211361 20528 layer_factory.hpp:77] Creating layer res4_6
I0816 10:11:03.211378 20528 net.cpp:100] Creating Layer res4_6
I0816 10:11:03.211390 20528 net.cpp:434] res4_6 <- res4_4_res4_4_0_split_1
I0816 10:11:03.211401 20528 net.cpp:434] res4_6 <- conv4_6
I0816 10:11:03.211416 20528 net.cpp:408] res4_6 -> res4_6
I0816 10:11:03.211486 20528 net.cpp:150] Setting up res4_6
I0816 10:11:03.211501 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.211524 20528 net.cpp:165] Memory required for data: 23372800
I0816 10:11:03.211534 20528 layer_factory.hpp:77] Creating layer res4_6_res4_6_0_split
I0816 10:11:03.211549 20528 net.cpp:100] Creating Layer res4_6_res4_6_0_split
I0816 10:11:03.211558 20528 net.cpp:434] res4_6_res4_6_0_split <- res4_6
I0816 10:11:03.211570 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_0
I0816 10:11:03.211585 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_1
I0816 10:11:03.211693 20528 net.cpp:150] Setting up res4_6_res4_6_0_split
I0816 10:11:03.211709 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.211719 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.211727 20528 net.cpp:165] Memory required for data: 23618560
I0816 10:11:03.211745 20528 layer_factory.hpp:77] Creating layer conv4_7
I0816 10:11:03.211769 20528 net.cpp:100] Creating Layer conv4_7
I0816 10:11:03.211781 20528 net.cpp:434] conv4_7 <- res4_6_res4_6_0_split_0
I0816 10:11:03.211796 20528 net.cpp:408] conv4_7 -> conv4_7
I0816 10:11:03.249605 20528 net.cpp:150] Setting up conv4_7
I0816 10:11:03.249670 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.249682 20528 net.cpp:165] Memory required for data: 23741440
I0816 10:11:03.249704 20528 layer_factory.hpp:77] Creating layer relu4_7
I0816 10:11:03.249724 20528 net.cpp:100] Creating Layer relu4_7
I0816 10:11:03.249747 20528 net.cpp:434] relu4_7 <- conv4_7
I0816 10:11:03.249765 20528 net.cpp:395] relu4_7 -> conv4_7 (in-place)
I0816 10:11:03.250103 20528 net.cpp:150] Setting up relu4_7
I0816 10:11:03.250123 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.250133 20528 net.cpp:165] Memory required for data: 23864320
I0816 10:11:03.250144 20528 layer_factory.hpp:77] Creating layer conv4_8
I0816 10:11:03.250170 20528 net.cpp:100] Creating Layer conv4_8
I0816 10:11:03.250180 20528 net.cpp:434] conv4_8 <- conv4_7
I0816 10:11:03.250195 20528 net.cpp:408] conv4_8 -> conv4_8
I0816 10:11:03.286777 20528 net.cpp:150] Setting up conv4_8
I0816 10:11:03.286845 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.286855 20528 net.cpp:165] Memory required for data: 23987200
I0816 10:11:03.286875 20528 layer_factory.hpp:77] Creating layer relu4_8
I0816 10:11:03.286895 20528 net.cpp:100] Creating Layer relu4_8
I0816 10:11:03.286907 20528 net.cpp:434] relu4_8 <- conv4_8
I0816 10:11:03.286923 20528 net.cpp:395] relu4_8 -> conv4_8 (in-place)
I0816 10:11:03.288283 20528 net.cpp:150] Setting up relu4_8
I0816 10:11:03.288308 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.288317 20528 net.cpp:165] Memory required for data: 24110080
I0816 10:11:03.288333 20528 layer_factory.hpp:77] Creating layer res4_8
I0816 10:11:03.288349 20528 net.cpp:100] Creating Layer res4_8
I0816 10:11:03.288362 20528 net.cpp:434] res4_8 <- res4_6_res4_6_0_split_1
I0816 10:11:03.288373 20528 net.cpp:434] res4_8 <- conv4_8
I0816 10:11:03.288388 20528 net.cpp:408] res4_8 -> res4_8
I0816 10:11:03.288463 20528 net.cpp:150] Setting up res4_8
I0816 10:11:03.288481 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.288491 20528 net.cpp:165] Memory required for data: 24232960
I0816 10:11:03.288498 20528 layer_factory.hpp:77] Creating layer res4_8_res4_8_0_split
I0816 10:11:03.288512 20528 net.cpp:100] Creating Layer res4_8_res4_8_0_split
I0816 10:11:03.288522 20528 net.cpp:434] res4_8_res4_8_0_split <- res4_8
I0816 10:11:03.288534 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_0
I0816 10:11:03.288547 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_1
I0816 10:11:03.288657 20528 net.cpp:150] Setting up res4_8_res4_8_0_split
I0816 10:11:03.288673 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.288684 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.288692 20528 net.cpp:165] Memory required for data: 24478720
I0816 10:11:03.288702 20528 layer_factory.hpp:77] Creating layer conv4_9
I0816 10:11:03.288724 20528 net.cpp:100] Creating Layer conv4_9
I0816 10:11:03.288756 20528 net.cpp:434] conv4_9 <- res4_8_res4_8_0_split_0
I0816 10:11:03.288775 20528 net.cpp:408] conv4_9 -> conv4_9
I0816 10:11:03.325141 20528 net.cpp:150] Setting up conv4_9
I0816 10:11:03.325201 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.325211 20528 net.cpp:165] Memory required for data: 24601600
I0816 10:11:03.325232 20528 layer_factory.hpp:77] Creating layer relu4_9
I0816 10:11:03.325253 20528 net.cpp:100] Creating Layer relu4_9
I0816 10:11:03.325266 20528 net.cpp:434] relu4_9 <- conv4_9
I0816 10:11:03.325283 20528 net.cpp:395] relu4_9 -> conv4_9 (in-place)
I0816 10:11:03.325598 20528 net.cpp:150] Setting up relu4_9
I0816 10:11:03.325618 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.325625 20528 net.cpp:165] Memory required for data: 24724480
I0816 10:11:03.325640 20528 layer_factory.hpp:77] Creating layer conv4_10
I0816 10:11:03.325662 20528 net.cpp:100] Creating Layer conv4_10
I0816 10:11:03.325672 20528 net.cpp:434] conv4_10 <- conv4_9
I0816 10:11:03.325688 20528 net.cpp:408] conv4_10 -> conv4_10
I0816 10:11:03.361445 20528 net.cpp:150] Setting up conv4_10
I0816 10:11:03.361505 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.361515 20528 net.cpp:165] Memory required for data: 24847360
I0816 10:11:03.361534 20528 layer_factory.hpp:77] Creating layer relu4_10
I0816 10:11:03.361553 20528 net.cpp:100] Creating Layer relu4_10
I0816 10:11:03.361565 20528 net.cpp:434] relu4_10 <- conv4_10
I0816 10:11:03.361583 20528 net.cpp:395] relu4_10 -> conv4_10 (in-place)
I0816 10:11:03.361914 20528 net.cpp:150] Setting up relu4_10
I0816 10:11:03.361933 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.361943 20528 net.cpp:165] Memory required for data: 24970240
I0816 10:11:03.361954 20528 layer_factory.hpp:77] Creating layer res4_10
I0816 10:11:03.361973 20528 net.cpp:100] Creating Layer res4_10
I0816 10:11:03.361984 20528 net.cpp:434] res4_10 <- res4_8_res4_8_0_split_1
I0816 10:11:03.361995 20528 net.cpp:434] res4_10 <- conv4_10
I0816 10:11:03.362010 20528 net.cpp:408] res4_10 -> res4_10
I0816 10:11:03.362082 20528 net.cpp:150] Setting up res4_10
I0816 10:11:03.362098 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:03.362107 20528 net.cpp:165] Memory required for data: 25093120
I0816 10:11:03.362115 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:03.362138 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:03.362148 20528 net.cpp:434] conv4 <- res4_10
I0816 10:11:03.362162 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:03.381976 20528 net.cpp:150] Setting up conv4
I0816 10:11:03.382015 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:03.382025 20528 net.cpp:165] Memory required for data: 25256960
I0816 10:11:03.382041 20528 layer_factory.hpp:77] Creating layer relu4
I0816 10:11:03.382057 20528 net.cpp:100] Creating Layer relu4
I0816 10:11:03.382067 20528 net.cpp:434] relu4 <- conv4
I0816 10:11:03.382083 20528 net.cpp:395] relu4 -> conv4 (in-place)
I0816 10:11:03.382418 20528 net.cpp:150] Setting up relu4
I0816 10:11:03.382436 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:03.382444 20528 net.cpp:165] Memory required for data: 25420800
I0816 10:11:03.382457 20528 layer_factory.hpp:77] Creating layer pool4
I0816 10:11:03.382477 20528 net.cpp:100] Creating Layer pool4
I0816 10:11:03.382488 20528 net.cpp:434] pool4 <- conv4
I0816 10:11:03.382499 20528 net.cpp:408] pool4 -> pool4
I0816 10:11:03.382622 20528 net.cpp:150] Setting up pool4
I0816 10:11:03.382638 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.382647 20528 net.cpp:165] Memory required for data: 25461760
I0816 10:11:03.382655 20528 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I0816 10:11:03.382668 20528 net.cpp:100] Creating Layer pool4_pool4_0_split
I0816 10:11:03.382678 20528 net.cpp:434] pool4_pool4_0_split <- pool4
I0816 10:11:03.382691 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_0
I0816 10:11:03.382705 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_1
I0816 10:11:03.382827 20528 net.cpp:150] Setting up pool4_pool4_0_split
I0816 10:11:03.382861 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.382874 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.382882 20528 net.cpp:165] Memory required for data: 25543680
I0816 10:11:03.382892 20528 layer_factory.hpp:77] Creating layer conv5_1
I0816 10:11:03.382932 20528 net.cpp:100] Creating Layer conv5_1
I0816 10:11:03.382944 20528 net.cpp:434] conv5_1 <- pool4_pool4_0_split_0
I0816 10:11:03.382959 20528 net.cpp:408] conv5_1 -> conv5_1
I0816 10:11:03.516475 20528 net.cpp:150] Setting up conv5_1
I0816 10:11:03.516543 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.516554 20528 net.cpp:165] Memory required for data: 25584640
I0816 10:11:03.516605 20528 layer_factory.hpp:77] Creating layer relu5_1
I0816 10:11:03.516626 20528 net.cpp:100] Creating Layer relu5_1
I0816 10:11:03.516639 20528 net.cpp:434] relu5_1 <- conv5_1
I0816 10:11:03.516654 20528 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0816 10:11:03.517022 20528 net.cpp:150] Setting up relu5_1
I0816 10:11:03.517043 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.517052 20528 net.cpp:165] Memory required for data: 25625600
I0816 10:11:03.517067 20528 layer_factory.hpp:77] Creating layer conv5_2
I0816 10:11:03.517096 20528 net.cpp:100] Creating Layer conv5_2
I0816 10:11:03.517107 20528 net.cpp:434] conv5_2 <- conv5_1
I0816 10:11:03.517122 20528 net.cpp:408] conv5_2 -> conv5_2
I0816 10:11:03.653772 20528 net.cpp:150] Setting up conv5_2
I0816 10:11:03.653836 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.653847 20528 net.cpp:165] Memory required for data: 25666560
I0816 10:11:03.653867 20528 layer_factory.hpp:77] Creating layer relu5_2
I0816 10:11:03.653893 20528 net.cpp:100] Creating Layer relu5_2
I0816 10:11:03.653908 20528 net.cpp:434] relu5_2 <- conv5_2
I0816 10:11:03.653925 20528 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0816 10:11:03.654243 20528 net.cpp:150] Setting up relu5_2
I0816 10:11:03.654265 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.654274 20528 net.cpp:165] Memory required for data: 25707520
I0816 10:11:03.654289 20528 layer_factory.hpp:77] Creating layer res5_2
I0816 10:11:03.654304 20528 net.cpp:100] Creating Layer res5_2
I0816 10:11:03.654315 20528 net.cpp:434] res5_2 <- pool4_pool4_0_split_1
I0816 10:11:03.654327 20528 net.cpp:434] res5_2 <- conv5_2
I0816 10:11:03.654341 20528 net.cpp:408] res5_2 -> res5_2
I0816 10:11:03.654413 20528 net.cpp:150] Setting up res5_2
I0816 10:11:03.654430 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.654439 20528 net.cpp:165] Memory required for data: 25748480
I0816 10:11:03.654449 20528 layer_factory.hpp:77] Creating layer res5_2_res5_2_0_split
I0816 10:11:03.654462 20528 net.cpp:100] Creating Layer res5_2_res5_2_0_split
I0816 10:11:03.654474 20528 net.cpp:434] res5_2_res5_2_0_split <- res5_2
I0816 10:11:03.654485 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_0
I0816 10:11:03.654500 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_1
I0816 10:11:03.654611 20528 net.cpp:150] Setting up res5_2_res5_2_0_split
I0816 10:11:03.654628 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.654639 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.654647 20528 net.cpp:165] Memory required for data: 25830400
I0816 10:11:03.654656 20528 layer_factory.hpp:77] Creating layer conv5_3
I0816 10:11:03.654680 20528 net.cpp:100] Creating Layer conv5_3
I0816 10:11:03.654691 20528 net.cpp:434] conv5_3 <- res5_2_res5_2_0_split_0
I0816 10:11:03.654706 20528 net.cpp:408] conv5_3 -> conv5_3
I0816 10:11:03.785328 20528 net.cpp:150] Setting up conv5_3
I0816 10:11:03.785358 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.785368 20528 net.cpp:165] Memory required for data: 25871360
I0816 10:11:03.785384 20528 layer_factory.hpp:77] Creating layer relu5_3
I0816 10:11:03.785399 20528 net.cpp:100] Creating Layer relu5_3
I0816 10:11:03.785409 20528 net.cpp:434] relu5_3 <- conv5_3
I0816 10:11:03.785425 20528 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0816 10:11:03.785768 20528 net.cpp:150] Setting up relu5_3
I0816 10:11:03.785792 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.785801 20528 net.cpp:165] Memory required for data: 25912320
I0816 10:11:03.785815 20528 layer_factory.hpp:77] Creating layer conv5_4
I0816 10:11:03.785838 20528 net.cpp:100] Creating Layer conv5_4
I0816 10:11:03.785850 20528 net.cpp:434] conv5_4 <- conv5_3
I0816 10:11:03.785867 20528 net.cpp:408] conv5_4 -> conv5_4
I0816 10:11:03.915493 20528 net.cpp:150] Setting up conv5_4
I0816 10:11:03.915527 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.915539 20528 net.cpp:165] Memory required for data: 25953280
I0816 10:11:03.915556 20528 layer_factory.hpp:77] Creating layer relu5_4
I0816 10:11:03.915578 20528 net.cpp:100] Creating Layer relu5_4
I0816 10:11:03.915591 20528 net.cpp:434] relu5_4 <- conv5_4
I0816 10:11:03.915606 20528 net.cpp:395] relu5_4 -> conv5_4 (in-place)
I0816 10:11:03.915944 20528 net.cpp:150] Setting up relu5_4
I0816 10:11:03.915967 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.915977 20528 net.cpp:165] Memory required for data: 25994240
I0816 10:11:03.915989 20528 layer_factory.hpp:77] Creating layer res5_4
I0816 10:11:03.916007 20528 net.cpp:100] Creating Layer res5_4
I0816 10:11:03.916019 20528 net.cpp:434] res5_4 <- res5_2_res5_2_0_split_1
I0816 10:11:03.916031 20528 net.cpp:434] res5_4 <- conv5_4
I0816 10:11:03.916043 20528 net.cpp:408] res5_4 -> res5_4
I0816 10:11:03.916121 20528 net.cpp:150] Setting up res5_4
I0816 10:11:03.916141 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.916149 20528 net.cpp:165] Memory required for data: 26035200
I0816 10:11:03.916159 20528 layer_factory.hpp:77] Creating layer res5_4_res5_4_0_split
I0816 10:11:03.916172 20528 net.cpp:100] Creating Layer res5_4_res5_4_0_split
I0816 10:11:03.916182 20528 net.cpp:434] res5_4_res5_4_0_split <- res5_4
I0816 10:11:03.916203 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_0
I0816 10:11:03.916218 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_1
I0816 10:11:03.916333 20528 net.cpp:150] Setting up res5_4_res5_4_0_split
I0816 10:11:03.916353 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.916366 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:03.916374 20528 net.cpp:165] Memory required for data: 26117120
I0816 10:11:03.916383 20528 layer_factory.hpp:77] Creating layer conv5_5
I0816 10:11:03.916409 20528 net.cpp:100] Creating Layer conv5_5
I0816 10:11:03.916421 20528 net.cpp:434] conv5_5 <- res5_4_res5_4_0_split_0
I0816 10:11:03.916436 20528 net.cpp:408] conv5_5 -> conv5_5
I0816 10:11:04.047365 20528 net.cpp:150] Setting up conv5_5
I0816 10:11:04.047410 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:04.047420 20528 net.cpp:165] Memory required for data: 26158080
I0816 10:11:04.047438 20528 layer_factory.hpp:77] Creating layer relu5_5
I0816 10:11:04.047458 20528 net.cpp:100] Creating Layer relu5_5
I0816 10:11:04.047472 20528 net.cpp:434] relu5_5 <- conv5_5
I0816 10:11:04.047487 20528 net.cpp:395] relu5_5 -> conv5_5 (in-place)
I0816 10:11:04.047827 20528 net.cpp:150] Setting up relu5_5
I0816 10:11:04.047852 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:04.047860 20528 net.cpp:165] Memory required for data: 26199040
I0816 10:11:04.047876 20528 layer_factory.hpp:77] Creating layer conv5_6
I0816 10:11:04.047905 20528 net.cpp:100] Creating Layer conv5_6
I0816 10:11:04.047917 20528 net.cpp:434] conv5_6 <- conv5_5
I0816 10:11:04.047932 20528 net.cpp:408] conv5_6 -> conv5_6
I0816 10:11:04.180877 20528 net.cpp:150] Setting up conv5_6
I0816 10:11:04.180913 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:04.180924 20528 net.cpp:165] Memory required for data: 26240000
I0816 10:11:04.180943 20528 layer_factory.hpp:77] Creating layer relu5_6
I0816 10:11:04.180961 20528 net.cpp:100] Creating Layer relu5_6
I0816 10:11:04.180971 20528 net.cpp:434] relu5_6 <- conv5_6
I0816 10:11:04.180985 20528 net.cpp:395] relu5_6 -> conv5_6 (in-place)
I0816 10:11:04.181329 20528 net.cpp:150] Setting up relu5_6
I0816 10:11:04.181351 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:04.181362 20528 net.cpp:165] Memory required for data: 26280960
I0816 10:11:04.181376 20528 layer_factory.hpp:77] Creating layer res5_6
I0816 10:11:04.181397 20528 net.cpp:100] Creating Layer res5_6
I0816 10:11:04.181408 20528 net.cpp:434] res5_6 <- res5_4_res5_4_0_split_1
I0816 10:11:04.181421 20528 net.cpp:434] res5_6 <- conv5_6
I0816 10:11:04.181433 20528 net.cpp:408] res5_6 -> res5_6
I0816 10:11:04.181529 20528 net.cpp:150] Setting up res5_6
I0816 10:11:04.181553 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:04.181562 20528 net.cpp:165] Memory required for data: 26321920
I0816 10:11:04.181571 20528 layer_factory.hpp:77] Creating layer fc5
I0816 10:11:04.181588 20528 net.cpp:100] Creating Layer fc5
I0816 10:11:04.181598 20528 net.cpp:434] fc5 <- res5_6
I0816 10:11:04.181614 20528 net.cpp:408] fc5 -> fc5
I0816 10:11:04.223295 20528 net.cpp:150] Setting up fc5
I0816 10:11:04.223346 20528 net.cpp:157] Top shape: 1 512 (512)
I0816 10:11:04.223352 20528 net.cpp:165] Memory required for data: 26323968
I0816 10:11:04.223367 20528 net.cpp:228] fc5 does not need backward computation.
I0816 10:11:04.223374 20528 net.cpp:228] res5_6 does not need backward computation.
I0816 10:11:04.223381 20528 net.cpp:228] relu5_6 does not need backward computation.
I0816 10:11:04.223387 20528 net.cpp:228] conv5_6 does not need backward computation.
I0816 10:11:04.223392 20528 net.cpp:228] relu5_5 does not need backward computation.
I0816 10:11:04.223397 20528 net.cpp:228] conv5_5 does not need backward computation.
I0816 10:11:04.223403 20528 net.cpp:228] res5_4_res5_4_0_split does not need backward computation.
I0816 10:11:04.223410 20528 net.cpp:228] res5_4 does not need backward computation.
I0816 10:11:04.223417 20528 net.cpp:228] relu5_4 does not need backward computation.
I0816 10:11:04.223423 20528 net.cpp:228] conv5_4 does not need backward computation.
I0816 10:11:04.223428 20528 net.cpp:228] relu5_3 does not need backward computation.
I0816 10:11:04.223433 20528 net.cpp:228] conv5_3 does not need backward computation.
I0816 10:11:04.223439 20528 net.cpp:228] res5_2_res5_2_0_split does not need backward computation.
I0816 10:11:04.223445 20528 net.cpp:228] res5_2 does not need backward computation.
I0816 10:11:04.223453 20528 net.cpp:228] relu5_2 does not need backward computation.
I0816 10:11:04.223459 20528 net.cpp:228] conv5_2 does not need backward computation.
I0816 10:11:04.223464 20528 net.cpp:228] relu5_1 does not need backward computation.
I0816 10:11:04.223469 20528 net.cpp:228] conv5_1 does not need backward computation.
I0816 10:11:04.223475 20528 net.cpp:228] pool4_pool4_0_split does not need backward computation.
I0816 10:11:04.223481 20528 net.cpp:228] pool4 does not need backward computation.
I0816 10:11:04.223487 20528 net.cpp:228] relu4 does not need backward computation.
I0816 10:11:04.223493 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:04.223500 20528 net.cpp:228] res4_10 does not need backward computation.
I0816 10:11:04.223506 20528 net.cpp:228] relu4_10 does not need backward computation.
I0816 10:11:04.223511 20528 net.cpp:228] conv4_10 does not need backward computation.
I0816 10:11:04.223517 20528 net.cpp:228] relu4_9 does not need backward computation.
I0816 10:11:04.223523 20528 net.cpp:228] conv4_9 does not need backward computation.
I0816 10:11:04.223529 20528 net.cpp:228] res4_8_res4_8_0_split does not need backward computation.
I0816 10:11:04.223536 20528 net.cpp:228] res4_8 does not need backward computation.
I0816 10:11:04.223541 20528 net.cpp:228] relu4_8 does not need backward computation.
I0816 10:11:04.223547 20528 net.cpp:228] conv4_8 does not need backward computation.
I0816 10:11:04.223553 20528 net.cpp:228] relu4_7 does not need backward computation.
I0816 10:11:04.223558 20528 net.cpp:228] conv4_7 does not need backward computation.
I0816 10:11:04.223564 20528 net.cpp:228] res4_6_res4_6_0_split does not need backward computation.
I0816 10:11:04.223580 20528 net.cpp:228] res4_6 does not need backward computation.
I0816 10:11:04.223589 20528 net.cpp:228] relu4_6 does not need backward computation.
I0816 10:11:04.223595 20528 net.cpp:228] conv4_6 does not need backward computation.
I0816 10:11:04.223601 20528 net.cpp:228] relu4_5 does not need backward computation.
I0816 10:11:04.223606 20528 net.cpp:228] conv4_5 does not need backward computation.
I0816 10:11:04.223613 20528 net.cpp:228] res4_4_res4_4_0_split does not need backward computation.
I0816 10:11:04.223618 20528 net.cpp:228] res4_4 does not need backward computation.
I0816 10:11:04.223624 20528 net.cpp:228] relu4_4 does not need backward computation.
I0816 10:11:04.223629 20528 net.cpp:228] conv4_4 does not need backward computation.
I0816 10:11:04.223636 20528 net.cpp:228] relu4_3 does not need backward computation.
I0816 10:11:04.223641 20528 net.cpp:228] conv4_3 does not need backward computation.
I0816 10:11:04.223647 20528 net.cpp:228] res4_2_res4_2_0_split does not need backward computation.
I0816 10:11:04.223654 20528 net.cpp:228] res4_2 does not need backward computation.
I0816 10:11:04.223659 20528 net.cpp:228] relu4_2 does not need backward computation.
I0816 10:11:04.223665 20528 net.cpp:228] conv4_2 does not need backward computation.
I0816 10:11:04.223670 20528 net.cpp:228] relu4_1 does not need backward computation.
I0816 10:11:04.223676 20528 net.cpp:228] conv4_1 does not need backward computation.
I0816 10:11:04.223682 20528 net.cpp:228] pool3_pool3_0_split does not need backward computation.
I0816 10:11:04.223688 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:04.223695 20528 net.cpp:228] relu3 does not need backward computation.
I0816 10:11:04.223700 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:04.223706 20528 net.cpp:228] res3_4 does not need backward computation.
I0816 10:11:04.223712 20528 net.cpp:228] relu3_4 does not need backward computation.
I0816 10:11:04.223718 20528 net.cpp:228] conv3_4 does not need backward computation.
I0816 10:11:04.223723 20528 net.cpp:228] relu3_3 does not need backward computation.
I0816 10:11:04.223734 20528 net.cpp:228] conv3_3 does not need backward computation.
I0816 10:11:04.223742 20528 net.cpp:228] res3_2_res3_2_0_split does not need backward computation.
I0816 10:11:04.223747 20528 net.cpp:228] res3_2 does not need backward computation.
I0816 10:11:04.223754 20528 net.cpp:228] relu3_2 does not need backward computation.
I0816 10:11:04.223760 20528 net.cpp:228] conv3_2 does not need backward computation.
I0816 10:11:04.223767 20528 net.cpp:228] relu3_1 does not need backward computation.
I0816 10:11:04.223772 20528 net.cpp:228] conv3_1 does not need backward computation.
I0816 10:11:04.223778 20528 net.cpp:228] pool2_pool2_0_split does not need backward computation.
I0816 10:11:04.223783 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:04.223788 20528 net.cpp:228] relu2 does not need backward computation.
I0816 10:11:04.223794 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:04.223800 20528 net.cpp:228] res2_2 does not need backward computation.
I0816 10:11:04.223806 20528 net.cpp:228] relu2_2 does not need backward computation.
I0816 10:11:04.223812 20528 net.cpp:228] conv2_2 does not need backward computation.
I0816 10:11:04.223817 20528 net.cpp:228] relu2_1 does not need backward computation.
I0816 10:11:04.223824 20528 net.cpp:228] conv2_1 does not need backward computation.
I0816 10:11:04.223829 20528 net.cpp:228] pool1b_pool1b_0_split does not need backward computation.
I0816 10:11:04.223835 20528 net.cpp:228] pool1b does not need backward computation.
I0816 10:11:04.223842 20528 net.cpp:228] relu1b does not need backward computation.
I0816 10:11:04.223848 20528 net.cpp:228] conv1b does not need backward computation.
I0816 10:11:04.223853 20528 net.cpp:228] relu1a does not need backward computation.
I0816 10:11:04.223860 20528 net.cpp:228] conv1a does not need backward computation.
I0816 10:11:04.223870 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:04.223876 20528 net.cpp:270] This network produces output fc5
I0816 10:11:04.223940 20528 net.cpp:283] Network initialization done.
I0816 10:11:04.617458 20528 net.cpp:761] Ignoring source layer data
I0816 10:11:04.617511 20528 net.cpp:761] Ignoring source layer label_data_1_split
I0816 10:11:04.641793 20528 net.cpp:761] Ignoring source layer fc5_fc5_0_split
I0816 10:11:04.641834 20528 net.cpp:761] Ignoring source layer fc6
I0816 10:11:04.641841 20528 net.cpp:761] Ignoring source layer softmax_loss
I0816 10:11:04.641849 20528 net.cpp:761] Ignoring source layer center_loss
i: 310   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_161
I0816 10:11:04.651121 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det1.prototxt
I0816 10:11:04.651147 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:04.651155 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:04.651392 20528 net.cpp:58] Initializing net from parameters: 
name: "PNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4-1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4-2"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv4-1"
  top: "prob1"
}
I0816 10:11:04.651491 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:04.651510 20528 net.cpp:100] Creating Layer input
I0816 10:11:04.651518 20528 net.cpp:408] input -> data
I0816 10:11:04.651721 20528 net.cpp:150] Setting up input
I0816 10:11:04.651746 20528 net.cpp:157] Top shape: 1 3 12 12 (432)
I0816 10:11:04.651754 20528 net.cpp:165] Memory required for data: 1728
I0816 10:11:04.651774 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:04.651792 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:04.651799 20528 net.cpp:434] conv1 <- data
I0816 10:11:04.651811 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:04.655758 20528 net.cpp:150] Setting up conv1
I0816 10:11:04.655783 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:04.655791 20528 net.cpp:165] Memory required for data: 5728
I0816 10:11:04.655814 20528 layer_factory.hpp:77] Creating layer PReLU1
I0816 10:11:04.655828 20528 net.cpp:100] Creating Layer PReLU1
I0816 10:11:04.655838 20528 net.cpp:434] PReLU1 <- conv1
I0816 10:11:04.655848 20528 net.cpp:395] PReLU1 -> conv1 (in-place)
I0816 10:11:04.656126 20528 net.cpp:150] Setting up PReLU1
I0816 10:11:04.656141 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:04.656147 20528 net.cpp:165] Memory required for data: 9728
I0816 10:11:04.656162 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:04.656174 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:04.656182 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:04.656191 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:04.656297 20528 net.cpp:150] Setting up pool1
I0816 10:11:04.656312 20528 net.cpp:157] Top shape: 1 10 5 5 (250)
I0816 10:11:04.656319 20528 net.cpp:165] Memory required for data: 10728
I0816 10:11:04.656327 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:04.656342 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:04.656350 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:04.656361 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:04.659888 20528 net.cpp:150] Setting up conv2
I0816 10:11:04.659914 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:04.659924 20528 net.cpp:165] Memory required for data: 11304
I0816 10:11:04.659942 20528 layer_factory.hpp:77] Creating layer PReLU2
I0816 10:11:04.659956 20528 net.cpp:100] Creating Layer PReLU2
I0816 10:11:04.659965 20528 net.cpp:434] PReLU2 <- conv2
I0816 10:11:04.659974 20528 net.cpp:395] PReLU2 -> conv2 (in-place)
I0816 10:11:04.660271 20528 net.cpp:150] Setting up PReLU2
I0816 10:11:04.660290 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:04.660297 20528 net.cpp:165] Memory required for data: 11880
I0816 10:11:04.660308 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:04.660323 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:04.660331 20528 net.cpp:434] conv3 <- conv2
I0816 10:11:04.660343 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:04.663990 20528 net.cpp:150] Setting up conv3
I0816 10:11:04.664013 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:04.664021 20528 net.cpp:165] Memory required for data: 12008
I0816 10:11:04.664034 20528 layer_factory.hpp:77] Creating layer PReLU3
I0816 10:11:04.664047 20528 net.cpp:100] Creating Layer PReLU3
I0816 10:11:04.664054 20528 net.cpp:434] PReLU3 <- conv3
I0816 10:11:04.664065 20528 net.cpp:395] PReLU3 -> conv3 (in-place)
I0816 10:11:04.664322 20528 net.cpp:150] Setting up PReLU3
I0816 10:11:04.664338 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:04.664345 20528 net.cpp:165] Memory required for data: 12136
I0816 10:11:04.664361 20528 layer_factory.hpp:77] Creating layer conv3_PReLU3_0_split
I0816 10:11:04.664374 20528 net.cpp:100] Creating Layer conv3_PReLU3_0_split
I0816 10:11:04.664381 20528 net.cpp:434] conv3_PReLU3_0_split <- conv3
I0816 10:11:04.664392 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_0
I0816 10:11:04.664404 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_1
I0816 10:11:04.664502 20528 net.cpp:150] Setting up conv3_PReLU3_0_split
I0816 10:11:04.664516 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:04.664526 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:04.664532 20528 net.cpp:165] Memory required for data: 12392
I0816 10:11:04.664541 20528 layer_factory.hpp:77] Creating layer conv4-1
I0816 10:11:04.664556 20528 net.cpp:100] Creating Layer conv4-1
I0816 10:11:04.664563 20528 net.cpp:434] conv4-1 <- conv3_PReLU3_0_split_0
I0816 10:11:04.664577 20528 net.cpp:408] conv4-1 -> conv4-1
I0816 10:11:04.668422 20528 net.cpp:150] Setting up conv4-1
I0816 10:11:04.668465 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:04.668474 20528 net.cpp:165] Memory required for data: 12400
I0816 10:11:04.668488 20528 layer_factory.hpp:77] Creating layer conv4-2
I0816 10:11:04.668507 20528 net.cpp:100] Creating Layer conv4-2
I0816 10:11:04.668516 20528 net.cpp:434] conv4-2 <- conv3_PReLU3_0_split_1
I0816 10:11:04.668529 20528 net.cpp:408] conv4-2 -> conv4-2
I0816 10:11:04.673313 20528 net.cpp:150] Setting up conv4-2
I0816 10:11:04.673339 20528 net.cpp:157] Top shape: 1 4 1 1 (4)
I0816 10:11:04.673348 20528 net.cpp:165] Memory required for data: 12416
I0816 10:11:04.673362 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:04.673374 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:04.673383 20528 net.cpp:434] prob1 <- conv4-1
I0816 10:11:04.673396 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:04.675007 20528 net.cpp:150] Setting up prob1
I0816 10:11:04.675029 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:04.675036 20528 net.cpp:165] Memory required for data: 12424
I0816 10:11:04.675045 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:04.675052 20528 net.cpp:228] conv4-2 does not need backward computation.
I0816 10:11:04.675060 20528 net.cpp:228] conv4-1 does not need backward computation.
I0816 10:11:04.675068 20528 net.cpp:228] conv3_PReLU3_0_split does not need backward computation.
I0816 10:11:04.675076 20528 net.cpp:228] PReLU3 does not need backward computation.
I0816 10:11:04.675082 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:04.675091 20528 net.cpp:228] PReLU2 does not need backward computation.
I0816 10:11:04.675097 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:04.675104 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:04.675112 20528 net.cpp:228] PReLU1 does not need backward computation.
I0816 10:11:04.675120 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:04.675128 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:04.675134 20528 net.cpp:270] This network produces output conv4-2
I0816 10:11:04.675143 20528 net.cpp:270] This network produces output prob1
I0816 10:11:04.675163 20528 net.cpp:283] Network initialization done.
I0816 10:11:04.675482 20528 net.cpp:761] Ignoring source layer data12
I0816 10:11:04.675496 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:04.675503 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:04.675511 20528 net.cpp:761] Ignoring source layer silence
I0816 10:11:04.675535 20528 net.cpp:761] Ignoring source layer conv4-1_conv4-1_0_split
I0816 10:11:04.675546 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:04.675554 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:04.675562 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:04.676107 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det2.prototxt
I0816 10:11:04.676127 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:04.676134 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:04.676373 20528 net.cpp:58] Initializing net from parameters: 
name: "RNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
  propagate_down: true
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
  propagate_down: true
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
  propagate_down: true
}
layer {
  name: "conv4"
  type: "InnerProduct"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5-1"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5-2"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv5-1"
  top: "prob1"
}
I0816 10:11:04.676484 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:04.676501 20528 net.cpp:100] Creating Layer input
I0816 10:11:04.676509 20528 net.cpp:408] input -> data
I0816 10:11:04.676560 20528 net.cpp:150] Setting up input
I0816 10:11:04.676573 20528 net.cpp:157] Top shape: 1 3 24 24 (1728)
I0816 10:11:04.676580 20528 net.cpp:165] Memory required for data: 6912
I0816 10:11:04.676589 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:04.676604 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:04.676611 20528 net.cpp:434] conv1 <- data
I0816 10:11:04.676622 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:04.680382 20528 net.cpp:150] Setting up conv1
I0816 10:11:04.680405 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:04.680413 20528 net.cpp:165] Memory required for data: 61120
I0816 10:11:04.680431 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:04.680449 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:04.680456 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:04.680466 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:04.681566 20528 net.cpp:150] Setting up prelu1
I0816 10:11:04.681587 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:04.681596 20528 net.cpp:165] Memory required for data: 115328
I0816 10:11:04.681609 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:04.681625 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:04.681633 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:04.681643 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:04.681709 20528 net.cpp:150] Setting up pool1
I0816 10:11:04.681722 20528 net.cpp:157] Top shape: 1 28 11 11 (3388)
I0816 10:11:04.681735 20528 net.cpp:165] Memory required for data: 128880
I0816 10:11:04.681751 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:04.681771 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:04.681778 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:04.681792 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:04.687336 20528 net.cpp:150] Setting up conv2
I0816 10:11:04.687363 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:04.687371 20528 net.cpp:165] Memory required for data: 144432
I0816 10:11:04.687387 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:04.687400 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:04.687408 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:04.687420 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:04.687614 20528 net.cpp:150] Setting up prelu2
I0816 10:11:04.687629 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:04.687636 20528 net.cpp:165] Memory required for data: 159984
I0816 10:11:04.687646 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:04.687657 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:04.687665 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:04.687677 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:04.687746 20528 net.cpp:150] Setting up pool2
I0816 10:11:04.687760 20528 net.cpp:157] Top shape: 1 48 4 4 (768)
I0816 10:11:04.687767 20528 net.cpp:165] Memory required for data: 163056
I0816 10:11:04.687775 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:04.687798 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:04.687806 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:04.687818 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:04.691586 20528 net.cpp:150] Setting up conv3
I0816 10:11:04.691612 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:04.691623 20528 net.cpp:165] Memory required for data: 165360
I0816 10:11:04.691640 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:04.691658 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:04.691668 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:04.691684 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:04.691918 20528 net.cpp:150] Setting up prelu3
I0816 10:11:04.691937 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:04.691947 20528 net.cpp:165] Memory required for data: 167664
I0816 10:11:04.691964 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:04.691985 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:04.691996 20528 net.cpp:434] conv4 <- conv3
I0816 10:11:04.692013 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:04.696167 20528 net.cpp:150] Setting up conv4
I0816 10:11:04.696197 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:04.696208 20528 net.cpp:165] Memory required for data: 168176
I0816 10:11:04.696223 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:04.696246 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:04.696259 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:04.696271 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:04.696418 20528 net.cpp:150] Setting up prelu4
I0816 10:11:04.696434 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:04.696444 20528 net.cpp:165] Memory required for data: 168688
I0816 10:11:04.696455 20528 layer_factory.hpp:77] Creating layer conv4_prelu4_0_split
I0816 10:11:04.696472 20528 net.cpp:100] Creating Layer conv4_prelu4_0_split
I0816 10:11:04.696482 20528 net.cpp:434] conv4_prelu4_0_split <- conv4
I0816 10:11:04.696497 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_0
I0816 10:11:04.696512 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_1
I0816 10:11:04.696578 20528 net.cpp:150] Setting up conv4_prelu4_0_split
I0816 10:11:04.696593 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:04.696609 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:04.696617 20528 net.cpp:165] Memory required for data: 169712
I0816 10:11:04.696627 20528 layer_factory.hpp:77] Creating layer conv5-1
I0816 10:11:04.696643 20528 net.cpp:100] Creating Layer conv5-1
I0816 10:11:04.696653 20528 net.cpp:434] conv5-1 <- conv4_prelu4_0_split_0
I0816 10:11:04.696667 20528 net.cpp:408] conv5-1 -> conv5-1
I0816 10:11:04.696871 20528 net.cpp:150] Setting up conv5-1
I0816 10:11:04.696890 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:04.696899 20528 net.cpp:165] Memory required for data: 169720
I0816 10:11:04.696914 20528 layer_factory.hpp:77] Creating layer conv5-2
I0816 10:11:04.696930 20528 net.cpp:100] Creating Layer conv5-2
I0816 10:11:04.696940 20528 net.cpp:434] conv5-2 <- conv4_prelu4_0_split_1
I0816 10:11:04.696956 20528 net.cpp:408] conv5-2 -> conv5-2
I0816 10:11:04.697302 20528 net.cpp:150] Setting up conv5-2
I0816 10:11:04.697321 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:04.697331 20528 net.cpp:165] Memory required for data: 169736
I0816 10:11:04.697345 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:04.697363 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:04.697374 20528 net.cpp:434] prob1 <- conv5-1
I0816 10:11:04.697386 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:04.698828 20528 net.cpp:150] Setting up prob1
I0816 10:11:04.698854 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:04.698864 20528 net.cpp:165] Memory required for data: 169744
I0816 10:11:04.698874 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:04.698884 20528 net.cpp:228] conv5-2 does not need backward computation.
I0816 10:11:04.698892 20528 net.cpp:228] conv5-1 does not need backward computation.
I0816 10:11:04.698900 20528 net.cpp:228] conv4_prelu4_0_split does not need backward computation.
I0816 10:11:04.698909 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:04.698916 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:04.698925 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:04.698933 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:04.698941 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:04.698949 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:04.698958 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:04.698968 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:04.698977 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:04.698982 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:04.698988 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:04.698993 20528 net.cpp:270] This network produces output conv5-2
I0816 10:11:04.698999 20528 net.cpp:270] This network produces output prob1
I0816 10:11:04.699015 20528 net.cpp:283] Network initialization done.
I0816 10:11:04.701205 20528 net.cpp:761] Ignoring source layer data24
I0816 10:11:04.701225 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:04.701233 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:04.701314 20528 net.cpp:761] Ignoring source layer conv5-1_conv5-1_0_split
I0816 10:11:04.701328 20528 net.cpp:761] Ignoring source layer conv5-3
I0816 10:11:04.701336 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:04.701344 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:04.701351 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:04.701359 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:04.702256 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det3.prototxt
I0816 10:11:04.702281 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:04.702291 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:04.702657 20528 net.cpp:58] Initializing net from parameters: 
name: "ONet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 48
      dim: 48
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6-1"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-2"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-3"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv6-1"
  top: "prob1"
}
I0816 10:11:04.702824 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:04.702847 20528 net.cpp:100] Creating Layer input
I0816 10:11:04.702858 20528 net.cpp:408] input -> data
I0816 10:11:04.702919 20528 net.cpp:150] Setting up input
I0816 10:11:04.702934 20528 net.cpp:157] Top shape: 1 3 48 48 (6912)
I0816 10:11:04.702944 20528 net.cpp:165] Memory required for data: 27648
I0816 10:11:04.702952 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:04.702977 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:04.702987 20528 net.cpp:434] conv1 <- data
I0816 10:11:04.703001 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:04.707382 20528 net.cpp:150] Setting up conv1
I0816 10:11:04.707404 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:04.707411 20528 net.cpp:165] Memory required for data: 298496
I0816 10:11:04.707424 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:04.707434 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:04.707440 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:04.707448 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:04.707650 20528 net.cpp:150] Setting up prelu1
I0816 10:11:04.707662 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:04.707667 20528 net.cpp:165] Memory required for data: 569344
I0816 10:11:04.707680 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:04.707690 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:04.707696 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:04.707703 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:04.707756 20528 net.cpp:150] Setting up pool1
I0816 10:11:04.707767 20528 net.cpp:157] Top shape: 1 32 23 23 (16928)
I0816 10:11:04.707772 20528 net.cpp:165] Memory required for data: 637056
I0816 10:11:04.707777 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:04.707792 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:04.707798 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:04.707806 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:04.711521 20528 net.cpp:150] Setting up conv2
I0816 10:11:04.711542 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:04.711549 20528 net.cpp:165] Memory required for data: 749952
I0816 10:11:04.711561 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:04.711570 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:04.711576 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:04.711585 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:04.711719 20528 net.cpp:150] Setting up prelu2
I0816 10:11:04.711738 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:04.711745 20528 net.cpp:165] Memory required for data: 862848
I0816 10:11:04.711752 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:04.711761 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:04.711766 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:04.711773 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:04.711819 20528 net.cpp:150] Setting up pool2
I0816 10:11:04.711832 20528 net.cpp:157] Top shape: 1 64 10 10 (6400)
I0816 10:11:04.711838 20528 net.cpp:165] Memory required for data: 888448
I0816 10:11:04.711843 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:04.711853 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:04.711859 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:04.711866 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:04.716928 20528 net.cpp:150] Setting up conv3
I0816 10:11:04.716948 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:04.716953 20528 net.cpp:165] Memory required for data: 904832
I0816 10:11:04.716964 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:04.716974 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:04.716979 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:04.716987 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:04.717173 20528 net.cpp:150] Setting up prelu3
I0816 10:11:04.717185 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:04.717190 20528 net.cpp:165] Memory required for data: 921216
I0816 10:11:04.717200 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:04.717209 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:04.717214 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:04.717222 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:04.717265 20528 net.cpp:150] Setting up pool3
I0816 10:11:04.717274 20528 net.cpp:157] Top shape: 1 64 4 4 (1024)
I0816 10:11:04.717279 20528 net.cpp:165] Memory required for data: 925312
I0816 10:11:04.717284 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:04.717303 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:04.717309 20528 net.cpp:434] conv4 <- pool3
I0816 10:11:04.717317 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:04.720434 20528 net.cpp:150] Setting up conv4
I0816 10:11:04.720453 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:04.720458 20528 net.cpp:165] Memory required for data: 929920
I0816 10:11:04.720468 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:04.720477 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:04.720484 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:04.720491 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:04.720613 20528 net.cpp:150] Setting up prelu4
I0816 10:11:04.720623 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:04.720628 20528 net.cpp:165] Memory required for data: 934528
I0816 10:11:04.720634 20528 layer_factory.hpp:77] Creating layer conv5
I0816 10:11:04.720646 20528 net.cpp:100] Creating Layer conv5
I0816 10:11:04.720651 20528 net.cpp:434] conv5 <- conv4
I0816 10:11:04.720659 20528 net.cpp:408] conv5 -> conv5
I0816 10:11:04.723273 20528 net.cpp:150] Setting up conv5
I0816 10:11:04.723292 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:04.723297 20528 net.cpp:165] Memory required for data: 935552
I0816 10:11:04.723307 20528 layer_factory.hpp:77] Creating layer drop5
I0816 10:11:04.723317 20528 net.cpp:100] Creating Layer drop5
I0816 10:11:04.723323 20528 net.cpp:434] drop5 <- conv5
I0816 10:11:04.723331 20528 net.cpp:395] drop5 -> conv5 (in-place)
I0816 10:11:04.723361 20528 net.cpp:150] Setting up drop5
I0816 10:11:04.723369 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:04.723374 20528 net.cpp:165] Memory required for data: 936576
I0816 10:11:04.723379 20528 layer_factory.hpp:77] Creating layer prelu5
I0816 10:11:04.723387 20528 net.cpp:100] Creating Layer prelu5
I0816 10:11:04.723392 20528 net.cpp:434] prelu5 <- conv5
I0816 10:11:04.723398 20528 net.cpp:395] prelu5 -> conv5 (in-place)
I0816 10:11:04.723486 20528 net.cpp:150] Setting up prelu5
I0816 10:11:04.723495 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:04.723500 20528 net.cpp:165] Memory required for data: 937600
I0816 10:11:04.723506 20528 layer_factory.hpp:77] Creating layer conv5_prelu5_0_split
I0816 10:11:04.723515 20528 net.cpp:100] Creating Layer conv5_prelu5_0_split
I0816 10:11:04.723520 20528 net.cpp:434] conv5_prelu5_0_split <- conv5
I0816 10:11:04.723526 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_0
I0816 10:11:04.723534 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_1
I0816 10:11:04.723543 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_2
I0816 10:11:04.723597 20528 net.cpp:150] Setting up conv5_prelu5_0_split
I0816 10:11:04.723604 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:04.723610 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:04.723616 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:04.723621 20528 net.cpp:165] Memory required for data: 940672
I0816 10:11:04.723626 20528 layer_factory.hpp:77] Creating layer conv6-1
I0816 10:11:04.723637 20528 net.cpp:100] Creating Layer conv6-1
I0816 10:11:04.723642 20528 net.cpp:434] conv6-1 <- conv5_prelu5_0_split_0
I0816 10:11:04.723651 20528 net.cpp:408] conv6-1 -> conv6-1
I0816 10:11:04.723810 20528 net.cpp:150] Setting up conv6-1
I0816 10:11:04.723821 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:04.723826 20528 net.cpp:165] Memory required for data: 940680
I0816 10:11:04.723839 20528 layer_factory.hpp:77] Creating layer conv6-2
I0816 10:11:04.723847 20528 net.cpp:100] Creating Layer conv6-2
I0816 10:11:04.723853 20528 net.cpp:434] conv6-2 <- conv5_prelu5_0_split_1
I0816 10:11:04.723860 20528 net.cpp:408] conv6-2 -> conv6-2
I0816 10:11:04.724002 20528 net.cpp:150] Setting up conv6-2
I0816 10:11:04.724011 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:04.724016 20528 net.cpp:165] Memory required for data: 940696
I0816 10:11:04.724025 20528 layer_factory.hpp:77] Creating layer conv6-3
I0816 10:11:04.724035 20528 net.cpp:100] Creating Layer conv6-3
I0816 10:11:04.724040 20528 net.cpp:434] conv6-3 <- conv5_prelu5_0_split_2
I0816 10:11:04.724053 20528 net.cpp:408] conv6-3 -> conv6-3
I0816 10:11:04.724208 20528 net.cpp:150] Setting up conv6-3
I0816 10:11:04.724218 20528 net.cpp:157] Top shape: 1 10 (10)
I0816 10:11:04.724223 20528 net.cpp:165] Memory required for data: 940736
I0816 10:11:04.724232 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:04.724241 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:04.724247 20528 net.cpp:434] prob1 <- conv6-1
I0816 10:11:04.724254 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:04.724580 20528 net.cpp:150] Setting up prob1
I0816 10:11:04.724591 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:04.724596 20528 net.cpp:165] Memory required for data: 940744
I0816 10:11:04.724602 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:04.724607 20528 net.cpp:228] conv6-3 does not need backward computation.
I0816 10:11:04.724612 20528 net.cpp:228] conv6-2 does not need backward computation.
I0816 10:11:04.724618 20528 net.cpp:228] conv6-1 does not need backward computation.
I0816 10:11:04.724623 20528 net.cpp:228] conv5_prelu5_0_split does not need backward computation.
I0816 10:11:04.724628 20528 net.cpp:228] prelu5 does not need backward computation.
I0816 10:11:04.724633 20528 net.cpp:228] drop5 does not need backward computation.
I0816 10:11:04.724638 20528 net.cpp:228] conv5 does not need backward computation.
I0816 10:11:04.724643 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:04.724648 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:04.724653 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:04.724658 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:04.724663 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:04.724669 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:04.724674 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:04.724678 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:04.724684 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:04.724689 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:04.724694 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:04.724699 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:04.724704 20528 net.cpp:270] This network produces output conv6-2
I0816 10:11:04.724710 20528 net.cpp:270] This network produces output conv6-3
I0816 10:11:04.724715 20528 net.cpp:270] This network produces output prob1
I0816 10:11:04.724740 20528 net.cpp:283] Network initialization done.
I0816 10:11:04.729398 20528 net.cpp:761] Ignoring source layer data48
I0816 10:11:04.729411 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:04.729416 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:04.729652 20528 net.cpp:761] Ignoring source layer conv6-1_conv6-1_0_split
I0816 10:11:04.729663 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:04.729668 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:04.729673 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:04.729678 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:04.731680 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/face_deploy.prototxt
I0816 10:11:04.731719 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:04.731737 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:04.732868 20528 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 96
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "PReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1b"
  type: "PReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1b"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1b"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1b"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "res2_2"
  type: "Eltwise"
  bottom: "pool1b"
  bottom: "conv2_2"
  top: "res2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "res2_2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "res3_2"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "conv3_2"
  top: "res3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "res3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "res3_4"
  type: "Eltwise"
  bottom: "res3_2"
  bottom: "conv3_4"
  top: "res3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "res3_4"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "res4_2"
  type: "Eltwise"
  bottom: "pool3"
  bottom: "conv4_2"
  top: "res4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "res4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_4"
  type: "PReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "res4_4"
  type: "Eltwise"
  bottom: "res4_2"
  bottom: "conv4_4"
  top: "res4_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_5"
  type: "Convolution"
  bottom: "res4_4"
  top: "conv4_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_5"
  type: "PReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_6"
  type: "PReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
layer {
  name: "res4_6"
  type: "Eltwise"
  bottom: "res4_4"
  bottom: "conv4_6"
  top: "res4_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_7"
  type: "Convolution"
  bottom: "res4_6"
  top: "conv4_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_7"
  type: "PReLU"
  bottom: "conv4_7"
  top: "conv4_7"
}
layer {
  name: "conv4_8"
  type: "Convolution"
  bottom: "conv4_7"
  top: "conv4_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_8"
  type: "PReLU"
  bottom: "conv4_8"
  top: "conv4_8"
}
layer {
  name: "res4_8"
  type: "Eltwise"
  bottom: "res4_6"
  bottom: "conv4_8"
  top: "res4_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_9"
  type: "Convolution"
  bottom: "res4_8"
  top: "conv4_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_9"
  type: "PReLU"
  bottom: "conv4_9"
  top: "conv4_9"
}
layer {
  name: "conv4_10"
  type: "Convolution"
  bottom: "conv4_9"
  top: "conv4_10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_10"
  type: "PReLU"
  bottom: "conv4_10"
  top: "conv4_10"
}
layer {
  name: "res4_10"
  type: "Eltwise"
  bottom: "res4_8"
  bottom: "conv4_10"
  top: "res4_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "res4_10"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "PReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "PReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "res5_2"
  type: "Eltwise"
  bottom: "pool4"
  bottom: "conv5_2"
  top: "res5_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "res5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "PReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_4"
  type: "PReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "res5_4"
  type: "Eltwise"
  bottom: "res5_2"
  bottom: "conv5_4"
  top: "res5_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_5"
  type: "Convolution"
  bottom: "res5_4"
  top: "conv5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_5"
  type: "PReLU"
  bottom: "conv5_5"
  top: "conv5_5"
}
layer {
  name: "conv5_6"
  type: "Convolution"
  bottom: "conv5_5"
  top: "conv5_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_6"
  type: "PReLU"
  bottom: "conv5_6"
  top: "conv5_6"
}
layer {
  name: "res5_6"
  type: "Eltwise"
  bottom: "res5_4"
  bottom: "conv5_6"
  top: "res5_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res5_6"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
I0816 10:11:04.733499 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:04.733521 20528 net.cpp:100] Creating Layer input
I0816 10:11:04.733534 20528 net.cpp:408] input -> data
I0816 10:11:04.733613 20528 net.cpp:150] Setting up input
I0816 10:11:04.733629 20528 net.cpp:157] Top shape: 1 3 112 96 (32256)
I0816 10:11:04.733639 20528 net.cpp:165] Memory required for data: 129024
I0816 10:11:04.733649 20528 layer_factory.hpp:77] Creating layer conv1a
I0816 10:11:04.733674 20528 net.cpp:100] Creating Layer conv1a
I0816 10:11:04.733685 20528 net.cpp:434] conv1a <- data
I0816 10:11:04.733700 20528 net.cpp:408] conv1a -> conv1a
I0816 10:11:04.738775 20528 net.cpp:150] Setting up conv1a
I0816 10:11:04.738796 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:04.738803 20528 net.cpp:165] Memory required for data: 1452544
I0816 10:11:04.738818 20528 layer_factory.hpp:77] Creating layer relu1a
I0816 10:11:04.738828 20528 net.cpp:100] Creating Layer relu1a
I0816 10:11:04.738834 20528 net.cpp:434] relu1a <- conv1a
I0816 10:11:04.738842 20528 net.cpp:395] relu1a -> conv1a (in-place)
I0816 10:11:04.740408 20528 net.cpp:150] Setting up relu1a
I0816 10:11:04.740434 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:04.740445 20528 net.cpp:165] Memory required for data: 2776064
I0816 10:11:04.740471 20528 layer_factory.hpp:77] Creating layer conv1b
I0816 10:11:04.740492 20528 net.cpp:100] Creating Layer conv1b
I0816 10:11:04.740504 20528 net.cpp:434] conv1b <- conv1a
I0816 10:11:04.740517 20528 net.cpp:408] conv1b -> conv1b
I0816 10:11:04.743628 20528 net.cpp:150] Setting up conv1b
I0816 10:11:04.743651 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:04.743659 20528 net.cpp:165] Memory required for data: 5319680
I0816 10:11:04.743675 20528 layer_factory.hpp:77] Creating layer relu1b
I0816 10:11:04.743688 20528 net.cpp:100] Creating Layer relu1b
I0816 10:11:04.743695 20528 net.cpp:434] relu1b <- conv1b
I0816 10:11:04.743702 20528 net.cpp:395] relu1b -> conv1b (in-place)
I0816 10:11:04.745784 20528 net.cpp:150] Setting up relu1b
I0816 10:11:04.745803 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:04.745810 20528 net.cpp:165] Memory required for data: 7863296
I0816 10:11:04.745817 20528 layer_factory.hpp:77] Creating layer pool1b
I0816 10:11:04.745827 20528 net.cpp:100] Creating Layer pool1b
I0816 10:11:04.745833 20528 net.cpp:434] pool1b <- conv1b
I0816 10:11:04.745843 20528 net.cpp:408] pool1b -> pool1b
I0816 10:11:04.745908 20528 net.cpp:150] Setting up pool1b
I0816 10:11:04.745920 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.745926 20528 net.cpp:165] Memory required for data: 8499200
I0816 10:11:04.745931 20528 layer_factory.hpp:77] Creating layer pool1b_pool1b_0_split
I0816 10:11:04.745939 20528 net.cpp:100] Creating Layer pool1b_pool1b_0_split
I0816 10:11:04.745945 20528 net.cpp:434] pool1b_pool1b_0_split <- pool1b
I0816 10:11:04.745952 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_0
I0816 10:11:04.745961 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_1
I0816 10:11:04.746012 20528 net.cpp:150] Setting up pool1b_pool1b_0_split
I0816 10:11:04.746024 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.746031 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.746037 20528 net.cpp:165] Memory required for data: 9771008
I0816 10:11:04.746042 20528 layer_factory.hpp:77] Creating layer conv2_1
I0816 10:11:04.746058 20528 net.cpp:100] Creating Layer conv2_1
I0816 10:11:04.746065 20528 net.cpp:434] conv2_1 <- pool1b_pool1b_0_split_0
I0816 10:11:04.746073 20528 net.cpp:408] conv2_1 -> conv2_1
I0816 10:11:04.751386 20528 net.cpp:150] Setting up conv2_1
I0816 10:11:04.751408 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.751417 20528 net.cpp:165] Memory required for data: 10406912
I0816 10:11:04.751430 20528 layer_factory.hpp:77] Creating layer relu2_1
I0816 10:11:04.751441 20528 net.cpp:100] Creating Layer relu2_1
I0816 10:11:04.751447 20528 net.cpp:434] relu2_1 <- conv2_1
I0816 10:11:04.751456 20528 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0816 10:11:04.752526 20528 net.cpp:150] Setting up relu2_1
I0816 10:11:04.752553 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.752564 20528 net.cpp:165] Memory required for data: 11042816
I0816 10:11:04.752584 20528 layer_factory.hpp:77] Creating layer conv2_2
I0816 10:11:04.752607 20528 net.cpp:100] Creating Layer conv2_2
I0816 10:11:04.752619 20528 net.cpp:434] conv2_2 <- conv2_1
I0816 10:11:04.752635 20528 net.cpp:408] conv2_2 -> conv2_2
I0816 10:11:04.758445 20528 net.cpp:150] Setting up conv2_2
I0816 10:11:04.758472 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.758482 20528 net.cpp:165] Memory required for data: 11678720
I0816 10:11:04.758500 20528 layer_factory.hpp:77] Creating layer relu2_2
I0816 10:11:04.758515 20528 net.cpp:100] Creating Layer relu2_2
I0816 10:11:04.758527 20528 net.cpp:434] relu2_2 <- conv2_2
I0816 10:11:04.758540 20528 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0816 10:11:04.759799 20528 net.cpp:150] Setting up relu2_2
I0816 10:11:04.759824 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.759834 20528 net.cpp:165] Memory required for data: 12314624
I0816 10:11:04.759848 20528 layer_factory.hpp:77] Creating layer res2_2
I0816 10:11:04.759873 20528 net.cpp:100] Creating Layer res2_2
I0816 10:11:04.759884 20528 net.cpp:434] res2_2 <- pool1b_pool1b_0_split_1
I0816 10:11:04.759896 20528 net.cpp:434] res2_2 <- conv2_2
I0816 10:11:04.759909 20528 net.cpp:408] res2_2 -> res2_2
I0816 10:11:04.759966 20528 net.cpp:150] Setting up res2_2
I0816 10:11:04.759982 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:04.759991 20528 net.cpp:165] Memory required for data: 12950528
I0816 10:11:04.760001 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:04.760020 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:04.760030 20528 net.cpp:434] conv2 <- res2_2
I0816 10:11:04.760044 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:04.763839 20528 net.cpp:150] Setting up conv2
I0816 10:11:04.763869 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:04.763878 20528 net.cpp:165] Memory required for data: 14121984
I0816 10:11:04.763895 20528 layer_factory.hpp:77] Creating layer relu2
I0816 10:11:04.763911 20528 net.cpp:100] Creating Layer relu2
I0816 10:11:04.763921 20528 net.cpp:434] relu2 <- conv2
I0816 10:11:04.763933 20528 net.cpp:395] relu2 -> conv2 (in-place)
I0816 10:11:04.765367 20528 net.cpp:150] Setting up relu2
I0816 10:11:04.765394 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:04.765404 20528 net.cpp:165] Memory required for data: 15293440
I0816 10:11:04.765417 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:04.765434 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:04.765444 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:04.765457 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:04.765537 20528 net.cpp:150] Setting up pool2
I0816 10:11:04.765553 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.765563 20528 net.cpp:165] Memory required for data: 15586304
I0816 10:11:04.765571 20528 layer_factory.hpp:77] Creating layer pool2_pool2_0_split
I0816 10:11:04.765585 20528 net.cpp:100] Creating Layer pool2_pool2_0_split
I0816 10:11:04.765594 20528 net.cpp:434] pool2_pool2_0_split <- pool2
I0816 10:11:04.765607 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_0
I0816 10:11:04.765622 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_1
I0816 10:11:04.765691 20528 net.cpp:150] Setting up pool2_pool2_0_split
I0816 10:11:04.765707 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.765719 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.765727 20528 net.cpp:165] Memory required for data: 16172032
I0816 10:11:04.765745 20528 layer_factory.hpp:77] Creating layer conv3_1
I0816 10:11:04.765769 20528 net.cpp:100] Creating Layer conv3_1
I0816 10:11:04.765779 20528 net.cpp:434] conv3_1 <- pool2_pool2_0_split_0
I0816 10:11:04.765795 20528 net.cpp:408] conv3_1 -> conv3_1
I0816 10:11:04.776801 20528 net.cpp:150] Setting up conv3_1
I0816 10:11:04.776823 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.776829 20528 net.cpp:165] Memory required for data: 16464896
I0816 10:11:04.776849 20528 layer_factory.hpp:77] Creating layer relu3_1
I0816 10:11:04.776861 20528 net.cpp:100] Creating Layer relu3_1
I0816 10:11:04.776868 20528 net.cpp:434] relu3_1 <- conv3_1
I0816 10:11:04.776876 20528 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0816 10:11:04.777036 20528 net.cpp:150] Setting up relu3_1
I0816 10:11:04.777051 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.777058 20528 net.cpp:165] Memory required for data: 16757760
I0816 10:11:04.777068 20528 layer_factory.hpp:77] Creating layer conv3_2
I0816 10:11:04.777081 20528 net.cpp:100] Creating Layer conv3_2
I0816 10:11:04.777086 20528 net.cpp:434] conv3_2 <- conv3_1
I0816 10:11:04.777096 20528 net.cpp:408] conv3_2 -> conv3_2
I0816 10:11:04.787583 20528 net.cpp:150] Setting up conv3_2
I0816 10:11:04.787606 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.787616 20528 net.cpp:165] Memory required for data: 17050624
I0816 10:11:04.787628 20528 layer_factory.hpp:77] Creating layer relu3_2
I0816 10:11:04.787639 20528 net.cpp:100] Creating Layer relu3_2
I0816 10:11:04.787652 20528 net.cpp:434] relu3_2 <- conv3_2
I0816 10:11:04.787662 20528 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0816 10:11:04.787832 20528 net.cpp:150] Setting up relu3_2
I0816 10:11:04.787844 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.787849 20528 net.cpp:165] Memory required for data: 17343488
I0816 10:11:04.787856 20528 layer_factory.hpp:77] Creating layer res3_2
I0816 10:11:04.787868 20528 net.cpp:100] Creating Layer res3_2
I0816 10:11:04.787874 20528 net.cpp:434] res3_2 <- pool2_pool2_0_split_1
I0816 10:11:04.787881 20528 net.cpp:434] res3_2 <- conv3_2
I0816 10:11:04.787889 20528 net.cpp:408] res3_2 -> res3_2
I0816 10:11:04.787930 20528 net.cpp:150] Setting up res3_2
I0816 10:11:04.787940 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.787945 20528 net.cpp:165] Memory required for data: 17636352
I0816 10:11:04.787950 20528 layer_factory.hpp:77] Creating layer res3_2_res3_2_0_split
I0816 10:11:04.787959 20528 net.cpp:100] Creating Layer res3_2_res3_2_0_split
I0816 10:11:04.787966 20528 net.cpp:434] res3_2_res3_2_0_split <- res3_2
I0816 10:11:04.787973 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_0
I0816 10:11:04.787986 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_1
I0816 10:11:04.788033 20528 net.cpp:150] Setting up res3_2_res3_2_0_split
I0816 10:11:04.788043 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.788049 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.788055 20528 net.cpp:165] Memory required for data: 18222080
I0816 10:11:04.788061 20528 layer_factory.hpp:77] Creating layer conv3_3
I0816 10:11:04.788075 20528 net.cpp:100] Creating Layer conv3_3
I0816 10:11:04.788081 20528 net.cpp:434] conv3_3 <- res3_2_res3_2_0_split_0
I0816 10:11:04.788089 20528 net.cpp:408] conv3_3 -> conv3_3
I0816 10:11:04.797420 20528 net.cpp:150] Setting up conv3_3
I0816 10:11:04.797441 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.797446 20528 net.cpp:165] Memory required for data: 18514944
I0816 10:11:04.797456 20528 layer_factory.hpp:77] Creating layer relu3_3
I0816 10:11:04.797466 20528 net.cpp:100] Creating Layer relu3_3
I0816 10:11:04.797472 20528 net.cpp:434] relu3_3 <- conv3_3
I0816 10:11:04.797482 20528 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0816 10:11:04.797631 20528 net.cpp:150] Setting up relu3_3
I0816 10:11:04.797641 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.797647 20528 net.cpp:165] Memory required for data: 18807808
I0816 10:11:04.797654 20528 layer_factory.hpp:77] Creating layer conv3_4
I0816 10:11:04.797667 20528 net.cpp:100] Creating Layer conv3_4
I0816 10:11:04.797673 20528 net.cpp:434] conv3_4 <- conv3_3
I0816 10:11:04.797683 20528 net.cpp:408] conv3_4 -> conv3_4
I0816 10:11:04.807335 20528 net.cpp:150] Setting up conv3_4
I0816 10:11:04.807356 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.807363 20528 net.cpp:165] Memory required for data: 19100672
I0816 10:11:04.807374 20528 layer_factory.hpp:77] Creating layer relu3_4
I0816 10:11:04.807384 20528 net.cpp:100] Creating Layer relu3_4
I0816 10:11:04.807390 20528 net.cpp:434] relu3_4 <- conv3_4
I0816 10:11:04.807399 20528 net.cpp:395] relu3_4 -> conv3_4 (in-place)
I0816 10:11:04.807550 20528 net.cpp:150] Setting up relu3_4
I0816 10:11:04.807560 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.807565 20528 net.cpp:165] Memory required for data: 19393536
I0816 10:11:04.807574 20528 layer_factory.hpp:77] Creating layer res3_4
I0816 10:11:04.807582 20528 net.cpp:100] Creating Layer res3_4
I0816 10:11:04.807588 20528 net.cpp:434] res3_4 <- res3_2_res3_2_0_split_1
I0816 10:11:04.807595 20528 net.cpp:434] res3_4 <- conv3_4
I0816 10:11:04.807603 20528 net.cpp:408] res3_4 -> res3_4
I0816 10:11:04.807636 20528 net.cpp:150] Setting up res3_4
I0816 10:11:04.807644 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:04.807649 20528 net.cpp:165] Memory required for data: 19686400
I0816 10:11:04.807656 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:04.807673 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:04.807680 20528 net.cpp:434] conv3 <- res3_4
I0816 10:11:04.807688 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:04.812755 20528 net.cpp:150] Setting up conv3
I0816 10:11:04.812777 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:04.812783 20528 net.cpp:165] Memory required for data: 20177920
I0816 10:11:04.812793 20528 layer_factory.hpp:77] Creating layer relu3
I0816 10:11:04.812803 20528 net.cpp:100] Creating Layer relu3
I0816 10:11:04.812808 20528 net.cpp:434] relu3 <- conv3
I0816 10:11:04.812818 20528 net.cpp:395] relu3 -> conv3 (in-place)
I0816 10:11:04.813725 20528 net.cpp:150] Setting up relu3
I0816 10:11:04.813750 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:04.813755 20528 net.cpp:165] Memory required for data: 20669440
I0816 10:11:04.813763 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:04.813773 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:04.813779 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:04.813787 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:04.813840 20528 net.cpp:150] Setting up pool3
I0816 10:11:04.813849 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:04.813854 20528 net.cpp:165] Memory required for data: 20792320
I0816 10:11:04.813860 20528 layer_factory.hpp:77] Creating layer pool3_pool3_0_split
I0816 10:11:04.813868 20528 net.cpp:100] Creating Layer pool3_pool3_0_split
I0816 10:11:04.813874 20528 net.cpp:434] pool3_pool3_0_split <- pool3
I0816 10:11:04.813881 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_0
I0816 10:11:04.813889 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_1
I0816 10:11:04.813932 20528 net.cpp:150] Setting up pool3_pool3_0_split
I0816 10:11:04.813941 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:04.813947 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:04.813952 20528 net.cpp:165] Memory required for data: 21038080
I0816 10:11:04.813957 20528 layer_factory.hpp:77] Creating layer conv4_1
I0816 10:11:04.813969 20528 net.cpp:100] Creating Layer conv4_1
I0816 10:11:04.813976 20528 net.cpp:434] conv4_1 <- pool3_pool3_0_split_0
I0816 10:11:04.813984 20528 net.cpp:408] conv4_1 -> conv4_1
I0816 10:11:04.840016 20528 net.cpp:150] Setting up conv4_1
I0816 10:11:04.840035 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:04.840041 20528 net.cpp:165] Memory required for data: 21160960
I0816 10:11:04.840051 20528 layer_factory.hpp:77] Creating layer relu4_1
I0816 10:11:04.840065 20528 net.cpp:100] Creating Layer relu4_1
I0816 10:11:04.840071 20528 net.cpp:434] relu4_1 <- conv4_1
I0816 10:11:04.840080 20528 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0816 10:11:04.840230 20528 net.cpp:150] Setting up relu4_1
I0816 10:11:04.840241 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:04.840246 20528 net.cpp:165] Memory required for data: 21283840
I0816 10:11:04.840261 20528 layer_factory.hpp:77] Creating layer conv4_2
I0816 10:11:04.840276 20528 net.cpp:100] Creating Layer conv4_2
I0816 10:11:04.840281 20528 net.cpp:434] conv4_2 <- conv4_1
I0816 10:11:04.840291 20528 net.cpp:408] conv4_2 -> conv4_2
I0816 10:11:05.137838 20528 net.cpp:150] Setting up conv4_2
I0816 10:11:05.137892 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.137899 20528 net.cpp:165] Memory required for data: 21406720
I0816 10:11:05.137915 20528 layer_factory.hpp:77] Creating layer relu4_2
I0816 10:11:05.137930 20528 net.cpp:100] Creating Layer relu4_2
I0816 10:11:05.137939 20528 net.cpp:434] relu4_2 <- conv4_2
I0816 10:11:05.137950 20528 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0816 10:11:05.138114 20528 net.cpp:150] Setting up relu4_2
I0816 10:11:05.138125 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.138130 20528 net.cpp:165] Memory required for data: 21529600
I0816 10:11:05.138139 20528 layer_factory.hpp:77] Creating layer res4_2
I0816 10:11:05.138149 20528 net.cpp:100] Creating Layer res4_2
I0816 10:11:05.138157 20528 net.cpp:434] res4_2 <- pool3_pool3_0_split_1
I0816 10:11:05.138177 20528 net.cpp:434] res4_2 <- conv4_2
I0816 10:11:05.138187 20528 net.cpp:408] res4_2 -> res4_2
I0816 10:11:05.138224 20528 net.cpp:150] Setting up res4_2
I0816 10:11:05.138233 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.138238 20528 net.cpp:165] Memory required for data: 21652480
I0816 10:11:05.138243 20528 layer_factory.hpp:77] Creating layer res4_2_res4_2_0_split
I0816 10:11:05.138253 20528 net.cpp:100] Creating Layer res4_2_res4_2_0_split
I0816 10:11:05.138258 20528 net.cpp:434] res4_2_res4_2_0_split <- res4_2
I0816 10:11:05.138267 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_0
I0816 10:11:05.138275 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_1
I0816 10:11:05.138320 20528 net.cpp:150] Setting up res4_2_res4_2_0_split
I0816 10:11:05.138329 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.138335 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.138340 20528 net.cpp:165] Memory required for data: 21898240
I0816 10:11:05.138345 20528 layer_factory.hpp:77] Creating layer conv4_3
I0816 10:11:05.138360 20528 net.cpp:100] Creating Layer conv4_3
I0816 10:11:05.138365 20528 net.cpp:434] conv4_3 <- res4_2_res4_2_0_split_0
I0816 10:11:05.138375 20528 net.cpp:408] conv4_3 -> conv4_3
I0816 10:11:05.163401 20528 net.cpp:150] Setting up conv4_3
I0816 10:11:05.163424 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.163429 20528 net.cpp:165] Memory required for data: 22021120
I0816 10:11:05.163441 20528 layer_factory.hpp:77] Creating layer relu4_3
I0816 10:11:05.163451 20528 net.cpp:100] Creating Layer relu4_3
I0816 10:11:05.163458 20528 net.cpp:434] relu4_3 <- conv4_3
I0816 10:11:05.163466 20528 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0816 10:11:05.163615 20528 net.cpp:150] Setting up relu4_3
I0816 10:11:05.163626 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.163631 20528 net.cpp:165] Memory required for data: 22144000
I0816 10:11:05.163638 20528 layer_factory.hpp:77] Creating layer conv4_4
I0816 10:11:05.163652 20528 net.cpp:100] Creating Layer conv4_4
I0816 10:11:05.163657 20528 net.cpp:434] conv4_4 <- conv4_3
I0816 10:11:05.163668 20528 net.cpp:408] conv4_4 -> conv4_4
I0816 10:11:05.188323 20528 net.cpp:150] Setting up conv4_4
I0816 10:11:05.188345 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.188351 20528 net.cpp:165] Memory required for data: 22266880
I0816 10:11:05.188361 20528 layer_factory.hpp:77] Creating layer relu4_4
I0816 10:11:05.188372 20528 net.cpp:100] Creating Layer relu4_4
I0816 10:11:05.188379 20528 net.cpp:434] relu4_4 <- conv4_4
I0816 10:11:05.188387 20528 net.cpp:395] relu4_4 -> conv4_4 (in-place)
I0816 10:11:05.188531 20528 net.cpp:150] Setting up relu4_4
I0816 10:11:05.188542 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.188547 20528 net.cpp:165] Memory required for data: 22389760
I0816 10:11:05.188555 20528 layer_factory.hpp:77] Creating layer res4_4
I0816 10:11:05.188563 20528 net.cpp:100] Creating Layer res4_4
I0816 10:11:05.188570 20528 net.cpp:434] res4_4 <- res4_2_res4_2_0_split_1
I0816 10:11:05.188577 20528 net.cpp:434] res4_4 <- conv4_4
I0816 10:11:05.188585 20528 net.cpp:408] res4_4 -> res4_4
I0816 10:11:05.188624 20528 net.cpp:150] Setting up res4_4
I0816 10:11:05.188635 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.188640 20528 net.cpp:165] Memory required for data: 22512640
I0816 10:11:05.188645 20528 layer_factory.hpp:77] Creating layer res4_4_res4_4_0_split
I0816 10:11:05.188654 20528 net.cpp:100] Creating Layer res4_4_res4_4_0_split
I0816 10:11:05.188659 20528 net.cpp:434] res4_4_res4_4_0_split <- res4_4
I0816 10:11:05.188668 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_0
I0816 10:11:05.188676 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_1
I0816 10:11:05.188719 20528 net.cpp:150] Setting up res4_4_res4_4_0_split
I0816 10:11:05.188727 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.188742 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.188753 20528 net.cpp:165] Memory required for data: 22758400
I0816 10:11:05.188760 20528 layer_factory.hpp:77] Creating layer conv4_5
I0816 10:11:05.188771 20528 net.cpp:100] Creating Layer conv4_5
I0816 10:11:05.188777 20528 net.cpp:434] conv4_5 <- res4_4_res4_4_0_split_0
I0816 10:11:05.188787 20528 net.cpp:408] conv4_5 -> conv4_5
I0816 10:11:05.219115 20528 net.cpp:150] Setting up conv4_5
I0816 10:11:05.219141 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.219146 20528 net.cpp:165] Memory required for data: 22881280
I0816 10:11:05.219159 20528 layer_factory.hpp:77] Creating layer relu4_5
I0816 10:11:05.219172 20528 net.cpp:100] Creating Layer relu4_5
I0816 10:11:05.219178 20528 net.cpp:434] relu4_5 <- conv4_5
I0816 10:11:05.219187 20528 net.cpp:395] relu4_5 -> conv4_5 (in-place)
I0816 10:11:05.219346 20528 net.cpp:150] Setting up relu4_5
I0816 10:11:05.219359 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.219365 20528 net.cpp:165] Memory required for data: 23004160
I0816 10:11:05.219372 20528 layer_factory.hpp:77] Creating layer conv4_6
I0816 10:11:05.219385 20528 net.cpp:100] Creating Layer conv4_6
I0816 10:11:05.219391 20528 net.cpp:434] conv4_6 <- conv4_5
I0816 10:11:05.219400 20528 net.cpp:408] conv4_6 -> conv4_6
I0816 10:11:05.246598 20528 net.cpp:150] Setting up conv4_6
I0816 10:11:05.246626 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.246634 20528 net.cpp:165] Memory required for data: 23127040
I0816 10:11:05.246649 20528 layer_factory.hpp:77] Creating layer relu4_6
I0816 10:11:05.246662 20528 net.cpp:100] Creating Layer relu4_6
I0816 10:11:05.246671 20528 net.cpp:434] relu4_6 <- conv4_6
I0816 10:11:05.246683 20528 net.cpp:395] relu4_6 -> conv4_6 (in-place)
I0816 10:11:05.246913 20528 net.cpp:150] Setting up relu4_6
I0816 10:11:05.246935 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.246944 20528 net.cpp:165] Memory required for data: 23249920
I0816 10:11:05.246958 20528 layer_factory.hpp:77] Creating layer res4_6
I0816 10:11:05.246971 20528 net.cpp:100] Creating Layer res4_6
I0816 10:11:05.246982 20528 net.cpp:434] res4_6 <- res4_4_res4_4_0_split_1
I0816 10:11:05.246994 20528 net.cpp:434] res4_6 <- conv4_6
I0816 10:11:05.247007 20528 net.cpp:408] res4_6 -> res4_6
I0816 10:11:05.247062 20528 net.cpp:150] Setting up res4_6
I0816 10:11:05.247078 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.247087 20528 net.cpp:165] Memory required for data: 23372800
I0816 10:11:05.247097 20528 layer_factory.hpp:77] Creating layer res4_6_res4_6_0_split
I0816 10:11:05.247109 20528 net.cpp:100] Creating Layer res4_6_res4_6_0_split
I0816 10:11:05.247119 20528 net.cpp:434] res4_6_res4_6_0_split <- res4_6
I0816 10:11:05.247131 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_0
I0816 10:11:05.247146 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_1
I0816 10:11:05.247222 20528 net.cpp:150] Setting up res4_6_res4_6_0_split
I0816 10:11:05.247238 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.247251 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.247259 20528 net.cpp:165] Memory required for data: 23618560
I0816 10:11:05.247267 20528 layer_factory.hpp:77] Creating layer conv4_7
I0816 10:11:05.247287 20528 net.cpp:100] Creating Layer conv4_7
I0816 10:11:05.247298 20528 net.cpp:434] conv4_7 <- res4_6_res4_6_0_split_0
I0816 10:11:05.247313 20528 net.cpp:408] conv4_7 -> conv4_7
I0816 10:11:05.280653 20528 net.cpp:150] Setting up conv4_7
I0816 10:11:05.280689 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.280699 20528 net.cpp:165] Memory required for data: 23741440
I0816 10:11:05.280710 20528 layer_factory.hpp:77] Creating layer relu4_7
I0816 10:11:05.280721 20528 net.cpp:100] Creating Layer relu4_7
I0816 10:11:05.280728 20528 net.cpp:434] relu4_7 <- conv4_7
I0816 10:11:05.280745 20528 net.cpp:395] relu4_7 -> conv4_7 (in-place)
I0816 10:11:05.281788 20528 net.cpp:150] Setting up relu4_7
I0816 10:11:05.281816 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.281838 20528 net.cpp:165] Memory required for data: 23864320
I0816 10:11:05.281853 20528 layer_factory.hpp:77] Creating layer conv4_8
I0816 10:11:05.281877 20528 net.cpp:100] Creating Layer conv4_8
I0816 10:11:05.281888 20528 net.cpp:434] conv4_8 <- conv4_7
I0816 10:11:05.281905 20528 net.cpp:408] conv4_8 -> conv4_8
I0816 10:11:05.312515 20528 net.cpp:150] Setting up conv4_8
I0816 10:11:05.312536 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.312542 20528 net.cpp:165] Memory required for data: 23987200
I0816 10:11:05.312553 20528 layer_factory.hpp:77] Creating layer relu4_8
I0816 10:11:05.312563 20528 net.cpp:100] Creating Layer relu4_8
I0816 10:11:05.312571 20528 net.cpp:434] relu4_8 <- conv4_8
I0816 10:11:05.312579 20528 net.cpp:395] relu4_8 -> conv4_8 (in-place)
I0816 10:11:05.312726 20528 net.cpp:150] Setting up relu4_8
I0816 10:11:05.312746 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.312750 20528 net.cpp:165] Memory required for data: 24110080
I0816 10:11:05.312758 20528 layer_factory.hpp:77] Creating layer res4_8
I0816 10:11:05.312768 20528 net.cpp:100] Creating Layer res4_8
I0816 10:11:05.312774 20528 net.cpp:434] res4_8 <- res4_6_res4_6_0_split_1
I0816 10:11:05.312782 20528 net.cpp:434] res4_8 <- conv4_8
I0816 10:11:05.312789 20528 net.cpp:408] res4_8 -> res4_8
I0816 10:11:05.312829 20528 net.cpp:150] Setting up res4_8
I0816 10:11:05.312839 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.312844 20528 net.cpp:165] Memory required for data: 24232960
I0816 10:11:05.312849 20528 layer_factory.hpp:77] Creating layer res4_8_res4_8_0_split
I0816 10:11:05.312857 20528 net.cpp:100] Creating Layer res4_8_res4_8_0_split
I0816 10:11:05.312863 20528 net.cpp:434] res4_8_res4_8_0_split <- res4_8
I0816 10:11:05.312871 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_0
I0816 10:11:05.312880 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_1
I0816 10:11:05.312930 20528 net.cpp:150] Setting up res4_8_res4_8_0_split
I0816 10:11:05.312940 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.312947 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.312952 20528 net.cpp:165] Memory required for data: 24478720
I0816 10:11:05.312957 20528 layer_factory.hpp:77] Creating layer conv4_9
I0816 10:11:05.312969 20528 net.cpp:100] Creating Layer conv4_9
I0816 10:11:05.312975 20528 net.cpp:434] conv4_9 <- res4_8_res4_8_0_split_0
I0816 10:11:05.312984 20528 net.cpp:408] conv4_9 -> conv4_9
I0816 10:11:05.341416 20528 net.cpp:150] Setting up conv4_9
I0816 10:11:05.341439 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.341444 20528 net.cpp:165] Memory required for data: 24601600
I0816 10:11:05.341455 20528 layer_factory.hpp:77] Creating layer relu4_9
I0816 10:11:05.341465 20528 net.cpp:100] Creating Layer relu4_9
I0816 10:11:05.341472 20528 net.cpp:434] relu4_9 <- conv4_9
I0816 10:11:05.341481 20528 net.cpp:395] relu4_9 -> conv4_9 (in-place)
I0816 10:11:05.341622 20528 net.cpp:150] Setting up relu4_9
I0816 10:11:05.341634 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.341639 20528 net.cpp:165] Memory required for data: 24724480
I0816 10:11:05.341645 20528 layer_factory.hpp:77] Creating layer conv4_10
I0816 10:11:05.341660 20528 net.cpp:100] Creating Layer conv4_10
I0816 10:11:05.341665 20528 net.cpp:434] conv4_10 <- conv4_9
I0816 10:11:05.341675 20528 net.cpp:408] conv4_10 -> conv4_10
I0816 10:11:05.366554 20528 net.cpp:150] Setting up conv4_10
I0816 10:11:05.366581 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.366587 20528 net.cpp:165] Memory required for data: 24847360
I0816 10:11:05.366597 20528 layer_factory.hpp:77] Creating layer relu4_10
I0816 10:11:05.366608 20528 net.cpp:100] Creating Layer relu4_10
I0816 10:11:05.366616 20528 net.cpp:434] relu4_10 <- conv4_10
I0816 10:11:05.366624 20528 net.cpp:395] relu4_10 -> conv4_10 (in-place)
I0816 10:11:05.366785 20528 net.cpp:150] Setting up relu4_10
I0816 10:11:05.366796 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.366809 20528 net.cpp:165] Memory required for data: 24970240
I0816 10:11:05.366817 20528 layer_factory.hpp:77] Creating layer res4_10
I0816 10:11:05.366827 20528 net.cpp:100] Creating Layer res4_10
I0816 10:11:05.366833 20528 net.cpp:434] res4_10 <- res4_8_res4_8_0_split_1
I0816 10:11:05.366840 20528 net.cpp:434] res4_10 <- conv4_10
I0816 10:11:05.366848 20528 net.cpp:408] res4_10 -> res4_10
I0816 10:11:05.366888 20528 net.cpp:150] Setting up res4_10
I0816 10:11:05.366896 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:05.366902 20528 net.cpp:165] Memory required for data: 25093120
I0816 10:11:05.366907 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:05.366919 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:05.366925 20528 net.cpp:434] conv4 <- res4_10
I0816 10:11:05.366935 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:05.378502 20528 net.cpp:150] Setting up conv4
I0816 10:11:05.378530 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:05.378536 20528 net.cpp:165] Memory required for data: 25256960
I0816 10:11:05.378547 20528 layer_factory.hpp:77] Creating layer relu4
I0816 10:11:05.378561 20528 net.cpp:100] Creating Layer relu4
I0816 10:11:05.378567 20528 net.cpp:434] relu4 <- conv4
I0816 10:11:05.378576 20528 net.cpp:395] relu4 -> conv4 (in-place)
I0816 10:11:05.378798 20528 net.cpp:150] Setting up relu4
I0816 10:11:05.378813 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:05.378818 20528 net.cpp:165] Memory required for data: 25420800
I0816 10:11:05.378825 20528 layer_factory.hpp:77] Creating layer pool4
I0816 10:11:05.378835 20528 net.cpp:100] Creating Layer pool4
I0816 10:11:05.378840 20528 net.cpp:434] pool4 <- conv4
I0816 10:11:05.378849 20528 net.cpp:408] pool4 -> pool4
I0816 10:11:05.378906 20528 net.cpp:150] Setting up pool4
I0816 10:11:05.378916 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.378921 20528 net.cpp:165] Memory required for data: 25461760
I0816 10:11:05.378926 20528 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I0816 10:11:05.378934 20528 net.cpp:100] Creating Layer pool4_pool4_0_split
I0816 10:11:05.378940 20528 net.cpp:434] pool4_pool4_0_split <- pool4
I0816 10:11:05.378949 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_0
I0816 10:11:05.378957 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_1
I0816 10:11:05.379006 20528 net.cpp:150] Setting up pool4_pool4_0_split
I0816 10:11:05.379015 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.379021 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.379026 20528 net.cpp:165] Memory required for data: 25543680
I0816 10:11:05.379031 20528 layer_factory.hpp:77] Creating layer conv5_1
I0816 10:11:05.379056 20528 net.cpp:100] Creating Layer conv5_1
I0816 10:11:05.379062 20528 net.cpp:434] conv5_1 <- pool4_pool4_0_split_0
I0816 10:11:05.379071 20528 net.cpp:408] conv5_1 -> conv5_1
I0816 10:11:05.471256 20528 net.cpp:150] Setting up conv5_1
I0816 10:11:05.471297 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.471302 20528 net.cpp:165] Memory required for data: 25584640
I0816 10:11:05.471333 20528 layer_factory.hpp:77] Creating layer relu5_1
I0816 10:11:05.471349 20528 net.cpp:100] Creating Layer relu5_1
I0816 10:11:05.471356 20528 net.cpp:434] relu5_1 <- conv5_1
I0816 10:11:05.471365 20528 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0816 10:11:05.471562 20528 net.cpp:150] Setting up relu5_1
I0816 10:11:05.471575 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.471580 20528 net.cpp:165] Memory required for data: 25625600
I0816 10:11:05.471587 20528 layer_factory.hpp:77] Creating layer conv5_2
I0816 10:11:05.471602 20528 net.cpp:100] Creating Layer conv5_2
I0816 10:11:05.471608 20528 net.cpp:434] conv5_2 <- conv5_1
I0816 10:11:05.471619 20528 net.cpp:408] conv5_2 -> conv5_2
I0816 10:11:05.563663 20528 net.cpp:150] Setting up conv5_2
I0816 10:11:05.563688 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.563694 20528 net.cpp:165] Memory required for data: 25666560
I0816 10:11:05.563716 20528 layer_factory.hpp:77] Creating layer relu5_2
I0816 10:11:05.563726 20528 net.cpp:100] Creating Layer relu5_2
I0816 10:11:05.563740 20528 net.cpp:434] relu5_2 <- conv5_2
I0816 10:11:05.563748 20528 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0816 10:11:05.563928 20528 net.cpp:150] Setting up relu5_2
I0816 10:11:05.563938 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.563943 20528 net.cpp:165] Memory required for data: 25707520
I0816 10:11:05.563951 20528 layer_factory.hpp:77] Creating layer res5_2
I0816 10:11:05.563963 20528 net.cpp:100] Creating Layer res5_2
I0816 10:11:05.563971 20528 net.cpp:434] res5_2 <- pool4_pool4_0_split_1
I0816 10:11:05.563977 20528 net.cpp:434] res5_2 <- conv5_2
I0816 10:11:05.563987 20528 net.cpp:408] res5_2 -> res5_2
I0816 10:11:05.564025 20528 net.cpp:150] Setting up res5_2
I0816 10:11:05.564034 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.564039 20528 net.cpp:165] Memory required for data: 25748480
I0816 10:11:05.564044 20528 layer_factory.hpp:77] Creating layer res5_2_res5_2_0_split
I0816 10:11:05.564055 20528 net.cpp:100] Creating Layer res5_2_res5_2_0_split
I0816 10:11:05.564061 20528 net.cpp:434] res5_2_res5_2_0_split <- res5_2
I0816 10:11:05.564067 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_0
I0816 10:11:05.564076 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_1
I0816 10:11:05.564128 20528 net.cpp:150] Setting up res5_2_res5_2_0_split
I0816 10:11:05.564136 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.564143 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.564148 20528 net.cpp:165] Memory required for data: 25830400
I0816 10:11:05.564153 20528 layer_factory.hpp:77] Creating layer conv5_3
I0816 10:11:05.564167 20528 net.cpp:100] Creating Layer conv5_3
I0816 10:11:05.564173 20528 net.cpp:434] conv5_3 <- res5_2_res5_2_0_split_0
I0816 10:11:05.564184 20528 net.cpp:408] conv5_3 -> conv5_3
I0816 10:11:05.661224 20528 net.cpp:150] Setting up conv5_3
I0816 10:11:05.661289 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.661301 20528 net.cpp:165] Memory required for data: 25871360
I0816 10:11:05.661324 20528 layer_factory.hpp:77] Creating layer relu5_3
I0816 10:11:05.661342 20528 net.cpp:100] Creating Layer relu5_3
I0816 10:11:05.661356 20528 net.cpp:434] relu5_3 <- conv5_3
I0816 10:11:05.661372 20528 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0816 10:11:05.661669 20528 net.cpp:150] Setting up relu5_3
I0816 10:11:05.661690 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.661700 20528 net.cpp:165] Memory required for data: 25912320
I0816 10:11:05.661713 20528 layer_factory.hpp:77] Creating layer conv5_4
I0816 10:11:05.661746 20528 net.cpp:100] Creating Layer conv5_4
I0816 10:11:05.661759 20528 net.cpp:434] conv5_4 <- conv5_3
I0816 10:11:05.661778 20528 net.cpp:408] conv5_4 -> conv5_4
I0816 10:11:05.772119 20528 net.cpp:150] Setting up conv5_4
I0816 10:11:05.772159 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.772169 20528 net.cpp:165] Memory required for data: 25953280
I0816 10:11:05.772191 20528 layer_factory.hpp:77] Creating layer relu5_4
I0816 10:11:05.772208 20528 net.cpp:100] Creating Layer relu5_4
I0816 10:11:05.772222 20528 net.cpp:434] relu5_4 <- conv5_4
I0816 10:11:05.772238 20528 net.cpp:395] relu5_4 -> conv5_4 (in-place)
I0816 10:11:05.772485 20528 net.cpp:150] Setting up relu5_4
I0816 10:11:05.772503 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.772513 20528 net.cpp:165] Memory required for data: 25994240
I0816 10:11:05.772523 20528 layer_factory.hpp:77] Creating layer res5_4
I0816 10:11:05.772536 20528 net.cpp:100] Creating Layer res5_4
I0816 10:11:05.772558 20528 net.cpp:434] res5_4 <- res5_2_res5_2_0_split_1
I0816 10:11:05.772568 20528 net.cpp:434] res5_4 <- conv5_4
I0816 10:11:05.772581 20528 net.cpp:408] res5_4 -> res5_4
I0816 10:11:05.772636 20528 net.cpp:150] Setting up res5_4
I0816 10:11:05.772650 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.772660 20528 net.cpp:165] Memory required for data: 26035200
I0816 10:11:05.772677 20528 layer_factory.hpp:77] Creating layer res5_4_res5_4_0_split
I0816 10:11:05.772688 20528 net.cpp:100] Creating Layer res5_4_res5_4_0_split
I0816 10:11:05.772694 20528 net.cpp:434] res5_4_res5_4_0_split <- res5_4
I0816 10:11:05.772706 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_0
I0816 10:11:05.772716 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_1
I0816 10:11:05.772799 20528 net.cpp:150] Setting up res5_4_res5_4_0_split
I0816 10:11:05.772811 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.772820 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.772828 20528 net.cpp:165] Memory required for data: 26117120
I0816 10:11:05.772838 20528 layer_factory.hpp:77] Creating layer conv5_5
I0816 10:11:05.772861 20528 net.cpp:100] Creating Layer conv5_5
I0816 10:11:05.772868 20528 net.cpp:434] conv5_5 <- res5_4_res5_4_0_split_0
I0816 10:11:05.772888 20528 net.cpp:408] conv5_5 -> conv5_5
I0816 10:11:05.866504 20528 net.cpp:150] Setting up conv5_5
I0816 10:11:05.866540 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.866546 20528 net.cpp:165] Memory required for data: 26158080
I0816 10:11:05.866559 20528 layer_factory.hpp:77] Creating layer relu5_5
I0816 10:11:05.866572 20528 net.cpp:100] Creating Layer relu5_5
I0816 10:11:05.866580 20528 net.cpp:434] relu5_5 <- conv5_5
I0816 10:11:05.866590 20528 net.cpp:395] relu5_5 -> conv5_5 (in-place)
I0816 10:11:05.866783 20528 net.cpp:150] Setting up relu5_5
I0816 10:11:05.866797 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.866803 20528 net.cpp:165] Memory required for data: 26199040
I0816 10:11:05.866811 20528 layer_factory.hpp:77] Creating layer conv5_6
I0816 10:11:05.866825 20528 net.cpp:100] Creating Layer conv5_6
I0816 10:11:05.866832 20528 net.cpp:434] conv5_6 <- conv5_5
I0816 10:11:05.866840 20528 net.cpp:408] conv5_6 -> conv5_6
I0816 10:11:05.960448 20528 net.cpp:150] Setting up conv5_6
I0816 10:11:05.960479 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.960485 20528 net.cpp:165] Memory required for data: 26240000
I0816 10:11:05.960497 20528 layer_factory.hpp:77] Creating layer relu5_6
I0816 10:11:05.960511 20528 net.cpp:100] Creating Layer relu5_6
I0816 10:11:05.960520 20528 net.cpp:434] relu5_6 <- conv5_6
I0816 10:11:05.960528 20528 net.cpp:395] relu5_6 -> conv5_6 (in-place)
I0816 10:11:05.960743 20528 net.cpp:150] Setting up relu5_6
I0816 10:11:05.960757 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.960763 20528 net.cpp:165] Memory required for data: 26280960
I0816 10:11:05.960772 20528 layer_factory.hpp:77] Creating layer res5_6
I0816 10:11:05.960788 20528 net.cpp:100] Creating Layer res5_6
I0816 10:11:05.960796 20528 net.cpp:434] res5_6 <- res5_4_res5_4_0_split_1
I0816 10:11:05.960804 20528 net.cpp:434] res5_6 <- conv5_6
I0816 10:11:05.960813 20528 net.cpp:408] res5_6 -> res5_6
I0816 10:11:05.960901 20528 net.cpp:150] Setting up res5_6
I0816 10:11:05.960912 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:05.960918 20528 net.cpp:165] Memory required for data: 26321920
I0816 10:11:05.960924 20528 layer_factory.hpp:77] Creating layer fc5
I0816 10:11:05.960939 20528 net.cpp:100] Creating Layer fc5
I0816 10:11:05.960947 20528 net.cpp:434] fc5 <- res5_6
I0816 10:11:05.960953 20528 net.cpp:408] fc5 -> fc5
I0816 10:11:06.003257 20528 net.cpp:150] Setting up fc5
I0816 10:11:06.003303 20528 net.cpp:157] Top shape: 1 512 (512)
I0816 10:11:06.003309 20528 net.cpp:165] Memory required for data: 26323968
I0816 10:11:06.003322 20528 net.cpp:228] fc5 does not need backward computation.
I0816 10:11:06.003329 20528 net.cpp:228] res5_6 does not need backward computation.
I0816 10:11:06.003335 20528 net.cpp:228] relu5_6 does not need backward computation.
I0816 10:11:06.003341 20528 net.cpp:228] conv5_6 does not need backward computation.
I0816 10:11:06.003347 20528 net.cpp:228] relu5_5 does not need backward computation.
I0816 10:11:06.003352 20528 net.cpp:228] conv5_5 does not need backward computation.
I0816 10:11:06.003368 20528 net.cpp:228] res5_4_res5_4_0_split does not need backward computation.
I0816 10:11:06.003376 20528 net.cpp:228] res5_4 does not need backward computation.
I0816 10:11:06.003381 20528 net.cpp:228] relu5_4 does not need backward computation.
I0816 10:11:06.003387 20528 net.cpp:228] conv5_4 does not need backward computation.
I0816 10:11:06.003392 20528 net.cpp:228] relu5_3 does not need backward computation.
I0816 10:11:06.003398 20528 net.cpp:228] conv5_3 does not need backward computation.
I0816 10:11:06.003404 20528 net.cpp:228] res5_2_res5_2_0_split does not need backward computation.
I0816 10:11:06.003409 20528 net.cpp:228] res5_2 does not need backward computation.
I0816 10:11:06.003417 20528 net.cpp:228] relu5_2 does not need backward computation.
I0816 10:11:06.003422 20528 net.cpp:228] conv5_2 does not need backward computation.
I0816 10:11:06.003427 20528 net.cpp:228] relu5_1 does not need backward computation.
I0816 10:11:06.003434 20528 net.cpp:228] conv5_1 does not need backward computation.
I0816 10:11:06.003440 20528 net.cpp:228] pool4_pool4_0_split does not need backward computation.
I0816 10:11:06.003446 20528 net.cpp:228] pool4 does not need backward computation.
I0816 10:11:06.003453 20528 net.cpp:228] relu4 does not need backward computation.
I0816 10:11:06.003458 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:06.003464 20528 net.cpp:228] res4_10 does not need backward computation.
I0816 10:11:06.003473 20528 net.cpp:228] relu4_10 does not need backward computation.
I0816 10:11:06.003480 20528 net.cpp:228] conv4_10 does not need backward computation.
I0816 10:11:06.003485 20528 net.cpp:228] relu4_9 does not need backward computation.
I0816 10:11:06.003492 20528 net.cpp:228] conv4_9 does not need backward computation.
I0816 10:11:06.003499 20528 net.cpp:228] res4_8_res4_8_0_split does not need backward computation.
I0816 10:11:06.003504 20528 net.cpp:228] res4_8 does not need backward computation.
I0816 10:11:06.003510 20528 net.cpp:228] relu4_8 does not need backward computation.
I0816 10:11:06.003516 20528 net.cpp:228] conv4_8 does not need backward computation.
I0816 10:11:06.003522 20528 net.cpp:228] relu4_7 does not need backward computation.
I0816 10:11:06.003528 20528 net.cpp:228] conv4_7 does not need backward computation.
I0816 10:11:06.003535 20528 net.cpp:228] res4_6_res4_6_0_split does not need backward computation.
I0816 10:11:06.003541 20528 net.cpp:228] res4_6 does not need backward computation.
I0816 10:11:06.003548 20528 net.cpp:228] relu4_6 does not need backward computation.
I0816 10:11:06.003556 20528 net.cpp:228] conv4_6 does not need backward computation.
I0816 10:11:06.003561 20528 net.cpp:228] relu4_5 does not need backward computation.
I0816 10:11:06.003568 20528 net.cpp:228] conv4_5 does not need backward computation.
I0816 10:11:06.003574 20528 net.cpp:228] res4_4_res4_4_0_split does not need backward computation.
I0816 10:11:06.003581 20528 net.cpp:228] res4_4 does not need backward computation.
I0816 10:11:06.003587 20528 net.cpp:228] relu4_4 does not need backward computation.
I0816 10:11:06.003592 20528 net.cpp:228] conv4_4 does not need backward computation.
I0816 10:11:06.003599 20528 net.cpp:228] relu4_3 does not need backward computation.
I0816 10:11:06.003605 20528 net.cpp:228] conv4_3 does not need backward computation.
I0816 10:11:06.003612 20528 net.cpp:228] res4_2_res4_2_0_split does not need backward computation.
I0816 10:11:06.003618 20528 net.cpp:228] res4_2 does not need backward computation.
I0816 10:11:06.003624 20528 net.cpp:228] relu4_2 does not need backward computation.
I0816 10:11:06.003630 20528 net.cpp:228] conv4_2 does not need backward computation.
I0816 10:11:06.003636 20528 net.cpp:228] relu4_1 does not need backward computation.
I0816 10:11:06.003643 20528 net.cpp:228] conv4_1 does not need backward computation.
I0816 10:11:06.003649 20528 net.cpp:228] pool3_pool3_0_split does not need backward computation.
I0816 10:11:06.003655 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:06.003674 20528 net.cpp:228] relu3 does not need backward computation.
I0816 10:11:06.003679 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:06.003685 20528 net.cpp:228] res3_4 does not need backward computation.
I0816 10:11:06.003693 20528 net.cpp:228] relu3_4 does not need backward computation.
I0816 10:11:06.003700 20528 net.cpp:228] conv3_4 does not need backward computation.
I0816 10:11:06.003707 20528 net.cpp:228] relu3_3 does not need backward computation.
I0816 10:11:06.003715 20528 net.cpp:228] conv3_3 does not need backward computation.
I0816 10:11:06.003720 20528 net.cpp:228] res3_2_res3_2_0_split does not need backward computation.
I0816 10:11:06.003727 20528 net.cpp:228] res3_2 does not need backward computation.
I0816 10:11:06.003741 20528 net.cpp:228] relu3_2 does not need backward computation.
I0816 10:11:06.003747 20528 net.cpp:228] conv3_2 does not need backward computation.
I0816 10:11:06.003753 20528 net.cpp:228] relu3_1 does not need backward computation.
I0816 10:11:06.003759 20528 net.cpp:228] conv3_1 does not need backward computation.
I0816 10:11:06.003765 20528 net.cpp:228] pool2_pool2_0_split does not need backward computation.
I0816 10:11:06.003772 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:06.003779 20528 net.cpp:228] relu2 does not need backward computation.
I0816 10:11:06.003785 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:06.003793 20528 net.cpp:228] res2_2 does not need backward computation.
I0816 10:11:06.003803 20528 net.cpp:228] relu2_2 does not need backward computation.
I0816 10:11:06.003810 20528 net.cpp:228] conv2_2 does not need backward computation.
I0816 10:11:06.003818 20528 net.cpp:228] relu2_1 does not need backward computation.
I0816 10:11:06.003824 20528 net.cpp:228] conv2_1 does not need backward computation.
I0816 10:11:06.003830 20528 net.cpp:228] pool1b_pool1b_0_split does not need backward computation.
I0816 10:11:06.003836 20528 net.cpp:228] pool1b does not need backward computation.
I0816 10:11:06.003844 20528 net.cpp:228] relu1b does not need backward computation.
I0816 10:11:06.003849 20528 net.cpp:228] conv1b does not need backward computation.
I0816 10:11:06.003856 20528 net.cpp:228] relu1a does not need backward computation.
I0816 10:11:06.003861 20528 net.cpp:228] conv1a does not need backward computation.
I0816 10:11:06.003867 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:06.003872 20528 net.cpp:270] This network produces output fc5
I0816 10:11:06.003929 20528 net.cpp:283] Network initialization done.
I0816 10:11:06.321012 20528 net.cpp:761] Ignoring source layer data
I0816 10:11:06.321053 20528 net.cpp:761] Ignoring source layer label_data_1_split
I0816 10:11:06.343936 20528 net.cpp:761] Ignoring source layer fc5_fc5_0_split
I0816 10:11:06.343966 20528 net.cpp:761] Ignoring source layer fc6
I0816 10:11:06.343971 20528 net.cpp:761] Ignoring source layer softmax_loss
I0816 10:11:06.343976 20528 net.cpp:761] Ignoring source layer center_loss
i: 620   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_440
I0816 10:11:06.345916 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det1.prototxt
I0816 10:11:06.345937 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:06.345942 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:06.346107 20528 net.cpp:58] Initializing net from parameters: 
name: "PNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 12
      dim: 12
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 10
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4-1"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4-2"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv4-1"
  top: "prob1"
}
I0816 10:11:06.346190 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:06.346205 20528 net.cpp:100] Creating Layer input
I0816 10:11:06.346212 20528 net.cpp:408] input -> data
I0816 10:11:06.346339 20528 net.cpp:150] Setting up input
I0816 10:11:06.346352 20528 net.cpp:157] Top shape: 1 3 12 12 (432)
I0816 10:11:06.346357 20528 net.cpp:165] Memory required for data: 1728
I0816 10:11:06.346364 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:06.346375 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:06.346381 20528 net.cpp:434] conv1 <- data
I0816 10:11:06.346388 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:06.349009 20528 net.cpp:150] Setting up conv1
I0816 10:11:06.349028 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:06.349035 20528 net.cpp:165] Memory required for data: 5728
I0816 10:11:06.349050 20528 layer_factory.hpp:77] Creating layer PReLU1
I0816 10:11:06.349061 20528 net.cpp:100] Creating Layer PReLU1
I0816 10:11:06.349067 20528 net.cpp:434] PReLU1 <- conv1
I0816 10:11:06.349076 20528 net.cpp:395] PReLU1 -> conv1 (in-place)
I0816 10:11:06.349261 20528 net.cpp:150] Setting up PReLU1
I0816 10:11:06.349272 20528 net.cpp:157] Top shape: 1 10 10 10 (1000)
I0816 10:11:06.349277 20528 net.cpp:165] Memory required for data: 9728
I0816 10:11:06.349287 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:06.349298 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:06.349303 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:06.349310 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:06.349367 20528 net.cpp:150] Setting up pool1
I0816 10:11:06.349377 20528 net.cpp:157] Top shape: 1 10 5 5 (250)
I0816 10:11:06.349383 20528 net.cpp:165] Memory required for data: 10728
I0816 10:11:06.349388 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:06.349401 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:06.349406 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:06.349414 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:06.351186 20528 net.cpp:150] Setting up conv2
I0816 10:11:06.351205 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:06.351217 20528 net.cpp:165] Memory required for data: 11304
I0816 10:11:06.351231 20528 layer_factory.hpp:77] Creating layer PReLU2
I0816 10:11:06.351239 20528 net.cpp:100] Creating Layer PReLU2
I0816 10:11:06.351245 20528 net.cpp:434] PReLU2 <- conv2
I0816 10:11:06.351255 20528 net.cpp:395] PReLU2 -> conv2 (in-place)
I0816 10:11:06.351399 20528 net.cpp:150] Setting up PReLU2
I0816 10:11:06.351409 20528 net.cpp:157] Top shape: 1 16 3 3 (144)
I0816 10:11:06.351414 20528 net.cpp:165] Memory required for data: 11880
I0816 10:11:06.351423 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:06.351433 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:06.351440 20528 net.cpp:434] conv3 <- conv2
I0816 10:11:06.351449 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:06.353559 20528 net.cpp:150] Setting up conv3
I0816 10:11:06.353577 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:06.353584 20528 net.cpp:165] Memory required for data: 12008
I0816 10:11:06.353593 20528 layer_factory.hpp:77] Creating layer PReLU3
I0816 10:11:06.353603 20528 net.cpp:100] Creating Layer PReLU3
I0816 10:11:06.353608 20528 net.cpp:434] PReLU3 <- conv3
I0816 10:11:06.353616 20528 net.cpp:395] PReLU3 -> conv3 (in-place)
I0816 10:11:06.353766 20528 net.cpp:150] Setting up PReLU3
I0816 10:11:06.353778 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:06.353783 20528 net.cpp:165] Memory required for data: 12136
I0816 10:11:06.353794 20528 layer_factory.hpp:77] Creating layer conv3_PReLU3_0_split
I0816 10:11:06.353806 20528 net.cpp:100] Creating Layer conv3_PReLU3_0_split
I0816 10:11:06.353811 20528 net.cpp:434] conv3_PReLU3_0_split <- conv3
I0816 10:11:06.353818 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_0
I0816 10:11:06.353827 20528 net.cpp:408] conv3_PReLU3_0_split -> conv3_PReLU3_0_split_1
I0816 10:11:06.353880 20528 net.cpp:150] Setting up conv3_PReLU3_0_split
I0816 10:11:06.353889 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:06.353895 20528 net.cpp:157] Top shape: 1 32 1 1 (32)
I0816 10:11:06.353900 20528 net.cpp:165] Memory required for data: 12392
I0816 10:11:06.353905 20528 layer_factory.hpp:77] Creating layer conv4-1
I0816 10:11:06.353917 20528 net.cpp:100] Creating Layer conv4-1
I0816 10:11:06.353924 20528 net.cpp:434] conv4-1 <- conv3_PReLU3_0_split_0
I0816 10:11:06.353932 20528 net.cpp:408] conv4-1 -> conv4-1
I0816 10:11:06.356051 20528 net.cpp:150] Setting up conv4-1
I0816 10:11:06.356070 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:06.356076 20528 net.cpp:165] Memory required for data: 12400
I0816 10:11:06.356086 20528 layer_factory.hpp:77] Creating layer conv4-2
I0816 10:11:06.356101 20528 net.cpp:100] Creating Layer conv4-2
I0816 10:11:06.356107 20528 net.cpp:434] conv4-2 <- conv3_PReLU3_0_split_1
I0816 10:11:06.356117 20528 net.cpp:408] conv4-2 -> conv4-2
I0816 10:11:06.358228 20528 net.cpp:150] Setting up conv4-2
I0816 10:11:06.358248 20528 net.cpp:157] Top shape: 1 4 1 1 (4)
I0816 10:11:06.358254 20528 net.cpp:165] Memory required for data: 12416
I0816 10:11:06.358265 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:06.358278 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:06.358284 20528 net.cpp:434] prob1 <- conv4-1
I0816 10:11:06.358294 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:06.358657 20528 net.cpp:150] Setting up prob1
I0816 10:11:06.358669 20528 net.cpp:157] Top shape: 1 2 1 1 (2)
I0816 10:11:06.358675 20528 net.cpp:165] Memory required for data: 12424
I0816 10:11:06.358681 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:06.358687 20528 net.cpp:228] conv4-2 does not need backward computation.
I0816 10:11:06.358692 20528 net.cpp:228] conv4-1 does not need backward computation.
I0816 10:11:06.358697 20528 net.cpp:228] conv3_PReLU3_0_split does not need backward computation.
I0816 10:11:06.358702 20528 net.cpp:228] PReLU3 does not need backward computation.
I0816 10:11:06.358707 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:06.358713 20528 net.cpp:228] PReLU2 does not need backward computation.
I0816 10:11:06.358723 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:06.358736 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:06.358741 20528 net.cpp:228] PReLU1 does not need backward computation.
I0816 10:11:06.358747 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:06.358752 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:06.358757 20528 net.cpp:270] This network produces output conv4-2
I0816 10:11:06.358763 20528 net.cpp:270] This network produces output prob1
I0816 10:11:06.358777 20528 net.cpp:283] Network initialization done.
I0816 10:11:06.358973 20528 net.cpp:761] Ignoring source layer data12
I0816 10:11:06.358981 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:06.358986 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:06.358991 20528 net.cpp:761] Ignoring source layer silence
I0816 10:11:06.359004 20528 net.cpp:761] Ignoring source layer conv4-1_conv4-1_0_split
I0816 10:11:06.359010 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:06.359015 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:06.359019 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:06.359388 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det2.prototxt
I0816 10:11:06.359400 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:06.359405 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:06.359558 20528 net.cpp:58] Initializing net from parameters: 
name: "RNet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 24
      dim: 24
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 28
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
  propagate_down: true
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 48
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
  propagate_down: true
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 2
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
  propagate_down: true
}
layer {
  name: "conv4"
  type: "InnerProduct"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 128
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5-1"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv5-2"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv5-1"
  top: "prob1"
}
I0816 10:11:06.359632 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:06.359643 20528 net.cpp:100] Creating Layer input
I0816 10:11:06.359650 20528 net.cpp:408] input -> data
I0816 10:11:06.359699 20528 net.cpp:150] Setting up input
I0816 10:11:06.359710 20528 net.cpp:157] Top shape: 1 3 24 24 (1728)
I0816 10:11:06.359715 20528 net.cpp:165] Memory required for data: 6912
I0816 10:11:06.359721 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:06.359740 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:06.359746 20528 net.cpp:434] conv1 <- data
I0816 10:11:06.359755 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:06.361919 20528 net.cpp:150] Setting up conv1
I0816 10:11:06.361939 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:06.361945 20528 net.cpp:165] Memory required for data: 61120
I0816 10:11:06.361960 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:06.361971 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:06.361977 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:06.361985 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:06.362138 20528 net.cpp:150] Setting up prelu1
I0816 10:11:06.362148 20528 net.cpp:157] Top shape: 1 28 22 22 (13552)
I0816 10:11:06.362154 20528 net.cpp:165] Memory required for data: 115328
I0816 10:11:06.362162 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:06.362172 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:06.362177 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:06.362185 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:06.362241 20528 net.cpp:150] Setting up pool1
I0816 10:11:06.362251 20528 net.cpp:157] Top shape: 1 28 11 11 (3388)
I0816 10:11:06.362256 20528 net.cpp:165] Memory required for data: 128880
I0816 10:11:06.362260 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:06.362272 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:06.362278 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:06.362287 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:06.364509 20528 net.cpp:150] Setting up conv2
I0816 10:11:06.364528 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:06.364533 20528 net.cpp:165] Memory required for data: 144432
I0816 10:11:06.364547 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:06.364557 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:06.364562 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:06.364570 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:06.364765 20528 net.cpp:150] Setting up prelu2
I0816 10:11:06.364778 20528 net.cpp:157] Top shape: 1 48 9 9 (3888)
I0816 10:11:06.364784 20528 net.cpp:165] Memory required for data: 159984
I0816 10:11:06.364790 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:06.364800 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:06.364805 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:06.364814 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:06.364869 20528 net.cpp:150] Setting up pool2
I0816 10:11:06.364881 20528 net.cpp:157] Top shape: 1 48 4 4 (768)
I0816 10:11:06.364886 20528 net.cpp:165] Memory required for data: 163056
I0816 10:11:06.364890 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:06.364902 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:06.364907 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:06.364915 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:06.367092 20528 net.cpp:150] Setting up conv3
I0816 10:11:06.367111 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:06.367122 20528 net.cpp:165] Memory required for data: 165360
I0816 10:11:06.367135 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:06.367146 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:06.367151 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:06.367158 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:06.367336 20528 net.cpp:150] Setting up prelu3
I0816 10:11:06.367347 20528 net.cpp:157] Top shape: 1 64 3 3 (576)
I0816 10:11:06.367352 20528 net.cpp:165] Memory required for data: 167664
I0816 10:11:06.367363 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:06.367373 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:06.367379 20528 net.cpp:434] conv4 <- conv3
I0816 10:11:06.367388 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:06.367990 20528 net.cpp:150] Setting up conv4
I0816 10:11:06.368001 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:06.368007 20528 net.cpp:165] Memory required for data: 168176
I0816 10:11:06.368016 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:06.368024 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:06.368029 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:06.368037 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:06.368149 20528 net.cpp:150] Setting up prelu4
I0816 10:11:06.368158 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:06.368163 20528 net.cpp:165] Memory required for data: 168688
I0816 10:11:06.368170 20528 layer_factory.hpp:77] Creating layer conv4_prelu4_0_split
I0816 10:11:06.368180 20528 net.cpp:100] Creating Layer conv4_prelu4_0_split
I0816 10:11:06.368185 20528 net.cpp:434] conv4_prelu4_0_split <- conv4
I0816 10:11:06.368192 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_0
I0816 10:11:06.368201 20528 net.cpp:408] conv4_prelu4_0_split -> conv4_prelu4_0_split_1
I0816 10:11:06.368254 20528 net.cpp:150] Setting up conv4_prelu4_0_split
I0816 10:11:06.368263 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:06.368269 20528 net.cpp:157] Top shape: 1 128 (128)
I0816 10:11:06.368274 20528 net.cpp:165] Memory required for data: 169712
I0816 10:11:06.368279 20528 layer_factory.hpp:77] Creating layer conv5-1
I0816 10:11:06.368288 20528 net.cpp:100] Creating Layer conv5-1
I0816 10:11:06.368294 20528 net.cpp:434] conv5-1 <- conv4_prelu4_0_split_0
I0816 10:11:06.368304 20528 net.cpp:408] conv5-1 -> conv5-1
I0816 10:11:06.368448 20528 net.cpp:150] Setting up conv5-1
I0816 10:11:06.368458 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:06.368463 20528 net.cpp:165] Memory required for data: 169720
I0816 10:11:06.368471 20528 layer_factory.hpp:77] Creating layer conv5-2
I0816 10:11:06.368479 20528 net.cpp:100] Creating Layer conv5-2
I0816 10:11:06.368485 20528 net.cpp:434] conv5-2 <- conv4_prelu4_0_split_1
I0816 10:11:06.368494 20528 net.cpp:408] conv5-2 -> conv5-2
I0816 10:11:06.368697 20528 net.cpp:150] Setting up conv5-2
I0816 10:11:06.368708 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:06.368713 20528 net.cpp:165] Memory required for data: 169736
I0816 10:11:06.368721 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:06.368736 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:06.368743 20528 net.cpp:434] prob1 <- conv5-1
I0816 10:11:06.368751 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:06.369117 20528 net.cpp:150] Setting up prob1
I0816 10:11:06.369130 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:06.369137 20528 net.cpp:165] Memory required for data: 169744
I0816 10:11:06.369141 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:06.369148 20528 net.cpp:228] conv5-2 does not need backward computation.
I0816 10:11:06.369153 20528 net.cpp:228] conv5-1 does not need backward computation.
I0816 10:11:06.369158 20528 net.cpp:228] conv4_prelu4_0_split does not need backward computation.
I0816 10:11:06.369163 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:06.369168 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:06.369174 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:06.369184 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:06.369189 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:06.369194 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:06.369199 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:06.369205 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:06.369210 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:06.369215 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:06.369220 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:06.369225 20528 net.cpp:270] This network produces output conv5-2
I0816 10:11:06.369231 20528 net.cpp:270] This network produces output prob1
I0816 10:11:06.369244 20528 net.cpp:283] Network initialization done.
I0816 10:11:06.370157 20528 net.cpp:761] Ignoring source layer data24
I0816 10:11:06.370167 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:06.370172 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:06.370224 20528 net.cpp:761] Ignoring source layer conv5-1_conv5-1_0_split
I0816 10:11:06.370232 20528 net.cpp:761] Ignoring source layer conv5-3
I0816 10:11:06.370237 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:06.370241 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:06.370246 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:06.370251 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:06.370724 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/det3.prototxt
I0816 10:11:06.370744 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:06.370749 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:06.370944 20528 net.cpp:58] Initializing net from parameters: 
name: "ONet"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 48
      dim: 48
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu1"
  type: "PReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    kernel_size: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prelu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "InnerProduct"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "drop5"
  type: "Dropout"
  bottom: "conv5"
  top: "conv5"
  dropout_param {
    dropout_ratio: 0.25
  }
}
layer {
  name: "prelu5"
  type: "PReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "conv6-1"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-2"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6-3"
  type: "InnerProduct"
  bottom: "conv5"
  top: "conv6-3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob1"
  type: "Softmax"
  bottom: "conv6-1"
  top: "prob1"
}
I0816 10:11:06.371031 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:06.371042 20528 net.cpp:100] Creating Layer input
I0816 10:11:06.371049 20528 net.cpp:408] input -> data
I0816 10:11:06.371101 20528 net.cpp:150] Setting up input
I0816 10:11:06.371112 20528 net.cpp:157] Top shape: 1 3 48 48 (6912)
I0816 10:11:06.371119 20528 net.cpp:165] Memory required for data: 27648
I0816 10:11:06.371124 20528 layer_factory.hpp:77] Creating layer conv1
I0816 10:11:06.371135 20528 net.cpp:100] Creating Layer conv1
I0816 10:11:06.371140 20528 net.cpp:434] conv1 <- data
I0816 10:11:06.371148 20528 net.cpp:408] conv1 -> conv1
I0816 10:11:06.375357 20528 net.cpp:150] Setting up conv1
I0816 10:11:06.375378 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:06.375385 20528 net.cpp:165] Memory required for data: 298496
I0816 10:11:06.375399 20528 layer_factory.hpp:77] Creating layer prelu1
I0816 10:11:06.375413 20528 net.cpp:100] Creating Layer prelu1
I0816 10:11:06.375419 20528 net.cpp:434] prelu1 <- conv1
I0816 10:11:06.375427 20528 net.cpp:395] prelu1 -> conv1 (in-place)
I0816 10:11:06.375641 20528 net.cpp:150] Setting up prelu1
I0816 10:11:06.375653 20528 net.cpp:157] Top shape: 1 32 46 46 (67712)
I0816 10:11:06.375658 20528 net.cpp:165] Memory required for data: 569344
I0816 10:11:06.375668 20528 layer_factory.hpp:77] Creating layer pool1
I0816 10:11:06.375675 20528 net.cpp:100] Creating Layer pool1
I0816 10:11:06.375681 20528 net.cpp:434] pool1 <- conv1
I0816 10:11:06.375689 20528 net.cpp:408] pool1 -> pool1
I0816 10:11:06.375753 20528 net.cpp:150] Setting up pool1
I0816 10:11:06.375764 20528 net.cpp:157] Top shape: 1 32 23 23 (16928)
I0816 10:11:06.375769 20528 net.cpp:165] Memory required for data: 637056
I0816 10:11:06.375774 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:06.375787 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:06.375792 20528 net.cpp:434] conv2 <- pool1
I0816 10:11:06.375799 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:06.378002 20528 net.cpp:150] Setting up conv2
I0816 10:11:06.378021 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:06.378027 20528 net.cpp:165] Memory required for data: 749952
I0816 10:11:06.378047 20528 layer_factory.hpp:77] Creating layer prelu2
I0816 10:11:06.378057 20528 net.cpp:100] Creating Layer prelu2
I0816 10:11:06.378062 20528 net.cpp:434] prelu2 <- conv2
I0816 10:11:06.378069 20528 net.cpp:395] prelu2 -> conv2 (in-place)
I0816 10:11:06.378228 20528 net.cpp:150] Setting up prelu2
I0816 10:11:06.378238 20528 net.cpp:157] Top shape: 1 64 21 21 (28224)
I0816 10:11:06.378243 20528 net.cpp:165] Memory required for data: 862848
I0816 10:11:06.378252 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:06.378259 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:06.378264 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:06.378271 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:06.378327 20528 net.cpp:150] Setting up pool2
I0816 10:11:06.378337 20528 net.cpp:157] Top shape: 1 64 10 10 (6400)
I0816 10:11:06.378342 20528 net.cpp:165] Memory required for data: 888448
I0816 10:11:06.378347 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:06.378358 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:06.378363 20528 net.cpp:434] conv3 <- pool2
I0816 10:11:06.378371 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:06.380668 20528 net.cpp:150] Setting up conv3
I0816 10:11:06.380687 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:06.380693 20528 net.cpp:165] Memory required for data: 904832
I0816 10:11:06.380703 20528 layer_factory.hpp:77] Creating layer prelu3
I0816 10:11:06.380713 20528 net.cpp:100] Creating Layer prelu3
I0816 10:11:06.380719 20528 net.cpp:434] prelu3 <- conv3
I0816 10:11:06.380726 20528 net.cpp:395] prelu3 -> conv3 (in-place)
I0816 10:11:06.380934 20528 net.cpp:150] Setting up prelu3
I0816 10:11:06.380945 20528 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0816 10:11:06.380951 20528 net.cpp:165] Memory required for data: 921216
I0816 10:11:06.380961 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:06.380970 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:06.380976 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:06.380983 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:06.381041 20528 net.cpp:150] Setting up pool3
I0816 10:11:06.381049 20528 net.cpp:157] Top shape: 1 64 4 4 (1024)
I0816 10:11:06.381054 20528 net.cpp:165] Memory required for data: 925312
I0816 10:11:06.381059 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:06.381072 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:06.381077 20528 net.cpp:434] conv4 <- pool3
I0816 10:11:06.381084 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:06.384124 20528 net.cpp:150] Setting up conv4
I0816 10:11:06.384143 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:06.384150 20528 net.cpp:165] Memory required for data: 929920
I0816 10:11:06.384160 20528 layer_factory.hpp:77] Creating layer prelu4
I0816 10:11:06.384169 20528 net.cpp:100] Creating Layer prelu4
I0816 10:11:06.384176 20528 net.cpp:434] prelu4 <- conv4
I0816 10:11:06.384182 20528 net.cpp:395] prelu4 -> conv4 (in-place)
I0816 10:11:06.384340 20528 net.cpp:150] Setting up prelu4
I0816 10:11:06.384349 20528 net.cpp:157] Top shape: 1 128 3 3 (1152)
I0816 10:11:06.384356 20528 net.cpp:165] Memory required for data: 934528
I0816 10:11:06.384362 20528 layer_factory.hpp:77] Creating layer conv5
I0816 10:11:06.384372 20528 net.cpp:100] Creating Layer conv5
I0816 10:11:06.384378 20528 net.cpp:434] conv5 <- conv4
I0816 10:11:06.384385 20528 net.cpp:408] conv5 -> conv5
I0816 10:11:06.387013 20528 net.cpp:150] Setting up conv5
I0816 10:11:06.387032 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:06.387037 20528 net.cpp:165] Memory required for data: 935552
I0816 10:11:06.387046 20528 layer_factory.hpp:77] Creating layer drop5
I0816 10:11:06.387055 20528 net.cpp:100] Creating Layer drop5
I0816 10:11:06.387061 20528 net.cpp:434] drop5 <- conv5
I0816 10:11:06.387068 20528 net.cpp:395] drop5 -> conv5 (in-place)
I0816 10:11:06.387105 20528 net.cpp:150] Setting up drop5
I0816 10:11:06.387115 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:06.387120 20528 net.cpp:165] Memory required for data: 936576
I0816 10:11:06.387135 20528 layer_factory.hpp:77] Creating layer prelu5
I0816 10:11:06.387142 20528 net.cpp:100] Creating Layer prelu5
I0816 10:11:06.387147 20528 net.cpp:434] prelu5 <- conv5
I0816 10:11:06.387154 20528 net.cpp:395] prelu5 -> conv5 (in-place)
I0816 10:11:06.387274 20528 net.cpp:150] Setting up prelu5
I0816 10:11:06.387282 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:06.387287 20528 net.cpp:165] Memory required for data: 937600
I0816 10:11:06.387295 20528 layer_factory.hpp:77] Creating layer conv5_prelu5_0_split
I0816 10:11:06.387303 20528 net.cpp:100] Creating Layer conv5_prelu5_0_split
I0816 10:11:06.387308 20528 net.cpp:434] conv5_prelu5_0_split <- conv5
I0816 10:11:06.387315 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_0
I0816 10:11:06.387323 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_1
I0816 10:11:06.387332 20528 net.cpp:408] conv5_prelu5_0_split -> conv5_prelu5_0_split_2
I0816 10:11:06.387403 20528 net.cpp:150] Setting up conv5_prelu5_0_split
I0816 10:11:06.387410 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:06.387416 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:06.387423 20528 net.cpp:157] Top shape: 1 256 (256)
I0816 10:11:06.387428 20528 net.cpp:165] Memory required for data: 940672
I0816 10:11:06.387432 20528 layer_factory.hpp:77] Creating layer conv6-1
I0816 10:11:06.387444 20528 net.cpp:100] Creating Layer conv6-1
I0816 10:11:06.387449 20528 net.cpp:434] conv6-1 <- conv5_prelu5_0_split_0
I0816 10:11:06.387457 20528 net.cpp:408] conv6-1 -> conv6-1
I0816 10:11:06.387647 20528 net.cpp:150] Setting up conv6-1
I0816 10:11:06.387657 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:06.387663 20528 net.cpp:165] Memory required for data: 940680
I0816 10:11:06.387676 20528 layer_factory.hpp:77] Creating layer conv6-2
I0816 10:11:06.387686 20528 net.cpp:100] Creating Layer conv6-2
I0816 10:11:06.387691 20528 net.cpp:434] conv6-2 <- conv5_prelu5_0_split_1
I0816 10:11:06.387698 20528 net.cpp:408] conv6-2 -> conv6-2
I0816 10:11:06.387886 20528 net.cpp:150] Setting up conv6-2
I0816 10:11:06.387897 20528 net.cpp:157] Top shape: 1 4 (4)
I0816 10:11:06.387902 20528 net.cpp:165] Memory required for data: 940696
I0816 10:11:06.387909 20528 layer_factory.hpp:77] Creating layer conv6-3
I0816 10:11:06.387918 20528 net.cpp:100] Creating Layer conv6-3
I0816 10:11:06.387924 20528 net.cpp:434] conv6-3 <- conv5_prelu5_0_split_2
I0816 10:11:06.387933 20528 net.cpp:408] conv6-3 -> conv6-3
I0816 10:11:06.388121 20528 net.cpp:150] Setting up conv6-3
I0816 10:11:06.388131 20528 net.cpp:157] Top shape: 1 10 (10)
I0816 10:11:06.388136 20528 net.cpp:165] Memory required for data: 940736
I0816 10:11:06.388144 20528 layer_factory.hpp:77] Creating layer prob1
I0816 10:11:06.388154 20528 net.cpp:100] Creating Layer prob1
I0816 10:11:06.388159 20528 net.cpp:434] prob1 <- conv6-1
I0816 10:11:06.388166 20528 net.cpp:408] prob1 -> prob1
I0816 10:11:06.388535 20528 net.cpp:150] Setting up prob1
I0816 10:11:06.388547 20528 net.cpp:157] Top shape: 1 2 (2)
I0816 10:11:06.388552 20528 net.cpp:165] Memory required for data: 940744
I0816 10:11:06.388557 20528 net.cpp:228] prob1 does not need backward computation.
I0816 10:11:06.388563 20528 net.cpp:228] conv6-3 does not need backward computation.
I0816 10:11:06.388568 20528 net.cpp:228] conv6-2 does not need backward computation.
I0816 10:11:06.388574 20528 net.cpp:228] conv6-1 does not need backward computation.
I0816 10:11:06.388579 20528 net.cpp:228] conv5_prelu5_0_split does not need backward computation.
I0816 10:11:06.388584 20528 net.cpp:228] prelu5 does not need backward computation.
I0816 10:11:06.388591 20528 net.cpp:228] drop5 does not need backward computation.
I0816 10:11:06.388594 20528 net.cpp:228] conv5 does not need backward computation.
I0816 10:11:06.388599 20528 net.cpp:228] prelu4 does not need backward computation.
I0816 10:11:06.388604 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:06.388610 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:06.388620 20528 net.cpp:228] prelu3 does not need backward computation.
I0816 10:11:06.388626 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:06.388631 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:06.388636 20528 net.cpp:228] prelu2 does not need backward computation.
I0816 10:11:06.388641 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:06.388648 20528 net.cpp:228] pool1 does not need backward computation.
I0816 10:11:06.388653 20528 net.cpp:228] prelu1 does not need backward computation.
I0816 10:11:06.388658 20528 net.cpp:228] conv1 does not need backward computation.
I0816 10:11:06.388662 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:06.388667 20528 net.cpp:270] This network produces output conv6-2
I0816 10:11:06.388674 20528 net.cpp:270] This network produces output conv6-3
I0816 10:11:06.388679 20528 net.cpp:270] This network produces output prob1
I0816 10:11:06.388695 20528 net.cpp:283] Network initialization done.
I0816 10:11:06.392065 20528 net.cpp:761] Ignoring source layer data48
I0816 10:11:06.392076 20528 net.cpp:761] Ignoring source layer slicer_label
I0816 10:11:06.392081 20528 net.cpp:761] Ignoring source layer label1_slicer_label_0_split
I0816 10:11:06.392287 20528 net.cpp:761] Ignoring source layer conv6-1_conv6-1_0_split
I0816 10:11:06.392298 20528 net.cpp:761] Ignoring source layer loss1
I0816 10:11:06.392303 20528 net.cpp:761] Ignoring source layer accuracy1
I0816 10:11:06.392308 20528 net.cpp:761] Ignoring source layer loss2
I0816 10:11:06.392313 20528 net.cpp:761] Ignoring source layer loss3
I0816 10:11:06.393962 20528 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: model/face_deploy.prototxt
I0816 10:11:06.393985 20528 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0816 10:11:06.393990 20528 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0816 10:11:06.394598 20528 net.cpp:58] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 112
      dim: 96
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1a"
  type: "PReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1b"
  type: "PReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1b"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1b"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1b"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "PReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "PReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "res2_2"
  type: "Eltwise"
  bottom: "pool1b"
  bottom: "conv2_2"
  top: "res2_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "res2_2"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "PReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "PReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "PReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "res3_2"
  type: "Eltwise"
  bottom: "pool2"
  bottom: "conv3_2"
  top: "res3_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "res3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "PReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "conv3_4"
  type: "Convolution"
  bottom: "conv3_3"
  top: "conv3_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_4"
  type: "PReLU"
  bottom: "conv3_4"
  top: "conv3_4"
}
layer {
  name: "res3_4"
  type: "Eltwise"
  bottom: "res3_2"
  bottom: "conv3_4"
  top: "res3_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "res3_4"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "PReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "PReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "PReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "res4_2"
  type: "Eltwise"
  bottom: "pool3"
  bottom: "conv4_2"
  top: "res4_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "res4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "PReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "conv4_4"
  type: "Convolution"
  bottom: "conv4_3"
  top: "conv4_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_4"
  type: "PReLU"
  bottom: "conv4_4"
  top: "conv4_4"
}
layer {
  name: "res4_4"
  type: "Eltwise"
  bottom: "res4_2"
  bottom: "conv4_4"
  top: "res4_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_5"
  type: "Convolution"
  bottom: "res4_4"
  top: "conv4_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_5"
  type: "PReLU"
  bottom: "conv4_5"
  top: "conv4_5"
}
layer {
  name: "conv4_6"
  type: "Convolution"
  bottom: "conv4_5"
  top: "conv4_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_6"
  type: "PReLU"
  bottom: "conv4_6"
  top: "conv4_6"
}
layer {
  name: "res4_6"
  type: "Eltwise"
  bottom: "res4_4"
  bottom: "conv4_6"
  top: "res4_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_7"
  type: "Convolution"
  bottom: "res4_6"
  top: "conv4_7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_7"
  type: "PReLU"
  bottom: "conv4_7"
  top: "conv4_7"
}
layer {
  name: "conv4_8"
  type: "Convolution"
  bottom: "conv4_7"
  top: "conv4_8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_8"
  type: "PReLU"
  bottom: "conv4_8"
  top: "conv4_8"
}
layer {
  name: "res4_8"
  type: "Eltwise"
  bottom: "res4_6"
  bottom: "conv4_8"
  top: "res4_8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_9"
  type: "Convolution"
  bottom: "res4_8"
  top: "conv4_9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_9"
  type: "PReLU"
  bottom: "conv4_9"
  top: "conv4_9"
}
layer {
  name: "conv4_10"
  type: "Convolution"
  bottom: "conv4_9"
  top: "conv4_10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_10"
  type: "PReLU"
  bottom: "conv4_10"
  top: "conv4_10"
}
layer {
  name: "res4_10"
  type: "Eltwise"
  bottom: "res4_8"
  bottom: "conv4_10"
  top: "res4_10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "res4_10"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "PReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "PReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "PReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "res5_2"
  type: "Eltwise"
  bottom: "pool4"
  bottom: "conv5_2"
  top: "res5_2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "res5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_3"
  type: "PReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_4"
  type: "PReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "res5_4"
  type: "Eltwise"
  bottom: "res5_2"
  bottom: "conv5_4"
  top: "res5_4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_5"
  type: "Convolution"
  bottom: "res5_4"
  top: "conv5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_5"
  type: "PReLU"
  bottom: "conv5_5"
  top: "conv5_5"
}
layer {
  name: "conv5_6"
  type: "Convolution"
  bottom: "conv5_5"
  top: "conv5_6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_6"
  type: "PReLU"
  bottom: "conv5_6"
  top: "conv5_6"
}
layer {
  name: "res5_6"
  type: "Eltwise"
  bottom: "res5_4"
  bottom: "conv5_6"
  top: "res5_6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "fc5"
  type: "InnerProduct"
  bottom: "res5_6"
  top: "fc5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
I0816 10:11:06.394942 20528 layer_factory.hpp:77] Creating layer input
I0816 10:11:06.394958 20528 net.cpp:100] Creating Layer input
I0816 10:11:06.394964 20528 net.cpp:408] input -> data
I0816 10:11:06.395022 20528 net.cpp:150] Setting up input
I0816 10:11:06.395035 20528 net.cpp:157] Top shape: 1 3 112 96 (32256)
I0816 10:11:06.395040 20528 net.cpp:165] Memory required for data: 129024
I0816 10:11:06.395045 20528 layer_factory.hpp:77] Creating layer conv1a
I0816 10:11:06.395057 20528 net.cpp:100] Creating Layer conv1a
I0816 10:11:06.395062 20528 net.cpp:434] conv1a <- data
I0816 10:11:06.395071 20528 net.cpp:408] conv1a -> conv1a
I0816 10:11:06.397298 20528 net.cpp:150] Setting up conv1a
I0816 10:11:06.397320 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:06.397325 20528 net.cpp:165] Memory required for data: 1452544
I0816 10:11:06.397339 20528 layer_factory.hpp:77] Creating layer relu1a
I0816 10:11:06.397349 20528 net.cpp:100] Creating Layer relu1a
I0816 10:11:06.397356 20528 net.cpp:434] relu1a <- conv1a
I0816 10:11:06.397362 20528 net.cpp:395] relu1a -> conv1a (in-place)
I0816 10:11:06.398535 20528 net.cpp:150] Setting up relu1a
I0816 10:11:06.398552 20528 net.cpp:157] Top shape: 1 32 110 94 (330880)
I0816 10:11:06.398558 20528 net.cpp:165] Memory required for data: 2776064
I0816 10:11:06.398569 20528 layer_factory.hpp:77] Creating layer conv1b
I0816 10:11:06.398582 20528 net.cpp:100] Creating Layer conv1b
I0816 10:11:06.398588 20528 net.cpp:434] conv1b <- conv1a
I0816 10:11:06.398596 20528 net.cpp:408] conv1b -> conv1b
I0816 10:11:06.401280 20528 net.cpp:150] Setting up conv1b
I0816 10:11:06.401302 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:06.401309 20528 net.cpp:165] Memory required for data: 5319680
I0816 10:11:06.401322 20528 layer_factory.hpp:77] Creating layer relu1b
I0816 10:11:06.401332 20528 net.cpp:100] Creating Layer relu1b
I0816 10:11:06.401337 20528 net.cpp:434] relu1b <- conv1b
I0816 10:11:06.401346 20528 net.cpp:395] relu1b -> conv1b (in-place)
I0816 10:11:06.403249 20528 net.cpp:150] Setting up relu1b
I0816 10:11:06.403266 20528 net.cpp:157] Top shape: 1 64 108 92 (635904)
I0816 10:11:06.403271 20528 net.cpp:165] Memory required for data: 7863296
I0816 10:11:06.403280 20528 layer_factory.hpp:77] Creating layer pool1b
I0816 10:11:06.403290 20528 net.cpp:100] Creating Layer pool1b
I0816 10:11:06.403295 20528 net.cpp:434] pool1b <- conv1b
I0816 10:11:06.403306 20528 net.cpp:408] pool1b -> pool1b
I0816 10:11:06.403372 20528 net.cpp:150] Setting up pool1b
I0816 10:11:06.403381 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.403386 20528 net.cpp:165] Memory required for data: 8499200
I0816 10:11:06.403393 20528 layer_factory.hpp:77] Creating layer pool1b_pool1b_0_split
I0816 10:11:06.403403 20528 net.cpp:100] Creating Layer pool1b_pool1b_0_split
I0816 10:11:06.403408 20528 net.cpp:434] pool1b_pool1b_0_split <- pool1b
I0816 10:11:06.403414 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_0
I0816 10:11:06.403429 20528 net.cpp:408] pool1b_pool1b_0_split -> pool1b_pool1b_0_split_1
I0816 10:11:06.403492 20528 net.cpp:150] Setting up pool1b_pool1b_0_split
I0816 10:11:06.403502 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.403509 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.403514 20528 net.cpp:165] Memory required for data: 9771008
I0816 10:11:06.403519 20528 layer_factory.hpp:77] Creating layer conv2_1
I0816 10:11:06.403532 20528 net.cpp:100] Creating Layer conv2_1
I0816 10:11:06.403537 20528 net.cpp:434] conv2_1 <- pool1b_pool1b_0_split_0
I0816 10:11:06.403548 20528 net.cpp:408] conv2_1 -> conv2_1
I0816 10:11:06.407079 20528 net.cpp:150] Setting up conv2_1
I0816 10:11:06.407097 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.407104 20528 net.cpp:165] Memory required for data: 10406912
I0816 10:11:06.407114 20528 layer_factory.hpp:77] Creating layer relu2_1
I0816 10:11:06.407124 20528 net.cpp:100] Creating Layer relu2_1
I0816 10:11:06.407131 20528 net.cpp:434] relu2_1 <- conv2_1
I0816 10:11:06.407138 20528 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0816 10:11:06.408087 20528 net.cpp:150] Setting up relu2_1
I0816 10:11:06.408103 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.408108 20528 net.cpp:165] Memory required for data: 11042816
I0816 10:11:06.408120 20528 layer_factory.hpp:77] Creating layer conv2_2
I0816 10:11:06.408134 20528 net.cpp:100] Creating Layer conv2_2
I0816 10:11:06.408140 20528 net.cpp:434] conv2_2 <- conv2_1
I0816 10:11:06.408149 20528 net.cpp:408] conv2_2 -> conv2_2
I0816 10:11:06.412060 20528 net.cpp:150] Setting up conv2_2
I0816 10:11:06.412078 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.412084 20528 net.cpp:165] Memory required for data: 11678720
I0816 10:11:06.412096 20528 layer_factory.hpp:77] Creating layer relu2_2
I0816 10:11:06.412104 20528 net.cpp:100] Creating Layer relu2_2
I0816 10:11:06.412111 20528 net.cpp:434] relu2_2 <- conv2_2
I0816 10:11:06.412119 20528 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0816 10:11:06.413077 20528 net.cpp:150] Setting up relu2_2
I0816 10:11:06.413094 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.413100 20528 net.cpp:165] Memory required for data: 12314624
I0816 10:11:06.413108 20528 layer_factory.hpp:77] Creating layer res2_2
I0816 10:11:06.413118 20528 net.cpp:100] Creating Layer res2_2
I0816 10:11:06.413125 20528 net.cpp:434] res2_2 <- pool1b_pool1b_0_split_1
I0816 10:11:06.413132 20528 net.cpp:434] res2_2 <- conv2_2
I0816 10:11:06.413141 20528 net.cpp:408] res2_2 -> res2_2
I0816 10:11:06.413187 20528 net.cpp:150] Setting up res2_2
I0816 10:11:06.413197 20528 net.cpp:157] Top shape: 1 64 54 46 (158976)
I0816 10:11:06.413203 20528 net.cpp:165] Memory required for data: 12950528
I0816 10:11:06.413208 20528 layer_factory.hpp:77] Creating layer conv2
I0816 10:11:06.413220 20528 net.cpp:100] Creating Layer conv2
I0816 10:11:06.413225 20528 net.cpp:434] conv2 <- res2_2
I0816 10:11:06.413234 20528 net.cpp:408] conv2 -> conv2
I0816 10:11:06.415810 20528 net.cpp:150] Setting up conv2
I0816 10:11:06.415829 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:06.415835 20528 net.cpp:165] Memory required for data: 14121984
I0816 10:11:06.415845 20528 layer_factory.hpp:77] Creating layer relu2
I0816 10:11:06.415855 20528 net.cpp:100] Creating Layer relu2
I0816 10:11:06.415861 20528 net.cpp:434] relu2 <- conv2
I0816 10:11:06.415869 20528 net.cpp:395] relu2 -> conv2 (in-place)
I0816 10:11:06.416954 20528 net.cpp:150] Setting up relu2
I0816 10:11:06.416971 20528 net.cpp:157] Top shape: 1 128 52 44 (292864)
I0816 10:11:06.416977 20528 net.cpp:165] Memory required for data: 15293440
I0816 10:11:06.416986 20528 layer_factory.hpp:77] Creating layer pool2
I0816 10:11:06.416998 20528 net.cpp:100] Creating Layer pool2
I0816 10:11:06.417003 20528 net.cpp:434] pool2 <- conv2
I0816 10:11:06.417012 20528 net.cpp:408] pool2 -> pool2
I0816 10:11:06.417076 20528 net.cpp:150] Setting up pool2
I0816 10:11:06.417093 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.417098 20528 net.cpp:165] Memory required for data: 15586304
I0816 10:11:06.417104 20528 layer_factory.hpp:77] Creating layer pool2_pool2_0_split
I0816 10:11:06.417112 20528 net.cpp:100] Creating Layer pool2_pool2_0_split
I0816 10:11:06.417119 20528 net.cpp:434] pool2_pool2_0_split <- pool2
I0816 10:11:06.417125 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_0
I0816 10:11:06.417135 20528 net.cpp:408] pool2_pool2_0_split -> pool2_pool2_0_split_1
I0816 10:11:06.417191 20528 net.cpp:150] Setting up pool2_pool2_0_split
I0816 10:11:06.417198 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.417206 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.417209 20528 net.cpp:165] Memory required for data: 16172032
I0816 10:11:06.417215 20528 layer_factory.hpp:77] Creating layer conv3_1
I0816 10:11:06.417229 20528 net.cpp:100] Creating Layer conv3_1
I0816 10:11:06.417234 20528 net.cpp:434] conv3_1 <- pool2_pool2_0_split_0
I0816 10:11:06.417244 20528 net.cpp:408] conv3_1 -> conv3_1
I0816 10:11:06.428119 20528 net.cpp:150] Setting up conv3_1
I0816 10:11:06.428143 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.428148 20528 net.cpp:165] Memory required for data: 16464896
I0816 10:11:06.428167 20528 layer_factory.hpp:77] Creating layer relu3_1
I0816 10:11:06.428177 20528 net.cpp:100] Creating Layer relu3_1
I0816 10:11:06.428184 20528 net.cpp:434] relu3_1 <- conv3_1
I0816 10:11:06.428191 20528 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0816 10:11:06.428382 20528 net.cpp:150] Setting up relu3_1
I0816 10:11:06.428392 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.428397 20528 net.cpp:165] Memory required for data: 16757760
I0816 10:11:06.428406 20528 layer_factory.hpp:77] Creating layer conv3_2
I0816 10:11:06.428419 20528 net.cpp:100] Creating Layer conv3_2
I0816 10:11:06.428426 20528 net.cpp:434] conv3_2 <- conv3_1
I0816 10:11:06.428436 20528 net.cpp:408] conv3_2 -> conv3_2
I0816 10:11:06.437525 20528 net.cpp:150] Setting up conv3_2
I0816 10:11:06.437548 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.437556 20528 net.cpp:165] Memory required for data: 17050624
I0816 10:11:06.437566 20528 layer_factory.hpp:77] Creating layer relu3_2
I0816 10:11:06.437575 20528 net.cpp:100] Creating Layer relu3_2
I0816 10:11:06.437582 20528 net.cpp:434] relu3_2 <- conv3_2
I0816 10:11:06.437589 20528 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0816 10:11:06.437786 20528 net.cpp:150] Setting up relu3_2
I0816 10:11:06.437799 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.437804 20528 net.cpp:165] Memory required for data: 17343488
I0816 10:11:06.437811 20528 layer_factory.hpp:77] Creating layer res3_2
I0816 10:11:06.437821 20528 net.cpp:100] Creating Layer res3_2
I0816 10:11:06.437827 20528 net.cpp:434] res3_2 <- pool2_pool2_0_split_1
I0816 10:11:06.437834 20528 net.cpp:434] res3_2 <- conv3_2
I0816 10:11:06.437844 20528 net.cpp:408] res3_2 -> res3_2
I0816 10:11:06.437885 20528 net.cpp:150] Setting up res3_2
I0816 10:11:06.437894 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.437899 20528 net.cpp:165] Memory required for data: 17636352
I0816 10:11:06.437906 20528 layer_factory.hpp:77] Creating layer res3_2_res3_2_0_split
I0816 10:11:06.437917 20528 net.cpp:100] Creating Layer res3_2_res3_2_0_split
I0816 10:11:06.437923 20528 net.cpp:434] res3_2_res3_2_0_split <- res3_2
I0816 10:11:06.437929 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_0
I0816 10:11:06.437943 20528 net.cpp:408] res3_2_res3_2_0_split -> res3_2_res3_2_0_split_1
I0816 10:11:06.438000 20528 net.cpp:150] Setting up res3_2_res3_2_0_split
I0816 10:11:06.438016 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.438024 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.438029 20528 net.cpp:165] Memory required for data: 18222080
I0816 10:11:06.438033 20528 layer_factory.hpp:77] Creating layer conv3_3
I0816 10:11:06.438047 20528 net.cpp:100] Creating Layer conv3_3
I0816 10:11:06.438062 20528 net.cpp:434] conv3_3 <- res3_2_res3_2_0_split_0
I0816 10:11:06.438071 20528 net.cpp:408] conv3_3 -> conv3_3
I0816 10:11:06.447568 20528 net.cpp:150] Setting up conv3_3
I0816 10:11:06.447592 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.447599 20528 net.cpp:165] Memory required for data: 18514944
I0816 10:11:06.447613 20528 layer_factory.hpp:77] Creating layer relu3_3
I0816 10:11:06.447625 20528 net.cpp:100] Creating Layer relu3_3
I0816 10:11:06.447631 20528 net.cpp:434] relu3_3 <- conv3_3
I0816 10:11:06.447644 20528 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0816 10:11:06.447911 20528 net.cpp:150] Setting up relu3_3
I0816 10:11:06.447927 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.447935 20528 net.cpp:165] Memory required for data: 18807808
I0816 10:11:06.447945 20528 layer_factory.hpp:77] Creating layer conv3_4
I0816 10:11:06.447963 20528 net.cpp:100] Creating Layer conv3_4
I0816 10:11:06.447973 20528 net.cpp:434] conv3_4 <- conv3_3
I0816 10:11:06.447983 20528 net.cpp:408] conv3_4 -> conv3_4
I0816 10:11:06.458833 20528 net.cpp:150] Setting up conv3_4
I0816 10:11:06.458865 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.458873 20528 net.cpp:165] Memory required for data: 19100672
I0816 10:11:06.458884 20528 layer_factory.hpp:77] Creating layer relu3_4
I0816 10:11:06.458894 20528 net.cpp:100] Creating Layer relu3_4
I0816 10:11:06.458899 20528 net.cpp:434] relu3_4 <- conv3_4
I0816 10:11:06.458914 20528 net.cpp:395] relu3_4 -> conv3_4 (in-place)
I0816 10:11:06.459116 20528 net.cpp:150] Setting up relu3_4
I0816 10:11:06.459131 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.459136 20528 net.cpp:165] Memory required for data: 19393536
I0816 10:11:06.459143 20528 layer_factory.hpp:77] Creating layer res3_4
I0816 10:11:06.459152 20528 net.cpp:100] Creating Layer res3_4
I0816 10:11:06.459159 20528 net.cpp:434] res3_4 <- res3_2_res3_2_0_split_1
I0816 10:11:06.459168 20528 net.cpp:434] res3_4 <- conv3_4
I0816 10:11:06.459177 20528 net.cpp:408] res3_4 -> res3_4
I0816 10:11:06.459228 20528 net.cpp:150] Setting up res3_4
I0816 10:11:06.459239 20528 net.cpp:157] Top shape: 1 128 26 22 (73216)
I0816 10:11:06.459246 20528 net.cpp:165] Memory required for data: 19686400
I0816 10:11:06.459254 20528 layer_factory.hpp:77] Creating layer conv3
I0816 10:11:06.459266 20528 net.cpp:100] Creating Layer conv3
I0816 10:11:06.459273 20528 net.cpp:434] conv3 <- res3_4
I0816 10:11:06.459283 20528 net.cpp:408] conv3 -> conv3
I0816 10:11:06.464917 20528 net.cpp:150] Setting up conv3
I0816 10:11:06.464946 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:06.464957 20528 net.cpp:165] Memory required for data: 20177920
I0816 10:11:06.464973 20528 layer_factory.hpp:77] Creating layer relu3
I0816 10:11:06.464993 20528 net.cpp:100] Creating Layer relu3
I0816 10:11:06.465003 20528 net.cpp:434] relu3 <- conv3
I0816 10:11:06.465016 20528 net.cpp:395] relu3 -> conv3 (in-place)
I0816 10:11:06.466294 20528 net.cpp:150] Setting up relu3
I0816 10:11:06.466327 20528 net.cpp:157] Top shape: 1 256 24 20 (122880)
I0816 10:11:06.466337 20528 net.cpp:165] Memory required for data: 20669440
I0816 10:11:06.466351 20528 layer_factory.hpp:77] Creating layer pool3
I0816 10:11:06.466367 20528 net.cpp:100] Creating Layer pool3
I0816 10:11:06.466377 20528 net.cpp:434] pool3 <- conv3
I0816 10:11:06.466390 20528 net.cpp:408] pool3 -> pool3
I0816 10:11:06.466501 20528 net.cpp:150] Setting up pool3
I0816 10:11:06.466517 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.466523 20528 net.cpp:165] Memory required for data: 20792320
I0816 10:11:06.466528 20528 layer_factory.hpp:77] Creating layer pool3_pool3_0_split
I0816 10:11:06.466537 20528 net.cpp:100] Creating Layer pool3_pool3_0_split
I0816 10:11:06.466543 20528 net.cpp:434] pool3_pool3_0_split <- pool3
I0816 10:11:06.466553 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_0
I0816 10:11:06.466562 20528 net.cpp:408] pool3_pool3_0_split -> pool3_pool3_0_split_1
I0816 10:11:06.466645 20528 net.cpp:150] Setting up pool3_pool3_0_split
I0816 10:11:06.466658 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.466665 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.466670 20528 net.cpp:165] Memory required for data: 21038080
I0816 10:11:06.466676 20528 layer_factory.hpp:77] Creating layer conv4_1
I0816 10:11:06.466694 20528 net.cpp:100] Creating Layer conv4_1
I0816 10:11:06.466701 20528 net.cpp:434] conv4_1 <- pool3_pool3_0_split_0
I0816 10:11:06.466709 20528 net.cpp:408] conv4_1 -> conv4_1
I0816 10:11:06.497392 20528 net.cpp:150] Setting up conv4_1
I0816 10:11:06.497416 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.497422 20528 net.cpp:165] Memory required for data: 21160960
I0816 10:11:06.497432 20528 layer_factory.hpp:77] Creating layer relu4_1
I0816 10:11:06.497449 20528 net.cpp:100] Creating Layer relu4_1
I0816 10:11:06.497457 20528 net.cpp:434] relu4_1 <- conv4_1
I0816 10:11:06.497465 20528 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0816 10:11:06.497668 20528 net.cpp:150] Setting up relu4_1
I0816 10:11:06.497679 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.497685 20528 net.cpp:165] Memory required for data: 21283840
I0816 10:11:06.499383 20528 layer_factory.hpp:77] Creating layer conv4_2
I0816 10:11:06.499408 20528 net.cpp:100] Creating Layer conv4_2
I0816 10:11:06.499414 20528 net.cpp:434] conv4_2 <- conv4_1
I0816 10:11:06.499423 20528 net.cpp:408] conv4_2 -> conv4_2
I0816 10:11:06.534333 20528 net.cpp:150] Setting up conv4_2
I0816 10:11:06.534386 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.534394 20528 net.cpp:165] Memory required for data: 21406720
I0816 10:11:06.534409 20528 layer_factory.hpp:77] Creating layer relu4_2
I0816 10:11:06.534425 20528 net.cpp:100] Creating Layer relu4_2
I0816 10:11:06.534433 20528 net.cpp:434] relu4_2 <- conv4_2
I0816 10:11:06.534447 20528 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0816 10:11:06.534662 20528 net.cpp:150] Setting up relu4_2
I0816 10:11:06.534672 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.534678 20528 net.cpp:165] Memory required for data: 21529600
I0816 10:11:06.534687 20528 layer_factory.hpp:77] Creating layer res4_2
I0816 10:11:06.534699 20528 net.cpp:100] Creating Layer res4_2
I0816 10:11:06.534706 20528 net.cpp:434] res4_2 <- pool3_pool3_0_split_1
I0816 10:11:06.534713 20528 net.cpp:434] res4_2 <- conv4_2
I0816 10:11:06.534723 20528 net.cpp:408] res4_2 -> res4_2
I0816 10:11:06.534782 20528 net.cpp:150] Setting up res4_2
I0816 10:11:06.534793 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.534799 20528 net.cpp:165] Memory required for data: 21652480
I0816 10:11:06.534804 20528 layer_factory.hpp:77] Creating layer res4_2_res4_2_0_split
I0816 10:11:06.534814 20528 net.cpp:100] Creating Layer res4_2_res4_2_0_split
I0816 10:11:06.534821 20528 net.cpp:434] res4_2_res4_2_0_split <- res4_2
I0816 10:11:06.534829 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_0
I0816 10:11:06.534838 20528 net.cpp:408] res4_2_res4_2_0_split -> res4_2_res4_2_0_split_1
I0816 10:11:06.534899 20528 net.cpp:150] Setting up res4_2_res4_2_0_split
I0816 10:11:06.534910 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.534917 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.534922 20528 net.cpp:165] Memory required for data: 21898240
I0816 10:11:06.534927 20528 layer_factory.hpp:77] Creating layer conv4_3
I0816 10:11:06.534945 20528 net.cpp:100] Creating Layer conv4_3
I0816 10:11:06.534951 20528 net.cpp:434] conv4_3 <- res4_2_res4_2_0_split_0
I0816 10:11:06.534960 20528 net.cpp:408] conv4_3 -> conv4_3
I0816 10:11:06.564224 20528 net.cpp:150] Setting up conv4_3
I0816 10:11:06.564276 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.564283 20528 net.cpp:165] Memory required for data: 22021120
I0816 10:11:06.564301 20528 layer_factory.hpp:77] Creating layer relu4_3
I0816 10:11:06.564321 20528 net.cpp:100] Creating Layer relu4_3
I0816 10:11:06.564329 20528 net.cpp:434] relu4_3 <- conv4_3
I0816 10:11:06.564358 20528 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0816 10:11:06.564584 20528 net.cpp:150] Setting up relu4_3
I0816 10:11:06.564594 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.564600 20528 net.cpp:165] Memory required for data: 22144000
I0816 10:11:06.564609 20528 layer_factory.hpp:77] Creating layer conv4_4
I0816 10:11:06.564627 20528 net.cpp:100] Creating Layer conv4_4
I0816 10:11:06.564635 20528 net.cpp:434] conv4_4 <- conv4_3
I0816 10:11:06.564643 20528 net.cpp:408] conv4_4 -> conv4_4
I0816 10:11:06.591104 20528 net.cpp:150] Setting up conv4_4
I0816 10:11:06.591143 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.591150 20528 net.cpp:165] Memory required for data: 22266880
I0816 10:11:06.591166 20528 layer_factory.hpp:77] Creating layer relu4_4
I0816 10:11:06.591182 20528 net.cpp:100] Creating Layer relu4_4
I0816 10:11:06.591192 20528 net.cpp:434] relu4_4 <- conv4_4
I0816 10:11:06.591204 20528 net.cpp:395] relu4_4 -> conv4_4 (in-place)
I0816 10:11:06.591454 20528 net.cpp:150] Setting up relu4_4
I0816 10:11:06.591467 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.591473 20528 net.cpp:165] Memory required for data: 22389760
I0816 10:11:06.591481 20528 layer_factory.hpp:77] Creating layer res4_4
I0816 10:11:06.591493 20528 net.cpp:100] Creating Layer res4_4
I0816 10:11:06.591500 20528 net.cpp:434] res4_4 <- res4_2_res4_2_0_split_1
I0816 10:11:06.591507 20528 net.cpp:434] res4_4 <- conv4_4
I0816 10:11:06.591516 20528 net.cpp:408] res4_4 -> res4_4
I0816 10:11:06.591572 20528 net.cpp:150] Setting up res4_4
I0816 10:11:06.591584 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.591589 20528 net.cpp:165] Memory required for data: 22512640
I0816 10:11:06.591595 20528 layer_factory.hpp:77] Creating layer res4_4_res4_4_0_split
I0816 10:11:06.591605 20528 net.cpp:100] Creating Layer res4_4_res4_4_0_split
I0816 10:11:06.591611 20528 net.cpp:434] res4_4_res4_4_0_split <- res4_4
I0816 10:11:06.591619 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_0
I0816 10:11:06.591627 20528 net.cpp:408] res4_4_res4_4_0_split -> res4_4_res4_4_0_split_1
I0816 10:11:06.591687 20528 net.cpp:150] Setting up res4_4_res4_4_0_split
I0816 10:11:06.591696 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.591703 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.591707 20528 net.cpp:165] Memory required for data: 22758400
I0816 10:11:06.591713 20528 layer_factory.hpp:77] Creating layer conv4_5
I0816 10:11:06.591737 20528 net.cpp:100] Creating Layer conv4_5
I0816 10:11:06.591744 20528 net.cpp:434] conv4_5 <- res4_4_res4_4_0_split_0
I0816 10:11:06.591754 20528 net.cpp:408] conv4_5 -> conv4_5
I0816 10:11:06.623764 20528 net.cpp:150] Setting up conv4_5
I0816 10:11:06.623816 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.623824 20528 net.cpp:165] Memory required for data: 22881280
I0816 10:11:06.623842 20528 layer_factory.hpp:77] Creating layer relu4_5
I0816 10:11:06.623858 20528 net.cpp:100] Creating Layer relu4_5
I0816 10:11:06.623867 20528 net.cpp:434] relu4_5 <- conv4_5
I0816 10:11:06.623878 20528 net.cpp:395] relu4_5 -> conv4_5 (in-place)
I0816 10:11:06.624930 20528 net.cpp:150] Setting up relu4_5
I0816 10:11:06.624949 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.624955 20528 net.cpp:165] Memory required for data: 23004160
I0816 10:11:06.624964 20528 layer_factory.hpp:77] Creating layer conv4_6
I0816 10:11:06.624982 20528 net.cpp:100] Creating Layer conv4_6
I0816 10:11:06.624989 20528 net.cpp:434] conv4_6 <- conv4_5
I0816 10:11:06.625000 20528 net.cpp:408] conv4_6 -> conv4_6
I0816 10:11:06.651698 20528 net.cpp:150] Setting up conv4_6
I0816 10:11:06.651757 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.651767 20528 net.cpp:165] Memory required for data: 23127040
I0816 10:11:06.651785 20528 layer_factory.hpp:77] Creating layer relu4_6
I0816 10:11:06.651804 20528 net.cpp:100] Creating Layer relu4_6
I0816 10:11:06.651816 20528 net.cpp:434] relu4_6 <- conv4_6
I0816 10:11:06.651849 20528 net.cpp:395] relu4_6 -> conv4_6 (in-place)
I0816 10:11:06.652084 20528 net.cpp:150] Setting up relu4_6
I0816 10:11:06.652096 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.652102 20528 net.cpp:165] Memory required for data: 23249920
I0816 10:11:06.652110 20528 layer_factory.hpp:77] Creating layer res4_6
I0816 10:11:06.652122 20528 net.cpp:100] Creating Layer res4_6
I0816 10:11:06.652129 20528 net.cpp:434] res4_6 <- res4_4_res4_4_0_split_1
I0816 10:11:06.652137 20528 net.cpp:434] res4_6 <- conv4_6
I0816 10:11:06.652146 20528 net.cpp:408] res4_6 -> res4_6
I0816 10:11:06.652194 20528 net.cpp:150] Setting up res4_6
I0816 10:11:06.652204 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.652209 20528 net.cpp:165] Memory required for data: 23372800
I0816 10:11:06.652215 20528 layer_factory.hpp:77] Creating layer res4_6_res4_6_0_split
I0816 10:11:06.652225 20528 net.cpp:100] Creating Layer res4_6_res4_6_0_split
I0816 10:11:06.652231 20528 net.cpp:434] res4_6_res4_6_0_split <- res4_6
I0816 10:11:06.652240 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_0
I0816 10:11:06.652248 20528 net.cpp:408] res4_6_res4_6_0_split -> res4_6_res4_6_0_split_1
I0816 10:11:06.652309 20528 net.cpp:150] Setting up res4_6_res4_6_0_split
I0816 10:11:06.652318 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.652325 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.652329 20528 net.cpp:165] Memory required for data: 23618560
I0816 10:11:06.652335 20528 layer_factory.hpp:77] Creating layer conv4_7
I0816 10:11:06.652351 20528 net.cpp:100] Creating Layer conv4_7
I0816 10:11:06.652357 20528 net.cpp:434] conv4_7 <- res4_6_res4_6_0_split_0
I0816 10:11:06.652367 20528 net.cpp:408] conv4_7 -> conv4_7
I0816 10:11:06.684224 20528 net.cpp:150] Setting up conv4_7
I0816 10:11:06.684284 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.684294 20528 net.cpp:165] Memory required for data: 23741440
I0816 10:11:06.684316 20528 layer_factory.hpp:77] Creating layer relu4_7
I0816 10:11:06.684336 20528 net.cpp:100] Creating Layer relu4_7
I0816 10:11:06.684348 20528 net.cpp:434] relu4_7 <- conv4_7
I0816 10:11:06.684365 20528 net.cpp:395] relu4_7 -> conv4_7 (in-place)
I0816 10:11:06.684643 20528 net.cpp:150] Setting up relu4_7
I0816 10:11:06.684659 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.684666 20528 net.cpp:165] Memory required for data: 23864320
I0816 10:11:06.684679 20528 layer_factory.hpp:77] Creating layer conv4_8
I0816 10:11:06.684701 20528 net.cpp:100] Creating Layer conv4_8
I0816 10:11:06.684710 20528 net.cpp:434] conv4_8 <- conv4_7
I0816 10:11:06.684723 20528 net.cpp:408] conv4_8 -> conv4_8
I0816 10:11:06.710156 20528 net.cpp:150] Setting up conv4_8
I0816 10:11:06.710203 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.710209 20528 net.cpp:165] Memory required for data: 23987200
I0816 10:11:06.710225 20528 layer_factory.hpp:77] Creating layer relu4_8
I0816 10:11:06.710242 20528 net.cpp:100] Creating Layer relu4_8
I0816 10:11:06.710250 20528 net.cpp:434] relu4_8 <- conv4_8
I0816 10:11:06.710260 20528 net.cpp:395] relu4_8 -> conv4_8 (in-place)
I0816 10:11:06.710460 20528 net.cpp:150] Setting up relu4_8
I0816 10:11:06.710470 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.710476 20528 net.cpp:165] Memory required for data: 24110080
I0816 10:11:06.710484 20528 layer_factory.hpp:77] Creating layer res4_8
I0816 10:11:06.710496 20528 net.cpp:100] Creating Layer res4_8
I0816 10:11:06.710503 20528 net.cpp:434] res4_8 <- res4_6_res4_6_0_split_1
I0816 10:11:06.710510 20528 net.cpp:434] res4_8 <- conv4_8
I0816 10:11:06.710520 20528 net.cpp:408] res4_8 -> res4_8
I0816 10:11:06.710566 20528 net.cpp:150] Setting up res4_8
I0816 10:11:06.710575 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.710580 20528 net.cpp:165] Memory required for data: 24232960
I0816 10:11:06.710585 20528 layer_factory.hpp:77] Creating layer res4_8_res4_8_0_split
I0816 10:11:06.710595 20528 net.cpp:100] Creating Layer res4_8_res4_8_0_split
I0816 10:11:06.710613 20528 net.cpp:434] res4_8_res4_8_0_split <- res4_8
I0816 10:11:06.710623 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_0
I0816 10:11:06.710630 20528 net.cpp:408] res4_8_res4_8_0_split -> res4_8_res4_8_0_split_1
I0816 10:11:06.710692 20528 net.cpp:150] Setting up res4_8_res4_8_0_split
I0816 10:11:06.710701 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.710707 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.710712 20528 net.cpp:165] Memory required for data: 24478720
I0816 10:11:06.710717 20528 layer_factory.hpp:77] Creating layer conv4_9
I0816 10:11:06.710741 20528 net.cpp:100] Creating Layer conv4_9
I0816 10:11:06.710748 20528 net.cpp:434] conv4_9 <- res4_8_res4_8_0_split_0
I0816 10:11:06.710757 20528 net.cpp:408] conv4_9 -> conv4_9
I0816 10:11:06.736660 20528 net.cpp:150] Setting up conv4_9
I0816 10:11:06.736707 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.736713 20528 net.cpp:165] Memory required for data: 24601600
I0816 10:11:06.736737 20528 layer_factory.hpp:77] Creating layer relu4_9
I0816 10:11:06.736752 20528 net.cpp:100] Creating Layer relu4_9
I0816 10:11:06.736762 20528 net.cpp:434] relu4_9 <- conv4_9
I0816 10:11:06.736771 20528 net.cpp:395] relu4_9 -> conv4_9 (in-place)
I0816 10:11:06.736974 20528 net.cpp:150] Setting up relu4_9
I0816 10:11:06.736984 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.736989 20528 net.cpp:165] Memory required for data: 24724480
I0816 10:11:06.736997 20528 layer_factory.hpp:77] Creating layer conv4_10
I0816 10:11:06.737013 20528 net.cpp:100] Creating Layer conv4_10
I0816 10:11:06.737020 20528 net.cpp:434] conv4_10 <- conv4_9
I0816 10:11:06.737028 20528 net.cpp:408] conv4_10 -> conv4_10
I0816 10:11:06.763032 20528 net.cpp:150] Setting up conv4_10
I0816 10:11:06.763074 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.763082 20528 net.cpp:165] Memory required for data: 24847360
I0816 10:11:06.763098 20528 layer_factory.hpp:77] Creating layer relu4_10
I0816 10:11:06.763113 20528 net.cpp:100] Creating Layer relu4_10
I0816 10:11:06.763123 20528 net.cpp:434] relu4_10 <- conv4_10
I0816 10:11:06.763134 20528 net.cpp:395] relu4_10 -> conv4_10 (in-place)
I0816 10:11:06.763339 20528 net.cpp:150] Setting up relu4_10
I0816 10:11:06.763350 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.763355 20528 net.cpp:165] Memory required for data: 24970240
I0816 10:11:06.763363 20528 layer_factory.hpp:77] Creating layer res4_10
I0816 10:11:06.763375 20528 net.cpp:100] Creating Layer res4_10
I0816 10:11:06.763382 20528 net.cpp:434] res4_10 <- res4_8_res4_8_0_split_1
I0816 10:11:06.763389 20528 net.cpp:434] res4_10 <- conv4_10
I0816 10:11:06.763398 20528 net.cpp:408] res4_10 -> res4_10
I0816 10:11:06.763447 20528 net.cpp:150] Setting up res4_10
I0816 10:11:06.763455 20528 net.cpp:157] Top shape: 1 256 12 10 (30720)
I0816 10:11:06.763460 20528 net.cpp:165] Memory required for data: 25093120
I0816 10:11:06.763466 20528 layer_factory.hpp:77] Creating layer conv4
I0816 10:11:06.763484 20528 net.cpp:100] Creating Layer conv4
I0816 10:11:06.763489 20528 net.cpp:434] conv4 <- res4_10
I0816 10:11:06.763497 20528 net.cpp:408] conv4 -> conv4
I0816 10:11:06.776264 20528 net.cpp:150] Setting up conv4
I0816 10:11:06.776314 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:06.776319 20528 net.cpp:165] Memory required for data: 25256960
I0816 10:11:06.776335 20528 layer_factory.hpp:77] Creating layer relu4
I0816 10:11:06.776350 20528 net.cpp:100] Creating Layer relu4
I0816 10:11:06.776358 20528 net.cpp:434] relu4 <- conv4
I0816 10:11:06.776368 20528 net.cpp:395] relu4 -> conv4 (in-place)
I0816 10:11:06.776619 20528 net.cpp:150] Setting up relu4
I0816 10:11:06.776631 20528 net.cpp:157] Top shape: 1 512 10 8 (40960)
I0816 10:11:06.776638 20528 net.cpp:165] Memory required for data: 25420800
I0816 10:11:06.776645 20528 layer_factory.hpp:77] Creating layer pool4
I0816 10:11:06.776656 20528 net.cpp:100] Creating Layer pool4
I0816 10:11:06.776662 20528 net.cpp:434] pool4 <- conv4
I0816 10:11:06.776684 20528 net.cpp:408] pool4 -> pool4
I0816 10:11:06.776767 20528 net.cpp:150] Setting up pool4
I0816 10:11:06.776779 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.776785 20528 net.cpp:165] Memory required for data: 25461760
I0816 10:11:06.776790 20528 layer_factory.hpp:77] Creating layer pool4_pool4_0_split
I0816 10:11:06.776800 20528 net.cpp:100] Creating Layer pool4_pool4_0_split
I0816 10:11:06.776806 20528 net.cpp:434] pool4_pool4_0_split <- pool4
I0816 10:11:06.776814 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_0
I0816 10:11:06.776823 20528 net.cpp:408] pool4_pool4_0_split -> pool4_pool4_0_split_1
I0816 10:11:06.776885 20528 net.cpp:150] Setting up pool4_pool4_0_split
I0816 10:11:06.776895 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.776901 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.776906 20528 net.cpp:165] Memory required for data: 25543680
I0816 10:11:06.776911 20528 layer_factory.hpp:77] Creating layer conv5_1
I0816 10:11:06.776938 20528 net.cpp:100] Creating Layer conv5_1
I0816 10:11:06.776944 20528 net.cpp:434] conv5_1 <- pool4_pool4_0_split_0
I0816 10:11:06.776955 20528 net.cpp:408] conv5_1 -> conv5_1
I0816 10:11:06.871438 20528 net.cpp:150] Setting up conv5_1
I0816 10:11:06.871486 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.871492 20528 net.cpp:165] Memory required for data: 25584640
I0816 10:11:06.871526 20528 layer_factory.hpp:77] Creating layer relu5_1
I0816 10:11:06.871542 20528 net.cpp:100] Creating Layer relu5_1
I0816 10:11:06.871551 20528 net.cpp:434] relu5_1 <- conv5_1
I0816 10:11:06.871573 20528 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0816 10:11:06.871836 20528 net.cpp:150] Setting up relu5_1
I0816 10:11:06.871848 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.871853 20528 net.cpp:165] Memory required for data: 25625600
I0816 10:11:06.871862 20528 layer_factory.hpp:77] Creating layer conv5_2
I0816 10:11:06.871879 20528 net.cpp:100] Creating Layer conv5_2
I0816 10:11:06.871886 20528 net.cpp:434] conv5_2 <- conv5_1
I0816 10:11:06.871896 20528 net.cpp:408] conv5_2 -> conv5_2
I0816 10:11:06.966403 20528 net.cpp:150] Setting up conv5_2
I0816 10:11:06.966457 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.966464 20528 net.cpp:165] Memory required for data: 25666560
I0816 10:11:06.966478 20528 layer_factory.hpp:77] Creating layer relu5_2
I0816 10:11:06.966495 20528 net.cpp:100] Creating Layer relu5_2
I0816 10:11:06.966503 20528 net.cpp:434] relu5_2 <- conv5_2
I0816 10:11:06.966514 20528 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0816 10:11:06.967447 20528 net.cpp:150] Setting up relu5_2
I0816 10:11:06.967459 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.967465 20528 net.cpp:165] Memory required for data: 25707520
I0816 10:11:06.967473 20528 layer_factory.hpp:77] Creating layer res5_2
I0816 10:11:06.967484 20528 net.cpp:100] Creating Layer res5_2
I0816 10:11:06.967492 20528 net.cpp:434] res5_2 <- pool4_pool4_0_split_1
I0816 10:11:06.967499 20528 net.cpp:434] res5_2 <- conv5_2
I0816 10:11:06.967509 20528 net.cpp:408] res5_2 -> res5_2
I0816 10:11:06.967556 20528 net.cpp:150] Setting up res5_2
I0816 10:11:06.967566 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.967571 20528 net.cpp:165] Memory required for data: 25748480
I0816 10:11:06.967576 20528 layer_factory.hpp:77] Creating layer res5_2_res5_2_0_split
I0816 10:11:06.967586 20528 net.cpp:100] Creating Layer res5_2_res5_2_0_split
I0816 10:11:06.967592 20528 net.cpp:434] res5_2_res5_2_0_split <- res5_2
I0816 10:11:06.967599 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_0
I0816 10:11:06.967607 20528 net.cpp:408] res5_2_res5_2_0_split -> res5_2_res5_2_0_split_1
I0816 10:11:06.967669 20528 net.cpp:150] Setting up res5_2_res5_2_0_split
I0816 10:11:06.967677 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.967684 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:06.967689 20528 net.cpp:165] Memory required for data: 25830400
I0816 10:11:06.967705 20528 layer_factory.hpp:77] Creating layer conv5_3
I0816 10:11:06.967722 20528 net.cpp:100] Creating Layer conv5_3
I0816 10:11:06.967736 20528 net.cpp:434] conv5_3 <- res5_2_res5_2_0_split_0
I0816 10:11:06.967746 20528 net.cpp:408] conv5_3 -> conv5_3
I0816 10:11:07.063205 20528 net.cpp:150] Setting up conv5_3
I0816 10:11:07.063246 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.063253 20528 net.cpp:165] Memory required for data: 25871360
I0816 10:11:07.063269 20528 layer_factory.hpp:77] Creating layer relu5_3
I0816 10:11:07.063287 20528 net.cpp:100] Creating Layer relu5_3
I0816 10:11:07.063297 20528 net.cpp:434] relu5_3 <- conv5_3
I0816 10:11:07.063308 20528 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0816 10:11:07.063582 20528 net.cpp:150] Setting up relu5_3
I0816 10:11:07.063593 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.063598 20528 net.cpp:165] Memory required for data: 25912320
I0816 10:11:07.063607 20528 layer_factory.hpp:77] Creating layer conv5_4
I0816 10:11:07.063624 20528 net.cpp:100] Creating Layer conv5_4
I0816 10:11:07.063632 20528 net.cpp:434] conv5_4 <- conv5_3
I0816 10:11:07.063640 20528 net.cpp:408] conv5_4 -> conv5_4
I0816 10:11:07.158725 20528 net.cpp:150] Setting up conv5_4
I0816 10:11:07.158779 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.158785 20528 net.cpp:165] Memory required for data: 25953280
I0816 10:11:07.158800 20528 layer_factory.hpp:77] Creating layer relu5_4
I0816 10:11:07.158818 20528 net.cpp:100] Creating Layer relu5_4
I0816 10:11:07.158826 20528 net.cpp:434] relu5_4 <- conv5_4
I0816 10:11:07.158838 20528 net.cpp:395] relu5_4 -> conv5_4 (in-place)
I0816 10:11:07.159072 20528 net.cpp:150] Setting up relu5_4
I0816 10:11:07.159085 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.159090 20528 net.cpp:165] Memory required for data: 25994240
I0816 10:11:07.159098 20528 layer_factory.hpp:77] Creating layer res5_4
I0816 10:11:07.159109 20528 net.cpp:100] Creating Layer res5_4
I0816 10:11:07.159116 20528 net.cpp:434] res5_4 <- res5_2_res5_2_0_split_1
I0816 10:11:07.159123 20528 net.cpp:434] res5_4 <- conv5_4
I0816 10:11:07.159132 20528 net.cpp:408] res5_4 -> res5_4
I0816 10:11:07.159180 20528 net.cpp:150] Setting up res5_4
I0816 10:11:07.159189 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.159194 20528 net.cpp:165] Memory required for data: 26035200
I0816 10:11:07.159199 20528 layer_factory.hpp:77] Creating layer res5_4_res5_4_0_split
I0816 10:11:07.159209 20528 net.cpp:100] Creating Layer res5_4_res5_4_0_split
I0816 10:11:07.159215 20528 net.cpp:434] res5_4_res5_4_0_split <- res5_4
I0816 10:11:07.159224 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_0
I0816 10:11:07.159231 20528 net.cpp:408] res5_4_res5_4_0_split -> res5_4_res5_4_0_split_1
I0816 10:11:07.159294 20528 net.cpp:150] Setting up res5_4_res5_4_0_split
I0816 10:11:07.159303 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.159309 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.159314 20528 net.cpp:165] Memory required for data: 26117120
I0816 10:11:07.159319 20528 layer_factory.hpp:77] Creating layer conv5_5
I0816 10:11:07.159335 20528 net.cpp:100] Creating Layer conv5_5
I0816 10:11:07.159342 20528 net.cpp:434] conv5_5 <- res5_4_res5_4_0_split_0
I0816 10:11:07.159350 20528 net.cpp:408] conv5_5 -> conv5_5
I0816 10:11:07.255481 20528 net.cpp:150] Setting up conv5_5
I0816 10:11:07.255519 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.255527 20528 net.cpp:165] Memory required for data: 26158080
I0816 10:11:07.255543 20528 layer_factory.hpp:77] Creating layer relu5_5
I0816 10:11:07.255560 20528 net.cpp:100] Creating Layer relu5_5
I0816 10:11:07.255569 20528 net.cpp:434] relu5_5 <- conv5_5
I0816 10:11:07.255580 20528 net.cpp:395] relu5_5 -> conv5_5 (in-place)
I0816 10:11:07.255851 20528 net.cpp:150] Setting up relu5_5
I0816 10:11:07.255866 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.255870 20528 net.cpp:165] Memory required for data: 26199040
I0816 10:11:07.255887 20528 layer_factory.hpp:77] Creating layer conv5_6
I0816 10:11:07.255904 20528 net.cpp:100] Creating Layer conv5_6
I0816 10:11:07.255911 20528 net.cpp:434] conv5_6 <- conv5_5
I0816 10:11:07.255920 20528 net.cpp:408] conv5_6 -> conv5_6
I0816 10:11:07.350757 20528 net.cpp:150] Setting up conv5_6
I0816 10:11:07.350795 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.350800 20528 net.cpp:165] Memory required for data: 26240000
I0816 10:11:07.350816 20528 layer_factory.hpp:77] Creating layer relu5_6
I0816 10:11:07.350831 20528 net.cpp:100] Creating Layer relu5_6
I0816 10:11:07.350841 20528 net.cpp:434] relu5_6 <- conv5_6
I0816 10:11:07.350852 20528 net.cpp:395] relu5_6 -> conv5_6 (in-place)
I0816 10:11:07.351085 20528 net.cpp:150] Setting up relu5_6
I0816 10:11:07.351096 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.351102 20528 net.cpp:165] Memory required for data: 26280960
I0816 10:11:07.351110 20528 layer_factory.hpp:77] Creating layer res5_6
I0816 10:11:07.351122 20528 net.cpp:100] Creating Layer res5_6
I0816 10:11:07.351130 20528 net.cpp:434] res5_6 <- res5_4_res5_4_0_split_1
I0816 10:11:07.351136 20528 net.cpp:434] res5_6 <- conv5_6
I0816 10:11:07.351145 20528 net.cpp:408] res5_6 -> res5_6
I0816 10:11:07.351207 20528 net.cpp:150] Setting up res5_6
I0816 10:11:07.351219 20528 net.cpp:157] Top shape: 1 512 5 4 (10240)
I0816 10:11:07.351224 20528 net.cpp:165] Memory required for data: 26321920
I0816 10:11:07.351230 20528 layer_factory.hpp:77] Creating layer fc5
I0816 10:11:07.351244 20528 net.cpp:100] Creating Layer fc5
I0816 10:11:07.351250 20528 net.cpp:434] fc5 <- res5_6
I0816 10:11:07.351258 20528 net.cpp:408] fc5 -> fc5
I0816 10:11:07.394814 20528 net.cpp:150] Setting up fc5
I0816 10:11:07.394861 20528 net.cpp:157] Top shape: 1 512 (512)
I0816 10:11:07.394866 20528 net.cpp:165] Memory required for data: 26323968
I0816 10:11:07.394882 20528 net.cpp:228] fc5 does not need backward computation.
I0816 10:11:07.394889 20528 net.cpp:228] res5_6 does not need backward computation.
I0816 10:11:07.394896 20528 net.cpp:228] relu5_6 does not need backward computation.
I0816 10:11:07.394901 20528 net.cpp:228] conv5_6 does not need backward computation.
I0816 10:11:07.394907 20528 net.cpp:228] relu5_5 does not need backward computation.
I0816 10:11:07.394912 20528 net.cpp:228] conv5_5 does not need backward computation.
I0816 10:11:07.394919 20528 net.cpp:228] res5_4_res5_4_0_split does not need backward computation.
I0816 10:11:07.394925 20528 net.cpp:228] res5_4 does not need backward computation.
I0816 10:11:07.394932 20528 net.cpp:228] relu5_4 does not need backward computation.
I0816 10:11:07.394937 20528 net.cpp:228] conv5_4 does not need backward computation.
I0816 10:11:07.394943 20528 net.cpp:228] relu5_3 does not need backward computation.
I0816 10:11:07.394949 20528 net.cpp:228] conv5_3 does not need backward computation.
I0816 10:11:07.394955 20528 net.cpp:228] res5_2_res5_2_0_split does not need backward computation.
I0816 10:11:07.394961 20528 net.cpp:228] res5_2 does not need backward computation.
I0816 10:11:07.394968 20528 net.cpp:228] relu5_2 does not need backward computation.
I0816 10:11:07.394973 20528 net.cpp:228] conv5_2 does not need backward computation.
I0816 10:11:07.394979 20528 net.cpp:228] relu5_1 does not need backward computation.
I0816 10:11:07.394984 20528 net.cpp:228] conv5_1 does not need backward computation.
I0816 10:11:07.394990 20528 net.cpp:228] pool4_pool4_0_split does not need backward computation.
I0816 10:11:07.394997 20528 net.cpp:228] pool4 does not need backward computation.
I0816 10:11:07.395004 20528 net.cpp:228] relu4 does not need backward computation.
I0816 10:11:07.395009 20528 net.cpp:228] conv4 does not need backward computation.
I0816 10:11:07.395015 20528 net.cpp:228] res4_10 does not need backward computation.
I0816 10:11:07.395021 20528 net.cpp:228] relu4_10 does not need backward computation.
I0816 10:11:07.395027 20528 net.cpp:228] conv4_10 does not need backward computation.
I0816 10:11:07.395033 20528 net.cpp:228] relu4_9 does not need backward computation.
I0816 10:11:07.395052 20528 net.cpp:228] conv4_9 does not need backward computation.
I0816 10:11:07.395058 20528 net.cpp:228] res4_8_res4_8_0_split does not need backward computation.
I0816 10:11:07.395064 20528 net.cpp:228] res4_8 does not need backward computation.
I0816 10:11:07.395071 20528 net.cpp:228] relu4_8 does not need backward computation.
I0816 10:11:07.395077 20528 net.cpp:228] conv4_8 does not need backward computation.
I0816 10:11:07.395082 20528 net.cpp:228] relu4_7 does not need backward computation.
I0816 10:11:07.395088 20528 net.cpp:228] conv4_7 does not need backward computation.
I0816 10:11:07.395095 20528 net.cpp:228] res4_6_res4_6_0_split does not need backward computation.
I0816 10:11:07.395100 20528 net.cpp:228] res4_6 does not need backward computation.
I0816 10:11:07.395107 20528 net.cpp:228] relu4_6 does not need backward computation.
I0816 10:11:07.395112 20528 net.cpp:228] conv4_6 does not need backward computation.
I0816 10:11:07.395118 20528 net.cpp:228] relu4_5 does not need backward computation.
I0816 10:11:07.395124 20528 net.cpp:228] conv4_5 does not need backward computation.
I0816 10:11:07.395130 20528 net.cpp:228] res4_4_res4_4_0_split does not need backward computation.
I0816 10:11:07.395136 20528 net.cpp:228] res4_4 does not need backward computation.
I0816 10:11:07.395143 20528 net.cpp:228] relu4_4 does not need backward computation.
I0816 10:11:07.395148 20528 net.cpp:228] conv4_4 does not need backward computation.
I0816 10:11:07.395154 20528 net.cpp:228] relu4_3 does not need backward computation.
I0816 10:11:07.395159 20528 net.cpp:228] conv4_3 does not need backward computation.
I0816 10:11:07.395166 20528 net.cpp:228] res4_2_res4_2_0_split does not need backward computation.
I0816 10:11:07.395172 20528 net.cpp:228] res4_2 does not need backward computation.
I0816 10:11:07.395179 20528 net.cpp:228] relu4_2 does not need backward computation.
I0816 10:11:07.395184 20528 net.cpp:228] conv4_2 does not need backward computation.
I0816 10:11:07.395190 20528 net.cpp:228] relu4_1 does not need backward computation.
I0816 10:11:07.395196 20528 net.cpp:228] conv4_1 does not need backward computation.
I0816 10:11:07.395202 20528 net.cpp:228] pool3_pool3_0_split does not need backward computation.
I0816 10:11:07.395208 20528 net.cpp:228] pool3 does not need backward computation.
I0816 10:11:07.395215 20528 net.cpp:228] relu3 does not need backward computation.
I0816 10:11:07.395220 20528 net.cpp:228] conv3 does not need backward computation.
I0816 10:11:07.395226 20528 net.cpp:228] res3_4 does not need backward computation.
I0816 10:11:07.395233 20528 net.cpp:228] relu3_4 does not need backward computation.
I0816 10:11:07.395239 20528 net.cpp:228] conv3_4 does not need backward computation.
I0816 10:11:07.395246 20528 net.cpp:228] relu3_3 does not need backward computation.
I0816 10:11:07.395251 20528 net.cpp:228] conv3_3 does not need backward computation.
I0816 10:11:07.395257 20528 net.cpp:228] res3_2_res3_2_0_split does not need backward computation.
I0816 10:11:07.395263 20528 net.cpp:228] res3_2 does not need backward computation.
I0816 10:11:07.395269 20528 net.cpp:228] relu3_2 does not need backward computation.
I0816 10:11:07.395275 20528 net.cpp:228] conv3_2 does not need backward computation.
I0816 10:11:07.395282 20528 net.cpp:228] relu3_1 does not need backward computation.
I0816 10:11:07.395287 20528 net.cpp:228] conv3_1 does not need backward computation.
I0816 10:11:07.395292 20528 net.cpp:228] pool2_pool2_0_split does not need backward computation.
I0816 10:11:07.395298 20528 net.cpp:228] pool2 does not need backward computation.
I0816 10:11:07.395305 20528 net.cpp:228] relu2 does not need backward computation.
I0816 10:11:07.395310 20528 net.cpp:228] conv2 does not need backward computation.
I0816 10:11:07.395316 20528 net.cpp:228] res2_2 does not need backward computation.
I0816 10:11:07.395323 20528 net.cpp:228] relu2_2 does not need backward computation.
I0816 10:11:07.395328 20528 net.cpp:228] conv2_2 does not need backward computation.
I0816 10:11:07.395339 20528 net.cpp:228] relu2_1 does not need backward computation.
I0816 10:11:07.395344 20528 net.cpp:228] conv2_1 does not need backward computation.
I0816 10:11:07.395351 20528 net.cpp:228] pool1b_pool1b_0_split does not need backward computation.
I0816 10:11:07.395359 20528 net.cpp:228] pool1b does not need backward computation.
I0816 10:11:07.395364 20528 net.cpp:228] relu1b does not need backward computation.
I0816 10:11:07.395370 20528 net.cpp:228] conv1b does not need backward computation.
I0816 10:11:07.395376 20528 net.cpp:228] relu1a does not need backward computation.
I0816 10:11:07.395381 20528 net.cpp:228] conv1a does not need backward computation.
I0816 10:11:07.395387 20528 net.cpp:228] input does not need backward computation.
I0816 10:11:07.395393 20528 net.cpp:270] This network produces output fc5
I0816 10:11:07.395449 20528 net.cpp:283] Network initialization done.
I0816 10:11:07.705591 20528 net.cpp:761] Ignoring source layer data
I0816 10:11:07.705621 20528 net.cpp:761] Ignoring source layer label_data_1_split
I0816 10:11:07.729482 20528 net.cpp:761] Ignoring source layer fc5_fc5_0_split
I0816 10:11:07.729504 20528 net.cpp:761] Ignoring source layer fc6
I0816 10:11:07.729509 20528 net.cpp:761] Ignoring source layer softmax_loss
I0816 10:11:07.729514 20528 net.cpp:761] Ignoring source layer center_loss
i: 930   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_72
i: 621   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_441
i: 1   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1
i: 622   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_442
i: 931   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_720
i: 311   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_162
i: 623   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_443
[aac @ 0x7f638e1920c0] element type mismatch 3 != 0
i: 312   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_163
i: 932   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_721
i: 624   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_444
i: 313   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_164
[aac @ 0x7f646e8a5d40] element type mismatch 3 != 0
i: 933   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_722
i: 314   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_165
i: 625   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_445
i: 315   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_166
i: 934   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_723
i: 626   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_446
i: 2   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_10
i: 316   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_167
i: 3   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_100
i: 935   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_724
i: 4   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1000
i: 5   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1001
i: 317   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_168
i: 6   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1002
i: 318   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_169
i: 936   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_725
i: 7   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1003
i: 627   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_447
i: 319   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_17
i: 8   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1004
i: 628   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_448
i: 9   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1005
i: 10   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1006
i: 629   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_449
i: 11   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1007
i: 630   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_45
i: 12   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1008
i: 631   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_450
i: 13   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1009
i: 937   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_726
i: 14   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_101
i: 320   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_170
i: 15   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1010
i: 632   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_451
i: 633   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_452
i: 634   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_453
i: 938   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_727
i: 16   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1011
i: 939   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_728
i: 635   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_454
i: 17   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1012
i: 321   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_171
i: 636   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_455
i: 940   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_729
i: 637   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_456
i: 18   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1013
i: 638   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_457
i: 639   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_458
i: 322   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_172
i: 941   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_73
i: 19   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1014
i: 323   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_173
i: 324   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_174
i: 942   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_730
i: 325   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_175
i: 20   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1015
i: 21   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1016
i: 22   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1017
i: 943   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_731
i: 944   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_732
i: 326   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_176
i: 23   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1018
i: 327   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_177
i: 640   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_459
i: 24   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1019
i: 25   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_102
i: 328   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_178
i: 26   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1020
i: 945   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_733
i: 329   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_179
i: 27   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1021
i: 946   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_734
i: 641   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_46
i: 947   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_735
i: 28   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1022
i: 948   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_736
i: 330   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_18
i: 29   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1023
i: 949   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_737
i: 642   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_460
i: 331   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_180
i: 950   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_738
i: 30   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1024
i: 643   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_461
i: 951   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_739
i: 332   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_181
i: 952   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_74
i: 333   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_182
i: 953   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_740
i: 644   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_462
i: 334   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_183
i: 645   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_463
i: 31   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1025
i: 335   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_184
i: 336   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_185
i: 32   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1026
i: 337   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_186
i: 33   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1027
i: 954   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_741
i: 34   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1028
i: 955   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_742
i: 338   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_187
i: 646   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_464
[aac @ 0x7f638e717160] element type mismatch 3 != 0
i: 956   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_743
i: 35   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1029
i: 339   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_188
i: 957   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_744
i: 36   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_103
i: 340   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_189
i: 958   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_745
i: 341   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_19
i: 959   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_746
i: 342   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_190
i: 37   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1030
i: 647   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_465
i: 38   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1031
i: 343   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_191
i: 39   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1032
i: 40   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1033
i: 344   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_192
i: 648   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_466
i: 345   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_193
i: 41   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1034
i: 346   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_194
i: 649   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_467
i: 347   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_195
i: 960   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_747
i: 42   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1035
i: 961   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_748
i: 650   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_468
i: 348   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_196
i: 43   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1036
i: 962   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_749
i: 651   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_469
i: 963   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_75
i: 44   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1037
i: 349   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_197
i: 964   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_750
i: 652   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_47
i: 965   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_751
i: 45   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1038
i: 653   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_470
i: 46   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1039
i: 47   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_104
i: 966   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_752
i: 350   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_198
i: 654   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_471
i: 967   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_753
i: 48   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1040
i: 968   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_754
i: 969   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_755
i: 351   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_199
i: 655   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_472
i: 49   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1041
i: 352   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_2
i: 970   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_756
i: 971   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_757
i: 353   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_20
i: 50   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1042
i: 972   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_758
i: 354   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_200
i: 973   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_759
i: 51   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1043
i: 656   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_473
i: 52   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1044
i: 657   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_474
i: 53   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1045
i: 355   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_201
i: 54   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1046
i: 974   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_76
i: 975   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_760
i: 356   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_202
i: 976   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_761
i: 357   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_203
i: 55   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1047
i: 56   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1048
i: 358   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_204
i: 977   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_762
i: 359   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_205
i: 360   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_206
i: 57   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1049
i: 361   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_207
i: 978   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_763
i: 58   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_105
i: 362   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_208
i: 658   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_475
i: 363   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_209
i: 659   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_476
i: 59   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1050
i: 979   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_764
i: 364   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_21
i: 660   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_477
i: 980   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_765
i: 365   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_210
i: 981   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_766
i: 982   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_767
i: 60   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1051
i: 983   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_768
i: 661   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_478
i: 61   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1052
i: 62   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1053
i: 984   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_769
i: 366   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_211
i: 985   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_77
i: 662   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_479
i: 663   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_48
i: 664   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_480
i: 665   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_481
i: 63   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1054
i: 64   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1055
i: 666   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_482
i: 367   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_212
i: 65   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1056
i: 66   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1057
i: 667   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_483
i: 368   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_213
i: 668   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_484
i: 67   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1058
i: 68   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1059
i: 669   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_485
i: 369   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_214
i: 986   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_770
i: 987   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_771
i: 69   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_106
i: 988   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_772
i: 70   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1060
i: 989   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_773
i: 990   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_774
i: 670   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_486
i: 71   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1061
i: 671   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_487
i: 991   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_775
i: 72   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1062
i: 73   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1063
i: 370   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_215
i: 672   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_488
i: 673   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_489
i: 371   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_216
i: 992   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_776
i: 993   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_777
i: 674   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_49
i: 994   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_778
i: 675   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_490
i: 676   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_491
i: 995   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_779
i: 372   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_217
i: 373   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_218
i: 374   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_219
i: 996   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_78
i: 997   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_780
i: 375   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_22
i: 74   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1064
i: 677   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_492
i: 376   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_220
i: 75   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1065
i: 377   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_221
i: 998   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_781
i: 678   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_493
[aac @ 0x7f638c1b9860] element type mismatch 3 != 0
i: 999   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_782
i: 378   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_222
i: 1000   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_783
i: 679   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_494
i: 379   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_223
i: 680   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_495
i: 76   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1066
i: 77   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1067
i: 1001   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_784
i: 380   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_224
i: 1002   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_785
i: 78   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1068
i: 681   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_496
i: 79   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1069
i: 381   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_225
i: 382   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_226
i: 682   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_497
i: 683   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_498
i: 383   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_227
i: 684   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_499
i: 1003   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_786
i: 384   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_228
i: 385   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_229
i: 1004   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_787
i: 1005   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_788
i: 1006   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_789
i: 386   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_23
i: 685   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_5
i: 387   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_230
i: 686   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_50
i: 388   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_231
i: 1007   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_79
i: 389   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_232
i: 687   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_500
i: 688   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_501
i: 689   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_502
i: 390   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_233
i: 1008   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_790
i: 690   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_503
i: 391   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_234
i: 392   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_235
i: 691   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_504
i: 692   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_505
i: 80   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_107
i: 693   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_506
i: 1009   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_791
i: 694   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_507
i: 393   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_236
i: 1010   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_792
i: 695   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_508
i: 1011   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_793
i: 394   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_237
i: 1012   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_794
i: 395   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_238
i: 696   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_509
i: 1013   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_795
i: 697   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_51
i: 698   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_510
i: 1014   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_796
i: 699   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_511
i: 1015   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_797
i: 700   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_512
i: 701   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_513
i: 81   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1070
i: 1016   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_798
i: 702   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_514
i: 82   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1071
i: 703   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_515
i: 396   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_239
i: 704   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_516
i: 1017   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_799
i: 705   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_517
i: 1018   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_8
i: 706   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_518
i: 83   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1072
i: 707   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_519
i: 84   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1073
i: 85   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_1074
[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7f6550007240] error reading header
i: 708   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_52
i: 397   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_24
i: 709   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_520
i: 710   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_521
i: 1019   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_80
i: 1020   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_800
i: 398   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_240
i: 1021   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_801
i: 399   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_241
i: 400   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_242
i: 711   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_522
i: 401   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_243
i: 1022   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_802
i: 402   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_244
i: 1023   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_803
i: 1024   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_804
i: 403   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_245
i: 712   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_523
i: 404   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_246
i: 713   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_524
i: 1025   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_805
i: 405   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_247
i: 714   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_525
i: 715   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_526
i: 1026   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_806
i: 716   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_527
i: 1027   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_807
i: 1028   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_808
i: 717   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_528
i: 1029   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_809
i: 718   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_529
i: 406   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_248
i: 407   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_249
i: 719   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_53
i: 1030   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_81
i: 720   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_530
i: 408   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_25
i: 1031   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_810
i: 721   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_531
i: 1032   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_811
i: 1033   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_812
i: 722   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_532
i: 409   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_250
i: 1034   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_813
i: 410   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_251
i: 723   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_533
i: 1035   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_814
i: 411   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_252
i: 724   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_534
i: 412   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_253
i: 725   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_535
i: 413   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_254
i: 726   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_536
i: 414   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_255
i: 727   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_537
i: 415   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_256
i: 416   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_257
i: 1036   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_815
i: 728   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_538
i: 729   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_539
i: 730   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_54
i: 731   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_540
i: 417   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_258
i: 1037   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_816
i: 732   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_541
i: 418   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_259
i: 1038   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_817
i: 733   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_542
i: 419   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_26
i: 734   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_543
i: 420   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_260
i: 735   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_544
i: 1039   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_818
i: 421   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_261
i: 736   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_545
i: 1040   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_819
i: 1041   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_82
i: 422   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_262
i: 1042   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_820
i: 737   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_546
i: 423   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_263
i: 738   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_547
i: 424   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_264
i: 1043   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_821
i: 425   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_265
i: 739   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_548
i: 1044   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_822
[aac @ 0x7f61d46862a0] element type mismatch 3 != 0
i: 426   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_266
i: 740   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_549
i: 1045   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_823
i: 427   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_267
i: 428   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_268
i: 1046   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_824
i: 741   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_55
i: 429   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_269
i: 1047   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_825
i: 742   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_550
i: 430   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_27
i: 1048   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_826
i: 431   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_270
i: 743   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_551
i: 432   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_271
i: 744   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_552
i: 433   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_272
i: 745   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_553
i: 746   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_554
i: 434   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_273
i: 747   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_555
i: 1049   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_827
i: 435   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_274
i: 748   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_556
i: 436   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_275
i: 1050   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_828
i: 749   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_557
i: 437   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_276
i: 1051   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_829
i: 750   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_558
i: 438   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_277
i: 751   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_559
i: 439   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_278
i: 1052   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_83
i: 1053   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_830
i: 440   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_279
i: 1054   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_831
i: 441   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_28
i: 1055   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_832
i: 1056   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_833
i: 442   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_280
i: 752   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_56
i: 443   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_281
i: 1057   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_834
i: 753   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_560
i: 444   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_282
i: 754   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_561
i: 445   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_283
i: 446   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_284
i: 755   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_562
i: 1058   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_835
i: 447   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_285
i: 756   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_563
i: 1059   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_836
i: 448   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_286
i: 757   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_564
i: 1060   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_837
i: 1061   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_838
i: 449   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_287
i: 1062   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_839
i: 450   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_288
i: 758   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_565
i: 451   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_289
i: 759   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_566
i: 760   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_567
i: 761   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_568
i: 1063   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_84
i: 1064   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_840
i: 762   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_569
i: 1065   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_841
i: 763   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_57
i: 1066   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_842
[aac @ 0x7f62a2a36dc0] element type mismatch 3 != 0
i: 764   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_570
i: 452   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_29
i: 453   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_290
i: 765   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_571
i: 454   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_291
i: 766   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_572
i: 1067   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_843
i: 455   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_292
i: 767   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_573
i: 456   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_293
i: 1068   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_844
i: 768   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_574
i: 1069   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_845
i: 769   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_575
i: 1070   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_846
i: 1071   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_847
i: 457   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_294
i: 1072   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_848
i: 458   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_295
i: 770   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_576
i: 459   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_296
i: 460   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_297
i: 771   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_577
i: 461   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_298
i: 1073   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_849
i: 1074   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_85
i: 462   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_299
i: 1075   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_850
i: 463   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_3
i: 1076   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_851
i: 464   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_30
i: 465   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_300
i: 1077   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_852
i: 1078   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_853
i: 466   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_301
i: 772   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_578
i: 467   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_302
i: 773   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_579
i: 1079   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_854
i: 468   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_303
i: 774   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_58
i: 1080   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_855
i: 469   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_304
i: 470   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_305
i: 775   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_580
i: 776   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_581
i: 1081   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_856
i: 471   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_306
i: 1082   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_857
i: 777   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_582
i: 472   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_307
i: 1083   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_858
[aac @ 0x7f62a2a36dc0] element type mismatch 3 != 0
i: 1084   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_859
i: 778   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_583
i: 1085   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_86
i: 473   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_308
i: 779   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_584
i: 1086   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_860
i: 474   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_309
i: 780   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_585
i: 1087   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_861
i: 781   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_586
i: 475   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_31
i: 1088   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_862
i: 476   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_310
i: 1089   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_863
i: 477   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_311
i: 782   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_587
i: 478   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_312
i: 783   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_588
i: 1090   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_864
i: 784   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_589
i: 479   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_313
i: 785   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_59
i: 1091   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_865
i: 480   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_314
i: 481   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_315
i: 786   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_590
i: 1092   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_866
i: 1093   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_867
i: 482   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_316
i: 1094   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_868
i: 787   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_591
i: 483   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_317
i: 1095   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_869
i: 1096   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_87
i: 484   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_318
i: 1097   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_870
i: 485   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_319
i: 788   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_592
i: 789   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_593
i: 1098   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_871
i: 486   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_32
i: 790   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_594
i: 487   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_320
i: 791   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_595
i: 1099   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_872
i: 1100   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_873
i: 792   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_596
i: 1101   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_874
i: 793   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_597
i: 1102   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_875
i: 1103   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_876
i: 794   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_598
i: 795   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_599
i: 1104   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_877
i: 488   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_321
i: 796   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_6
i: 489   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_322
i: 797   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_60
i: 490   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_323
i: 1105   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_878
i: 491   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_324
i: 1106   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_879
i: 492   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_325
i: 1107   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_88
i: 493   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_326
i: 1108   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_880
i: 1109   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_881
i: 798   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_600
i: 1110   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_882
i: 494   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_327
i: 799   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_601
i: 800   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_602
i: 1111   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_883
i: 1112   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_884
i: 801   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_603
i: 495   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_328
i: 802   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_604
i: 496   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_329
i: 1113   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_885
i: 1114   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_886
i: 1115   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_887
i: 497   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_33
i: 498   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_330
i: 1116   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_888
i: 803   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_605
i: 1117   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_889
i: 499   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_331
i: 1118   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_89
i: 500   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_332
i: 804   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_606
i: 805   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_607
i: 501   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_333
i: 1119   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_890
i: 502   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_334
i: 806   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_608
i: 503   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_335
i: 1120   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_891
[aac @ 0x7f61d46862a0] element type mismatch 3 != 0
i: 1121   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_892
i: 807   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_609
i: 808   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_61
i: 1122   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_893
i: 809   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_610
i: 504   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_336
i: 505   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_337
i: 1123   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_894
i: 506   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_338
i: 507   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_339
i: 1124   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_895
i: 810   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_611
i: 508   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_34
i: 509   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_340
i: 811   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_612
i: 1125   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_896
i: 812   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_613
i: 510   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_341
i: 1126   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_897
i: 813   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_614
i: 1127   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_898
i: 814   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_615
i: 511   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_342
i: 1128   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_899
i: 512   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_343
i: 1129   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_9
i: 513   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_344
i: 815   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_616
i: 1130   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_90
i: 816   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_617
i: 514   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_345
i: 515   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_346
i: 1131   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_900
i: 817   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_618
i: 1132   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_901
i: 818   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_619
i: 819   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_62
i: 820   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_620
i: 1133   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_902
i: 821   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_621
i: 1134   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_903
i: 822   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_622
[aac @ 0x7f638c1b9860] element type mismatch 3 != 0
i: 823   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_623
i: 824   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_624
i: 1135   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_904
i: 516   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_347
i: 1136   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_905
i: 825   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_625
i: 517   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_348
i: 1137   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_906
i: 1138   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_907
i: 518   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_349
i: 519   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_35
i: 826   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_626
i: 520   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_350
i: 1139   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_908
i: 521   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_351
i: 827   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_627
i: 828   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_628
i: 1140   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_909
i: 522   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_352
i: 829   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_629
i: 1141   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_91
i: 1142   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_910
i: 830   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_63
i: 831   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_630
i: 1143   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_911
i: 1144   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_912
i: 832   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_631
i: 1145   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_913
i: 833   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_632
i: 1146   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_914
i: 523   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_353
i: 834   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_633
i: 835   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_634
i: 524   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_354
i: 1147   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_915
i: 1148   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_916
i: 836   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_635
i: 1149   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_917
i: 1150   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_918
i: 837   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_636
i: 1151   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_919
i: 525   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_355
i: 838   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_637
i: 1152   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_92
i: 1153   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_920
i: 839   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_638
i: 526   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_356
i: 1154   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_921
i: 527   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_357
i: 528   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_358
i: 840   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_639
i: 841   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_64
i: 529   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_359
i: 1155   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_922
i: 530   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_36
i: 1156   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_923
i: 1157   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_924
i: 1158   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_925
i: 1159   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_926
i: 531   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_360
i: 1160   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_927
i: 842   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_640
i: 1161   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_928
i: 1162   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_929
i: 532   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_361
i: 1163   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_93
i: 533   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_362
i: 534   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_363
i: 843   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_641
i: 1164   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_930
i: 1165   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_931
i: 844   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_642
i: 535   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_364
i: 536   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_365
i: 537   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_366
i: 538   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_367
i: 539   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_368
i: 1166   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_932
i: 540   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_369
i: 845   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_643
i: 1167   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_933
i: 541   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_37
i: 1168   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_934
i: 542   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_370
i: 1169   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_935
i: 846   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_644
i: 543   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_371
i: 847   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_645
i: 544   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_372
i: 545   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_373
i: 546   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_374
i: 547   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_375
i: 548   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_376
i: 549   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_377
i: 550   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_378
i: 551   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_379
i: 552   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_38
i: 848   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_646
i: 553   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_380
i: 554   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_381
i: 849   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_647
i: 850   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_648
i: 1170   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_936
i: 851   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_649
i: 1171   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_937
i: 1172   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_938
i: 1173   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_939
i: 555   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_382
i: 1174   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_94
i: 852   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_65
i: 556   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_383
i: 557   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_384
i: 1175   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_940
i: 558   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_385
i: 559   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_386
i: 1176   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_941
i: 1177   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_942
i: 560   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_387
i: 853   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_650
i: 561   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_388
i: 1178   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_943
i: 562   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_389
i: 854   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_651
i: 563   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_39
i: 855   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_652
i: 1179   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_944
i: 856   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_653
i: 857   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_654
i: 1180   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_945
i: 564   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_390
i: 858   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_655
i: 1181   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_946
i: 565   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_391
i: 859   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_656
i: 566   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_392
i: 860   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_657
i: 861   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_658
i: 862   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_659
i: 567   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_393
i: 863   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_66
i: 568   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_394
i: 1182   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_947
i: 864   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_660
i: 865   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_661
i: 569   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_395
i: 866   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_662
i: 867   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_663
i: 1183   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_948
i: 570   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_396
i: 868   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_664
i: 1184   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_949
i: 571   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_397
i: 869   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_665
i: 572   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_398
i: 1185   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_95
i: 573   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_399
i: 870   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_666
i: 574   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_4
i: 1186   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_950
i: 871   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_667
i: 575   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_40
i: 1187   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_951
i: 872   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_668
i: 576   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_400
i: 1188   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_952
i: 873   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_669
i: 577   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_401
i: 1189   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_953
i: 578   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_402
i: 874   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_67
i: 579   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_403
i: 875   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_670
i: 580   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_404
i: 876   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_671
i: 1190   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_954
i: 877   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_672
i: 581   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_405
i: 878   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_673
i: 1191   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_955
i: 582   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_406
i: 1192   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_956
i: 583   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_407
i: 879   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_674
i: 584   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_408
i: 1193   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_957
i: 585   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_409
i: 1194   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_958
i: 586   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_41
i: 1195   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_959
i: 587   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_410
i: 1196   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_96
i: 588   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_411
i: 589   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_412
i: 1197   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_960
i: 590   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_413
i: 1198   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_961
i: 880   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_675
i: 591   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_414
i: 592   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_415
i: 881   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_676
i: 593   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_416
i: 594   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_417
i: 1199   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_962
i: 595   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_418
i: 1200   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_963
i: 596   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_419
i: 1201   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_964
i: 1202   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_965
i: 597   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_42
i: 1203   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_966
[aac @ 0x7f62a2a36dc0] element type mismatch 3 != 0
i: 882   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_677
i: 598   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_420
i: 883   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_678
i: 599   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_421
i: 1204   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_967
i: 884   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_679
i: 885   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_68
i: 600   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_422
i: 886   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_680
i: 1205   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_968
i: 601   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_423
i: 602   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_424
i: 1206   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_969
i: 887   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_681
i: 888   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_682
i: 1207   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_97
i: 603   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_425
i: 889   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_683
i: 604   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_426
i: 1208   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_970
i: 605   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_427
i: 606   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_428
i: 890   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_684
i: 607   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_429
i: 608   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_43
i: 609   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_430
i: 1209   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_971
i: 610   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_431
i: 891   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_685
i: 611   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_432
i: 892   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_686
i: 893   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_687
i: 894   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_688
i: 1210   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_972
i: 612   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_433
i: 1211   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_973
i: 613   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_434
i: 895   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_689
i: 614   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_435
i: 1212   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_974
i: 615   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_436
i: 896   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_69
i: 1213   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_975
i: 616   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_437
i: 1214   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_976
i: 617   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_438
i: 1215   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_977
i: 1216   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_978
i: 897   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_690
i: 618   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_439
i: 1217   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_979
i: 619   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_44
i: 1218   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_98
i: 1219   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_980
i: 1220   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_981
i: 1221   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_982
i: 898   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_691
i: 1222   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_983
[aac @ 0x7f62a2a36dc0] element type mismatch 3 != 0
i: 899   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_692
i: 1223   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_984
i: 900   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_693
i: 1224   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_985
i: 901   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_694
i: 1225   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_986
i: 902   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_695
i: 1226   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_987
i: 1227   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_988
i: 1228   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_989
i: 1229   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_99
i: 903   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_696
i: 1230   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_990
i: 904   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_697
i: 905   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_698
i: 906   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_699
i: 907   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_7
i: 1231   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_991
i: 1232   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_992
i: 1233   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_993
i: 908   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_70
i: 1234   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_994
i: 1235   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_995
i: 909   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_700
i: 910   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_701
i: 1236   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_996
i: 911   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_702
i: 1237   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_997
i: 912   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_703
i: 1238   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_998
i: 913   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_704
i: 914   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_705
i: 1239   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_999
i: 915   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_706
i: 916   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_707
i: 917   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_708
i: 918   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_709
i: 919   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_71
i: 920   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_710
i: 921   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_711
i: 922   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_712
i: 923   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_713
i: 924   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_714
i: 925   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_715
i: 926   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_716
i: 927   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_717
i: 928   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_718
i: 929   /data_b/bd-recommend/lzm/face_worker/video_data/-/-_vid_719
sample_faces.sh: line 1: 20528 Killed                  ./face_samples /data_b/bd-recommend/lzm/face_worker/video_data/- /data_b/bd-recommend/lzm/face_worker/video_data/movies_faces 4
